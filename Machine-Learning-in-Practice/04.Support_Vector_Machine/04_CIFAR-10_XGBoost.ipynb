{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 02:06:12.250807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 02:06:12.259241: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 02:06:12.261699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 02:06:12.268295: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 02:06:12.650911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/myenv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [02:06:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/myenv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [02:06:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Flatten the images (convert 32x32x3 images into 1D vectors)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normalize the data (important for XGBoost)\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "X_test_flat = scaler.transform(X_test_flat)\n",
    "\n",
    "# Optional: Use a smaller subset of the data to speed up training\n",
    "X_train_subset, _, y_train_subset, _ = train_test_split(X_train_flat, y_train, test_size=0.9, random_state=42)\n",
    "X_test_subset, _, y_test_subset, _ = train_test_split(X_test_flat, y_test, test_size=0.9, random_state=42)\n",
    "\n",
    "# Convert the labels into a 1D array\n",
    "y_train_subset = y_train_subset.ravel()\n",
    "y_test_subset = y_test_subset.ravel()\n",
    "\n",
    "# Create the XGBoost DMatrix objects\n",
    "dtrain = xgb.DMatrix(X_train_subset, label=y_train_subset)\n",
    "dtest = xgb.DMatrix(X_test_subset, label=y_test_subset)\n",
    "\n",
    "# Set XGBoost parameters for multi-class classification\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Use softmax for multi-class classification\n",
    "    'num_class': 10,               # 10 classes for CIFAR-10\n",
    "    'max_depth': 6,                # Maximum depth of the trees\n",
    "    'eta': 0.3,                    # Learning rate\n",
    "    'eval_metric': 'mlogloss',      # Multiclass logloss evaluation metric\n",
    "    'tree_method': 'gpu_hist'      # Use GPU for training\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 50  # Number of boosting rounds\n",
    "bst = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 6. 3. 2. 2. 2. 3. 6. 2. 6. 6. 6. 4. 8. 0. 2. 0. 2. 6. 9. 5. 6. 1. 1.\n",
      " 4. 1. 2. 9. 9. 5. 9. 0. 2. 8. 2. 0. 6. 0. 2. 7. 0. 2. 7. 6. 9. 7. 5. 0.\n",
      " 0. 3. 8. 4. 9. 9. 3. 1. 0. 4. 7. 1. 7. 9. 3. 7. 0. 3. 0. 6. 8. 9. 4. 1.\n",
      " 3. 2. 9. 6. 5. 7. 6. 5. 4. 9. 8. 5. 5. 4. 2. 5. 9. 3. 4. 9. 9. 1. 4. 2.\n",
      " 2. 5. 1. 7. 8. 7. 9. 5. 4. 9. 9. 3. 5. 9. 3. 9. 6. 5. 4. 6. 7. 6. 5. 0.\n",
      " 6. 7. 7. 5. 4. 4. 3. 8. 5. 0. 0. 1. 0. 6. 4. 8. 6. 9. 4. 5. 3. 8. 7. 4.\n",
      " 3. 6. 6. 6. 4. 7. 2. 8. 8. 7. 1. 5. 2. 9. 9. 4. 1. 6. 9. 3. 6. 9. 9. 9.\n",
      " 8. 4. 7. 6. 0. 0. 9. 6. 6. 9. 2. 0. 7. 0. 1. 2. 5. 4. 1. 4. 9. 8. 2. 7.\n",
      " 0. 9. 9. 9. 0. 7. 2. 2. 3. 4. 6. 0. 6. 5. 2. 3. 5. 4. 7. 6. 8. 9. 4. 9.\n",
      " 4. 6. 7. 3. 7. 7. 5. 6. 8. 0. 6. 8. 8. 4. 9. 1. 5. 8. 8. 8. 7. 3. 9. 3.\n",
      " 9. 4. 2. 0. 2. 6. 0. 0. 0. 1. 7. 0. 2. 3. 0. 1. 1. 5. 9. 0. 4. 5. 6. 5.\n",
      " 7. 4. 2. 7. 5. 5. 1. 0. 9. 1. 1. 4. 3. 1. 1. 9. 9. 6. 4. 1. 9. 3. 1. 3.\n",
      " 4. 7. 6. 4. 4. 4. 0. 0. 6. 5. 0. 0. 8. 4. 2. 0. 2. 8. 4. 8. 0. 9. 5. 6.\n",
      " 9. 9. 8. 2. 7. 0. 0. 0. 0. 5. 4. 4. 4. 4. 9. 7. 2. 2. 4. 8. 8. 7. 7. 2.\n",
      " 7. 0. 0. 1. 2. 6. 8. 6. 6. 8. 4. 7. 1. 9. 6. 8. 6. 5. 1. 4. 2. 0. 2. 6.\n",
      " 0. 8. 8. 4. 3. 8. 4. 5. 4. 4. 5. 6. 5. 3. 3. 7. 6. 1. 7. 2. 0. 4. 6. 1.\n",
      " 4. 9. 1. 8. 3. 3. 6. 8. 0. 8. 1. 8. 4. 8. 9. 5. 0. 8. 1. 5. 4. 3. 5. 8.\n",
      " 4. 5. 9. 8. 8. 9. 9. 6. 9. 6. 0. 8. 8. 4. 5. 9. 6. 5. 0. 4. 1. 2. 5. 7.\n",
      " 7. 7. 2. 1. 9. 7. 5. 8. 8. 6. 6. 9. 8. 8. 5. 6. 8. 0. 6. 7. 9. 8. 9. 0.\n",
      " 1. 9. 1. 0. 5. 2. 9. 9. 3. 2. 8. 6. 5. 8. 2. 6. 5. 4. 4. 1. 2. 3. 3. 8.\n",
      " 6. 2. 5. 4. 3. 0. 2. 4. 9. 3. 4. 4. 7. 1. 8. 6. 0. 5. 9. 6. 5. 0. 8. 0.\n",
      " 9. 7. 2. 0. 5. 5. 7. 6. 6. 1. 9. 8. 2. 5. 8. 1. 6. 4. 1. 9. 8. 0. 6. 7.\n",
      " 9. 2. 3. 5. 6. 1. 8. 3. 2. 7. 2. 2. 2. 0. 3. 3. 3. 9. 6. 1. 9. 5. 6. 5.\n",
      " 5. 4. 2. 7. 6. 3. 1. 9. 9. 3. 3. 5. 4. 1. 3. 0. 2. 4. 6. 5. 2. 5. 3. 5.\n",
      " 8. 2. 4. 7. 8. 2. 1. 4. 2. 7. 4. 2. 5. 0. 6. 1. 8. 8. 0. 2. 6. 1. 6. 5.\n",
      " 0. 8. 6. 5. 4. 8. 6. 5. 2. 8. 4. 1. 4. 8. 4. 6. 6. 2. 0. 7. 0. 8. 7. 8.\n",
      " 4. 8. 6. 7. 4. 2. 1. 6. 1. 6. 5. 4. 2. 6. 6. 3. 0. 7. 9. 0. 0. 7. 7. 6.\n",
      " 3. 5. 9. 0. 0. 6. 8. 5. 9. 2. 9. 1. 4. 9. 1. 9. 2. 5. 9. 3. 6. 3. 4. 9.\n",
      " 4. 4. 8. 9. 0. 7. 0. 7. 4. 7. 4. 4. 4. 4. 3. 3. 2. 4. 6. 5. 0. 5. 5. 6.\n",
      " 1. 4. 5. 2. 9. 0. 4. 4. 2. 6. 8. 6. 4. 0. 9. 7. 9. 2. 2. 1. 9. 0. 6. 3.\n",
      " 4. 8. 6. 3. 3. 7. 5. 4. 8. 3. 8. 0. 8. 1. 1. 5. 4. 3. 4. 2. 0. 8. 0. 9.\n",
      " 4. 0. 6. 0. 2. 8. 0. 2. 4. 9. 3. 8. 9. 6. 5. 5. 6. 7. 4. 2. 6. 6. 0. 3.\n",
      " 9. 1. 5. 2. 0. 0. 7. 4. 3. 9. 2. 9. 0. 8. 4. 9. 5. 1. 5. 6. 8. 2. 1. 2.\n",
      " 6. 6. 4. 0. 0. 5. 8. 2. 5. 6. 9. 3. 2. 8. 4. 9. 8. 2. 8. 7. 8. 9. 3. 8.\n",
      " 7. 0. 3. 6. 0. 1. 7. 4. 5. 2. 3. 6. 9. 1. 9. 5. 8. 4. 0. 0. 5. 6. 5. 6.\n",
      " 3. 5. 0. 9. 8. 1. 8. 5. 9. 5. 6. 6. 3. 5. 7. 1. 6. 5. 9. 6. 8. 8. 4. 5.\n",
      " 5. 9. 0. 6. 6. 6. 6. 6. 8. 3. 0. 4. 5. 5. 6. 6. 0. 4. 6. 8. 7. 3. 9. 8.\n",
      " 5. 2. 1. 4. 3. 7. 0. 1. 1. 7. 4. 6. 9. 4. 5. 8. 0. 4. 9. 3. 1. 6. 3. 3.\n",
      " 4. 5. 6. 6. 9. 6. 5. 1. 0. 6. 7. 6. 0. 1. 4. 2. 9. 4. 8. 5. 9. 6. 7. 1.\n",
      " 1. 7. 3. 7. 3. 6. 4. 5. 1. 0. 3. 1. 8. 4. 9. 3. 2. 3. 7. 0. 5. 0. 4. 4.\n",
      " 7. 8. 5. 4. 2. 4. 5. 7. 1. 8. 7. 0. 7. 5. 5. 0. 2. 0. 0. 6. 1. 7. 6. 5.\n",
      " 9. 3. 0. 2. 2. 6. 6. 1. 0. 7. 4. 4. 7. 1. 2. 5.]\n",
      "Test accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_subset, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
