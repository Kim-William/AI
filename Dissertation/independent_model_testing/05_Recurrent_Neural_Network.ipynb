{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from textpreprocessor import TextPreprocessor\n",
    "import joblib, os\n",
    "import pandas as pd\n",
    "# Initialize the Text Pre Processor class\n",
    "# processor = TextPreprocessor()\n",
    "\n",
    "INPUT_DIR = \"../Output/proto_models_rev2\"\n",
    "X_train_pad = joblib.load(os.path.join(INPUT_DIR, 'X_train_pad.pkl'))\n",
    "X_test_pad = joblib.load(os.path.join(INPUT_DIR, 'X_test_pad.pkl'))\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv(os.path.join(INPUT_DIR, 'train_cleaned.csv'))\n",
    "df_test = pd.read_csv(os.path.join(INPUT_DIR, 'test_cleaned.csv'))\n",
    "# df_test = processor.load_data()\n",
    "\n",
    "y_train = df_train['polarity']\n",
    "y_test = df_test['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=2,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_16 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728595292.468859  126220 service.cc:146] XLA service 0x7fe17c0090d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728595292.469058  126220 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 23:21:32.497253: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 23:21:32.613572: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4835 - loss: 0.7019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728595293.175850  126220 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.5656 - loss: 0.6738 - val_accuracy: 0.7115 - val_loss: 0.5357\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7919 - loss: 0.4641 - val_accuracy: 0.8120 - val_loss: 0.4002\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9025 - loss: 0.2573 - val_accuracy: 0.8220 - val_loss: 0.3959\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9634 - loss: 0.1366 - val_accuracy: 0.8255 - val_loss: 0.4278\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9895 - loss: 0.0643 - val_accuracy: 0.8100 - val_loss: 0.4851\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Model Accuracy: 82.20%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       893\n",
      "           1       0.82      0.87      0.84      1107\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN Model Building\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "model.add(SimpleRNN(64))  # Using a Simple RNN layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train, epochs=20, batch_size=256, validation_data=(X_test_pad, y_test), callbacks= early_stopping)\n",
    "# Evaluate the model\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 222)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 222)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_1' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_2' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_3' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_4' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_5' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_6' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_7' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_8' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_9' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_10' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_11' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_12' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_13' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_14' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_15' has no defined outputs yet.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m\n\u001b[1;32m     25\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     26\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrnn_model,\n\u001b[1;32m     27\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Set to 1 to avoid parallelism issues\u001b[39;00m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Execute the search\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Display best parameters\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found by RandomizedSearchCV:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_1' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_2' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_3' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_4' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_5' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_6' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_7' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_8' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_9' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_10' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_11' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_12' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_13' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_14' has no defined outputs yet.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 936, in _fit\n    self._check_model_compatibility(y)\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 559, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n  File \"/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/models/sequential.py\", line 295, in outputs\n    raise ValueError(\nValueError: Sequential model 'sequential_15' has no defined outputs yet.\n"
     ]
    }
   ],
   "source": [
    "# Define the model creation function\n",
    "# Define the model creation function with **kwargs to accept arbitrary keyword arguments\n",
    "def create_rnn_model(rnn_units=64, output_dim = 128):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=output_dim))\n",
    "    model.add(SimpleRNN(rnn_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model with KerasClassifier, defining default hyperparameters here\n",
    "rnn_model = KerasClassifier(model=create_rnn_model, output_dim=128, rnn_units=64, optimizer='adam', epochs=10, batch_size=512, verbose=1)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_dist = {\n",
    "    'output_dim': [64, 128, 256],  # Embedding output dimension\n",
    "    'rnn_units': [32, 64, 128],   # Number of RNN units\n",
    "    'optimizer': ['adam', 'rmsprop']  # Optimizer\n",
    "}\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Configure RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rnn_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,  \n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=1  # Set to 1 to avoid parallelism issues\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "random_search.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Best parameters found by RandomizedSearchCV:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132321/1656335232.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(\n",
      "2024-10-10 23:32:31.257520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 23:32:31.278431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 23:32:31.600027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-10 23:32:31.600104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-10 23:32:31.600107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-10-10 23:32:31.625819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-10 23:32:31.625872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-10 23:32:31.625875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-10-10 23:32:32.082641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.082971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.113954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.113954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.113993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.114006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.114194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 23:32:32.114195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 23:32:32.117239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.117277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.117290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.117577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.117615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.117628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-10 23:32:32.321631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-10 23:32:32.321835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-10 23:32:32.321896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 23:32:32.321913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 23:32:34.512817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-10 23:32:34.609217: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f5b404d5dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-10 23:32:34.609240: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 23:32:34.611795: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 23:32:34.649512: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/417 [..............................] - ETA: 1:34 - loss: 0.6939 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 23:32:36.043389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-10 23:32:36.131800: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f56287fe980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-10 23:32:36.131823: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 23:32:36.134530: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 23:32:36.171447: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 236s 563ms/step - loss: 0.6900 - accuracy: 0.5363\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 240s 571ms/step - loss: 0.6955 - accuracy: 0.5166\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.5640 - accuracy: 0.7117\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 225s 540ms/step - loss: 0.6595 - accuracy: 0.6081\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.4168 - accuracy: 0.8162\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 225s 541ms/step - loss: 0.4773 - accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 235s 564ms/step - loss: 0.3492 - accuracy: 0.8506\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 235s 566ms/step - loss: 0.3782 - accuracy: 0.8341\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 237s 565ms/step - loss: 0.3226 - accuracy: 0.8662\n",
      "417/417 [==============================] - 237s 565ms/step - loss: 0.3337 - accuracy: 0.8610\n",
      "209/209 [==============================] - 18s 86ms/step - loss: 0.4232 - accuracy: 0.8083\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 18s 87ms/step - loss: 0.4280 - accuracy: 0.8107\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 137s 644ms/step - loss: 0.6905 - accuracy: 0.5338\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 247s 587ms/step - loss: 0.6943 - accuracy: 0.5215\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 122s 584ms/step - loss: 0.6799 - accuracy: 0.5746\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 119s 571ms/step - loss: 0.5588 - accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 235s 564ms/step - loss: 0.6256 - accuracy: 0.6433\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 116s 555ms/step - loss: 0.3466 - accuracy: 0.8530\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 115s 553ms/step - loss: 0.2776 - accuracy: 0.8906\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.4255 - accuracy: 0.8134\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 228s 548ms/step - loss: 0.4458 - accuracy: 0.7993\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 128s 603ms/step - loss: 0.6936 - accuracy: 0.5290\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 119s 569ms/step - loss: 0.6977 - accuracy: 0.5403\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 228s 547ms/step - loss: 0.3665 - accuracy: 0.8427\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 116s 556ms/step - loss: 0.6557 - accuracy: 0.6355\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 118s 567ms/step - loss: 0.5064 - accuracy: 0.7654\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 228s 548ms/step - loss: 0.3244 - accuracy: 0.8617\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4033 - accuracy: 0.8197\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 116s 558ms/step - loss: 0.3334 - accuracy: 0.8635\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.4097 - accuracy: 0.8092\n",
      " 78/209 [==========>...................] - ETA: 1:27 - loss: 0.6962 - accuracy: 0.5092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/209 [==========>...................] - ETA: 1:23 - loss: 0.6961 - accuracy: 0.5077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:12:39.827935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82/209 [==========>...................] - ETA: 1:21 - loss: 0.6961 - accuracy: 0.5072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:12:40.220280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 00:12:40.220329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 00:12:40.220333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83/209 [==========>...................] - ETA: 1:20 - loss: 0.6961 - accuracy: 0.5068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:12:40.584817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.606041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.606086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.606287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 00:12:40.608430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.608469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.608482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.721356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.721408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.721412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 00:12:40.721429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:12:40.721451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7241 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/209 [===========>..................] - ETA: 1:19 - loss: 0.6960 - accuracy: 0.5063Epoch 1/10\n",
      " 89/209 [===========>..................] - ETA: 1:15 - loss: 0.6958 - accuracy: 0.5081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:12:43.641217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 00:12:43.734347: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f88384ea980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 00:12:43.734367: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 00:12:43.737047: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 00:12:43.784569: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 130s 611ms/step - loss: 0.6943 - accuracy: 0.5122\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 117s 551ms/step - loss: 0.6979 - accuracy: 0.5344\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 245s 583ms/step - loss: 0.6919 - accuracy: 0.5191\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 116s 548ms/step - loss: 0.6846 - accuracy: 0.5545\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 114s 546ms/step - loss: 0.6629 - accuracy: 0.6433\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 225s 541ms/step - loss: 0.5774 - accuracy: 0.7064\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 111s 535ms/step - loss: 0.6220 - accuracy: 0.6801\n",
      "105/105 [==============================] - 9s 85ms/step - loss: 0.6857 - accuracy: 0.5611\n",
      "132/417 [========>.....................] - ETA: 2:34 - loss: 0.4385 - accuracy: 0.8002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:21:43.416617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/417 [========>.....................] - ETA: 2:32 - loss: 0.4388 - accuracy: 0.8004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:21:43.760202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 00:21:43.760255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 00:21:43.760259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/417 [========>.....................] - ETA: 2:29 - loss: 0.4396 - accuracy: 0.8001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:21:44.119733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.140940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.140986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.141184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 00:21:44.144055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.144100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.144124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.275627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.275678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.275683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 00:21:44.275700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 00:21:44.275722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7305 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/417 [=========>....................] - ETA: 2:26 - loss: 0.4434 - accuracy: 0.7965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 00:21:47.149289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 00:21:47.244125: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f79986b8350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 00:21:47.244145: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 00:21:47.248955: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 00:21:47.295755: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 222s 533ms/step - loss: 0.4125 - accuracy: 0.8171\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 246s 585ms/step - loss: 0.6933 - accuracy: 0.5241\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 222s 533ms/step - loss: 0.2754 - accuracy: 0.8911\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 233s 560ms/step - loss: 0.6518 - accuracy: 0.6271\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.2138 - accuracy: 0.9205\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 231s 555ms/step - loss: 0.4464 - accuracy: 0.7935\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.1829 - accuracy: 0.9346\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 229s 549ms/step - loss: 0.3021 - accuracy: 0.8776\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 219s 521ms/step - loss: 0.1282 - accuracy: 0.9590\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 231s 554ms/step - loss: 0.2267 - accuracy: 0.9154\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.1254 - accuracy: 0.9587\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 231s 554ms/step - loss: 0.1823 - accuracy: 0.9384\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 222s 527ms/step - loss: 0.1031 - accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 229s 549ms/step - loss: 0.1554 - accuracy: 0.9484\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 219s 527ms/step - loss: 0.0765 - accuracy: 0.9779\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.6513 - accuracy: 0.8059\n",
      "Epoch 1/10\n",
      "417/417 [==============================] - 231s 554ms/step - loss: 0.1322 - accuracy: 0.9600\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 232s 550ms/step - loss: 0.6841 - accuracy: 0.5457\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 226s 542ms/step - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 222s 528ms/step - loss: 0.5242 - accuracy: 0.7527\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 228s 542ms/step - loss: 0.1103 - accuracy: 0.9636\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.7182 - accuracy: 0.7879\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 222s 533ms/step - loss: 0.3541 - accuracy: 0.8502\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 243s 578ms/step - loss: 0.6929 - accuracy: 0.5234\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 219s 527ms/step - loss: 0.2482 - accuracy: 0.9040\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 231s 555ms/step - loss: 0.6723 - accuracy: 0.6008\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 222s 533ms/step - loss: 0.1919 - accuracy: 0.9306\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 228s 549ms/step - loss: 0.5760 - accuracy: 0.7132\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.1659 - accuracy: 0.9426\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 228s 543ms/step - loss: 0.4228 - accuracy: 0.8057\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 219s 527ms/step - loss: 0.1230 - accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 219s 527ms/step - loss: 0.1479 - accuracy: 0.9499\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 228s 543ms/step - loss: 0.3218 - accuracy: 0.8683\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.5394 - accuracy: 0.7501\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 221s 527ms/step - loss: 0.0881 - accuracy: 0.9753\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 245s 584ms/step - loss: 0.6932 - accuracy: 0.5158\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 220s 528ms/step - loss: 0.0720 - accuracy: 0.9811\n",
      "209/209 [==============================] - 17s 74ms/step - loss: 0.7533 - accuracy: 0.7849\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 234s 562ms/step - loss: 0.6831 - accuracy: 0.5608\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 237s 564ms/step - loss: 0.6872 - accuracy: 0.5358\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 231s 554ms/step - loss: 0.6354 - accuracy: 0.6547\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 227s 541ms/step - loss: 0.4855 - accuracy: 0.7686\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 229s 550ms/step - loss: 0.5188 - accuracy: 0.7491\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.3083 - accuracy: 0.8718\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 231s 554ms/step - loss: 0.4061 - accuracy: 0.8235\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.5863 - accuracy: 0.7132\n",
      "121/417 [=======>......................] - ETA: 2:38 - loss: 0.2312 - accuracy: 0.9241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:40:00.197370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/417 [=======>......................] - ETA: 2:35 - loss: 0.2298 - accuracy: 0.9248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:40:00.550810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 01:40:00.550862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 01:40:00.550865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/417 [=======>......................] - ETA: 2:33 - loss: 0.2299 - accuracy: 0.9240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:40:00.943867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:00.965404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:00.965450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:00.965654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 01:40:00.967360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:00.967400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:00.967413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:01.090240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:01.090288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:01.090293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 01:40:01.090310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:40:01.090331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/417 [========>.....................] - ETA: 2:31 - loss: 0.2297 - accuracy: 0.9236Epoch 1/5\n",
      "131/417 [========>.....................] - ETA: 2:28 - loss: 0.2313 - accuracy: 0.9222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:40:03.967100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 01:40:04.056266: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f23e04ed3f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 01:40:04.056287: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 01:40:04.058661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 01:40:04.095775: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 222s 533ms/step - loss: 0.2334 - accuracy: 0.9120\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 234s 556ms/step - loss: 0.6943 - accuracy: 0.5120\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 225s 535ms/step - loss: 0.1770 - accuracy: 0.9355\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.5148 - accuracy: 0.7984\n",
      "310/417 [=====================>........] - ETA: 57s - loss: 0.6897 - accuracy: 0.5343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:46:40.663074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/417 [=====================>........] - ETA: 55s - loss: 0.6897 - accuracy: 0.5345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:46:40.999905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 01:46:40.999958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 01:46:40.999961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/417 [=====================>........] - ETA: 54s - loss: 0.6896 - accuracy: 0.5348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:46:41.383245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.404957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.405005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.405206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 01:46:41.407141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.407183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.407197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.505198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.505276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.505285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 01:46:41.505322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 01:46:41.505365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7294 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "320/417 [======================>.......] - ETA: 51s - loss: 0.6897 - accuracy: 0.5340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 01:46:44.425686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 01:46:44.524361: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f60944ed610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 01:46:44.524383: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 01:46:44.526712: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 01:46:44.563792: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 221s 531ms/step - loss: 0.6886 - accuracy: 0.5429\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 242s 576ms/step - loss: 0.6905 - accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 225s 540ms/step - loss: 0.6729 - accuracy: 0.5944\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 231s 555ms/step - loss: 0.6127 - accuracy: 0.7021\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 223s 534ms/step - loss: 0.6424 - accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 229s 549ms/step - loss: 0.4218 - accuracy: 0.8071\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.5936 - accuracy: 0.6838\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.6517 - accuracy: 0.6428\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 230s 553ms/step - loss: 0.3489 - accuracy: 0.8497\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 233s 555ms/step - loss: 0.6936 - accuracy: 0.5226\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 228s 548ms/step - loss: 0.3203 - accuracy: 0.8667\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.3948 - accuracy: 0.8254\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 222s 534ms/step - loss: 0.6286 - accuracy: 0.6391\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 133s 628ms/step - loss: 0.6944 - accuracy: 0.5119\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 224s 539ms/step - loss: 0.4478 - accuracy: 0.7941\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 118s 567ms/step - loss: 0.6961 - accuracy: 0.5101\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 116s 557ms/step - loss: 0.6908 - accuracy: 0.5311\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 223s 534ms/step - loss: 0.3552 - accuracy: 0.8454\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 118s 566ms/step - loss: 0.5923 - accuracy: 0.7072\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 116s 556ms/step - loss: 0.3918 - accuracy: 0.8258\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.4162 - accuracy: 0.8083\n",
      "Epoch 1/5\n",
      "417/417 [==============================] - 225s 539ms/step - loss: 0.3174 - accuracy: 0.8668\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4193 - accuracy: 0.8095\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 130s 611ms/step - loss: 0.6934 - accuracy: 0.5169\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 130s 612ms/step - loss: 0.6912 - accuracy: 0.5269\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 119s 571ms/step - loss: 0.6767 - accuracy: 0.5781\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 115s 553ms/step - loss: 0.6486 - accuracy: 0.6435\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 118s 566ms/step - loss: 0.6790 - accuracy: 0.5769\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 113s 542ms/step - loss: 0.4613 - accuracy: 0.7948\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 116s 558ms/step - loss: 0.6280 - accuracy: 0.6874\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 113s 541ms/step - loss: 0.2961 - accuracy: 0.8742\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 118s 568ms/step - loss: 0.4430 - accuracy: 0.8152\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.4800 - accuracy: 0.7660\n",
      " 78/209 [==========>...................] - ETA: 1:10 - loss: 0.4251 - accuracy: 0.8189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 02:26:41.001766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/209 [==========>...................] - ETA: 1:08 - loss: 0.4291 - accuracy: 0.8164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 02:26:41.401805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 02:26:41.401854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 02:26:41.401858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82/209 [==========>...................] - ETA: 1:06 - loss: 0.4313 - accuracy: 0.8144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 02:26:41.775396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.796847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.796896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.797098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 02:26:41.799116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.799157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.799170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.910650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.910725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.910742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 02:26:41.910779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 02:26:41.910819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83/209 [==========>...................] - ETA: 1:05 - loss: 0.4309 - accuracy: 0.8151Epoch 1/10\n",
      " 88/209 [===========>..................] - ETA: 1:02 - loss: 0.4327 - accuracy: 0.8150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 02:26:44.808016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 02:26:44.903613: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fbf9468f1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 02:26:44.903633: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 02:26:44.906154: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 02:26:44.943299: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 112s 528ms/step - loss: 0.3333 - accuracy: 0.8623\n",
      "105/105 [==============================] - 9s 84ms/step - loss: 0.4692 - accuracy: 0.8077\n",
      "Epoch 1/10\n",
      "417/417 [==============================] - 240s 571ms/step - loss: 0.6846 - accuracy: 0.5497\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 229s 544ms/step - loss: 0.6932 - accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 231s 555ms/step - loss: 0.5254 - accuracy: 0.7378\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 220s 523ms/step - loss: 0.6781 - accuracy: 0.5764\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 229s 550ms/step - loss: 0.4057 - accuracy: 0.8200\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.5343 - accuracy: 0.7411\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 229s 550ms/step - loss: 0.3568 - accuracy: 0.8453\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 219s 527ms/step - loss: 0.4249 - accuracy: 0.8022\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 231s 555ms/step - loss: 0.3106 - accuracy: 0.8671\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.3602 - accuracy: 0.8415\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 229s 550ms/step - loss: 0.2810 - accuracy: 0.8849\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 220s 528ms/step - loss: 0.3142 - accuracy: 0.8664\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 229s 549ms/step - loss: 0.2656 - accuracy: 0.8917\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.2971 - accuracy: 0.8754\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 217s 522ms/step - loss: 0.2728 - accuracy: 0.8886\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 225s 541ms/step - loss: 0.2445 - accuracy: 0.9034\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 220s 522ms/step - loss: 0.2577 - accuracy: 0.8941\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 223s 536ms/step - loss: 0.2443 - accuracy: 0.9011\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 220s 527ms/step - loss: 0.2456 - accuracy: 0.9013\n",
      "417/417 [==============================] - 223s 535ms/step - loss: 0.2376 - accuracy: 0.9053\n",
      "209/209 [==============================] - 17s 84ms/step - loss: 0.4510 - accuracy: 0.8209\n",
      " 88/209 [===========>..................] - ETA: 8s - loss: 0.4200 - accuracy: 0.8267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 03:04:59.762884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/209 [=============>................] - ETA: 6s - loss: 0.4239 - accuracy: 0.8263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 03:05:00.108934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 03:05:00.108986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 03:05:00.108990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/209 [================>.............] - ETA: 5s - loss: 0.4261 - accuracy: 0.8219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 03:05:00.490193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.511934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.511981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.512189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 03:05:00.513980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.514020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.514033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/209 [=================>............] - ETA: 4s - loss: 0.4316 - accuracy: 0.8218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 03:05:00.838354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.838408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.838413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 03:05:00.838430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 03:05:00.838454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7296 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/209 [======================>.......] - ETA: 2s - loss: 0.4249 - accuracy: 0.8253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 03:05:03.813543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 03:05:03.905504: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fe3b0fb54f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 03:05:03.905524: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 03:05:03.907966: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 03:05:03.944195: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 14s 69ms/step - loss: 0.4100 - accuracy: 0.8284\n",
      "Epoch 1/10\n",
      "417/417 [==============================] - 238s 566ms/step - loss: 0.6872 - accuracy: 0.5407\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 233s 559ms/step - loss: 0.6788 - accuracy: 0.5681\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 224s 537ms/step - loss: 0.5225 - accuracy: 0.7452\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 224s 537ms/step - loss: 0.5030 - accuracy: 0.7615\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 224s 537ms/step - loss: 0.3817 - accuracy: 0.8315\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 227s 544ms/step - loss: 0.4083 - accuracy: 0.8193\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 223s 536ms/step - loss: 0.3315 - accuracy: 0.8611\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 229s 550ms/step - loss: 0.3305 - accuracy: 0.8611\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 221s 532ms/step - loss: 0.3048 - accuracy: 0.8728\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 227s 544ms/step - loss: 0.2926 - accuracy: 0.8797\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 223s 531ms/step - loss: 0.2823 - accuracy: 0.8842\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 222s 532ms/step - loss: 0.2731 - accuracy: 0.8874\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 224s 537ms/step - loss: 0.2694 - accuracy: 0.8903\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 223s 532ms/step - loss: 0.2528 - accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 224s 539ms/step - loss: 0.2523 - accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 224s 538ms/step - loss: 0.2442 - accuracy: 0.9060\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 226s 538ms/step - loss: 0.2374 - accuracy: 0.9064\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 223s 535ms/step - loss: 0.2323 - accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 222s 532ms/step - loss: 0.2338 - accuracy: 0.9067\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.2193 - accuracy: 0.9147\n",
      "209/209 [==============================] - 17s 74ms/step - loss: 0.4171 - accuracy: 0.8332\n",
      "Epoch 1/10\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4301 - accuracy: 0.8266\n",
      "Epoch 1/10\n",
      "417/417 [==============================] - 232s 552ms/step - loss: 0.6920 - accuracy: 0.5274\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 232s 552ms/step - loss: 0.6962 - accuracy: 0.5133\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.5848 - accuracy: 0.6928\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 223s 537ms/step - loss: 0.6864 - accuracy: 0.5478\n",
      "Epoch 3/10\n",
      "417/417 [==============================] - 223s 531ms/step - loss: 0.4144 - accuracy: 0.8145\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.6719 - accuracy: 0.5877\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.3574 - accuracy: 0.8451\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.6076 - accuracy: 0.6682\n",
      "Epoch 5/10\n",
      "417/417 [==============================] - 223s 536ms/step - loss: 0.3188 - accuracy: 0.8628\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 223s 536ms/step - loss: 0.5087 - accuracy: 0.7483\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.2928 - accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 221s 532ms/step - loss: 0.4344 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "417/417 [==============================] - 221s 530ms/step - loss: 0.2725 - accuracy: 0.8868\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 223s 537ms/step - loss: 0.3820 - accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 221s 530ms/step - loss: 0.2510 - accuracy: 0.8961\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 223s 536ms/step - loss: 0.3389 - accuracy: 0.8547\n",
      "Epoch 9/10\n",
      "417/417 [==============================] - 221s 525ms/step - loss: 0.2492 - accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 221s 532ms/step - loss: 0.3090 - accuracy: 0.8733\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 223s 531ms/step - loss: 0.2305 - accuracy: 0.9085\n",
      "417/417 [==============================] - 223s 532ms/step - loss: 0.2927 - accuracy: 0.8767\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4138 - accuracy: 0.8266\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4514 - accuracy: 0.8047\n",
      " 16/417 [>.............................] - ETA: 4:14 - loss: 0.6966 - accuracy: 0.4766Epoch 1/5\n",
      "417/417 [==============================] - 244s 580ms/step - loss: 0.6888 - accuracy: 0.5440\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 239s 572ms/step - loss: 0.6598 - accuracy: 0.5950\n",
      "Epoch 2/5\n",
      "417/417 [==============================] - 227s 545ms/step - loss: 0.5032 - accuracy: 0.7618\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 221s 530ms/step - loss: 0.6125 - accuracy: 0.6879\n",
      "Epoch 3/5\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.4080 - accuracy: 0.8319\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 227s 545ms/step - loss: 0.3052 - accuracy: 0.8758\n",
      "Epoch 4/5\n",
      "417/417 [==============================] - 223s 531ms/step - loss: 0.3121 - accuracy: 0.8733\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 227s 544ms/step - loss: 0.2311 - accuracy: 0.9088\n",
      "Epoch 5/5\n",
      "417/417 [==============================] - 221s 531ms/step - loss: 0.2513 - accuracy: 0.9061\n",
      "417/417 [==============================] - 227s 545ms/step - loss: 0.1964 - accuracy: 0.9332\n",
      "209/209 [==============================] - 17s 83ms/step - loss: 0.4897 - accuracy: 0.7867\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 18s 84ms/step - loss: 0.4152 - accuracy: 0.8266\n",
      " 21/417 [>.............................] - ETA: 4:37 - loss: 0.6951 - accuracy: 0.5238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:39:42.120523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/417 [>.............................] - ETA: 4:18 - loss: 0.6950 - accuracy: 0.5136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:39:42.468884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 04:39:42.468937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 04:39:42.468941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/417 [>.............................] - ETA: 4:01 - loss: 0.6948 - accuracy: 0.5150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:39:42.836527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.858350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.858396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.858601: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 04:39:42.860403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.860443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.860457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.964424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.964510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.964519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 04:39:42.964556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:39:42.964599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7299 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/417 [>.............................] - ETA: 3:55 - loss: 0.6949 - accuracy: 0.5120Epoch 1/10\n",
      " 30/417 [=>............................] - ETA: 3:50 - loss: 0.6952 - accuracy: 0.5021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:39:45.897829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 04:39:45.992837: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f541cc203f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 04:39:45.992858: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 04:39:45.995370: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 04:39:46.042808: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 132s 622ms/step - loss: 0.6934 - accuracy: 0.5194\n",
      "Epoch 2/10\n",
      "417/417 [==============================] - 234s 560ms/step - loss: 0.6893 - accuracy: 0.5350\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 120s 565ms/step - loss: 0.6819 - accuracy: 0.5695\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 117s 560ms/step - loss: 0.6256 - accuracy: 0.6802\n",
      "Epoch 4/10\n",
      "417/417 [==============================] - 225s 535ms/step - loss: 0.6203 - accuracy: 0.6654\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 117s 560ms/step - loss: 0.4712 - accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 117s 561ms/step - loss: 0.3479 - accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "417/417 [==============================] - 224s 534ms/step - loss: 0.4106 - accuracy: 0.8158\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 116s 559ms/step - loss: 0.2960 - accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 117s 560ms/step - loss: 0.2288 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "417/417 [==============================] - 224s 533ms/step - loss: 0.2858 - accuracy: 0.8856\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 115s 550ms/step - loss: 0.1754 - accuracy: 0.9401\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 116s 549ms/step - loss: 0.1585 - accuracy: 0.9457\n",
      "Epoch 10/10\n",
      "417/417 [==============================] - 222s 533ms/step - loss: 0.2266 - accuracy: 0.9153\n",
      "209/209 [==============================] - 18s 84ms/step - loss: 0.5187 - accuracy: 0.7813\n",
      "117/209 [===============>..............] - ETA: 51s - loss: 0.1253 - accuracy: 0.9658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:58:34.591352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 04:58:34.932178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 04:58:34.932231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-11.8/lib64\n",
      "2024-10-11 04:58:34.932235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/209 [================>.............] - ETA: 48s - loss: 0.1245 - accuracy: 0.9667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:58:35.330598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.361496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.361540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.361745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 04:58:35.363639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.363680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.363693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.495858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.495906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.495911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 04:58:35.495930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 04:58:35.495952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7295 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/209 [=================>............] - ETA: 45s - loss: 0.1229 - accuracy: 0.9668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 04:58:38.417066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 04:58:38.503829: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fa1b97e7630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 04:58:38.503850: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 04:58:38.509459: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 04:58:38.555772: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 115s 554ms/step - loss: 0.1259 - accuracy: 0.9646\n",
      "105/105 [==============================] - 9s 84ms/step - loss: 0.5854 - accuracy: 0.7966\n",
      "Epoch 1/10\n",
      "209/209 [==============================] - 133s 627ms/step - loss: 0.6602 - accuracy: 0.6024\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 125s 586ms/step - loss: 0.6770 - accuracy: 0.5685\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 114s 547ms/step - loss: 0.4833 - accuracy: 0.7779\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 113s 542ms/step - loss: 0.5251 - accuracy: 0.7600\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 116s 546ms/step - loss: 0.3606 - accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 110s 529ms/step - loss: 0.3741 - accuracy: 0.8479\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 115s 552ms/step - loss: 0.2818 - accuracy: 0.8862\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 110s 529ms/step - loss: 0.2660 - accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 113s 543ms/step - loss: 0.2306 - accuracy: 0.9096\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 112s 528ms/step - loss: 0.2344 - accuracy: 0.9154\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 113s 543ms/step - loss: 0.1659 - accuracy: 0.9421\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 108s 517ms/step - loss: 0.1717 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 113s 543ms/step - loss: 0.1415 - accuracy: 0.9535\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 110s 518ms/step - loss: 0.1360 - accuracy: 0.9549\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 115s 543ms/step - loss: 0.1567 - accuracy: 0.9433\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 110s 526ms/step - loss: 0.1192 - accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 113s 543ms/step - loss: 0.0956 - accuracy: 0.9723\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 110s 527ms/step - loss: 0.0875 - accuracy: 0.9748\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 113s 543ms/step - loss: 0.0685 - accuracy: 0.9822\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7004 - accuracy: 0.7906\n",
      "209/209 [==============================] - 105s 506ms/step - loss: 0.0795 - accuracy: 0.9769\n",
      "105/105 [==============================] - 4s 33ms/step - loss: 0.7179 - accuracy: 0.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "2024-10-11 05:18:09.978574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.004126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.004162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 05:18:10.005071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 05:18:10.007823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.007849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.007861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.109508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.109546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.109549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-11 05:18:10.109565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-11 05:18:10.109585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2777 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-11 05:18:10.869314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-10-11 05:18:10.933363: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb9054c4b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-11 05:18:10.933385: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-11 05:18:10.936162: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-11 05:18:10.971286: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 92s 146ms/step - loss: 0.6666 - accuracy: 0.5829\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4793 - accuracy: 0.7810\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 90s 143ms/step - loss: 0.3707 - accuracy: 0.8336\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 90s 143ms/step - loss: 0.3215 - accuracy: 0.8632\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.2970 - accuracy: 0.8737\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 90s 143ms/step - loss: 0.2819 - accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 90s 143ms/step - loss: 0.2708 - accuracy: 0.8884\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 90s 143ms/step - loss: 0.2637 - accuracy: 0.8905\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.2593 - accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.2599 - accuracy: 0.8958\n",
      "Best parameters found: {'rnn_units': 32, 'optimizer': 'rmsprop', 'epochs': 10, 'embedding_dim': 16, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "\n",
    "# RNN 모델 정의\n",
    "def build_rnn_model(input_dim, output_dim=1, rnn_units=32, embedding_dim=32, input_length=222, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=output_dim))\n",
    "    model.add(SimpleRNN(rnn_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# KerasClassifier로 모델 래핑\n",
    "input_dim = 5000  # 단어 사전 크기 (예시로 5000)\n",
    "input_length = 222  # 문장의 최대 길이\n",
    "model = KerasClassifier(\n",
    "    build_fn=build_rnn_model,  # 모델 생성 함수\n",
    "    input_dim=input_dim,\n",
    "    input_length=input_length,\n",
    "    verbose=1  # 훈련 과정 출력\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 검색 공간 정의\n",
    "param_dist = {\n",
    "    'rnn_units': [16, 32, 64],       # RNN 유닛 수\n",
    "    'embedding_dim': [16, 32, 64],   # 임베딩 차원 수\n",
    "    'optimizer': ['adam', 'rmsprop'], # 옵티마이저 선택\n",
    "    'epochs': [5, 10],                # 에포크 수\n",
    "    'batch_size': [16, 32]            # 배치 크기\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 설정\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # 시도할 하이퍼파라미터 조합 개수\n",
    "    cv=3,       # 교차검증 folds 수\n",
    "    verbose=1,\n",
    "    n_jobs=2,  # 가능한 모든 CPU 코어 사용\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 예시 (여기서는 이미 전처리된 X_train_pad와 y_train 사용)\n",
    "random_search.fit(X_train_pad, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 출력\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593533.878845   66658 service.cc:146] XLA service 0x7f768c00ae10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593533.878869   66658 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:13.892188: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:13.965555: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:52:15.156135: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng55{k2=8,k13=1,k14=3,k18=1,k22=0,k23=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593535.422283   66627 service.cc:146] XLA service 0x7f3be8006a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593535.422304   66627 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:15.435579: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:15.509716: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:52:16.707420: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng56{k2=8,k12=1,k13=1,k14=3,k15=0,k17=16,k18=1,k22=0,k23=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593536.953296   66691 service.cc:146] XLA service 0x7ff9e80051e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593536.953318   66691 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:16.966355: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:17.041365: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:52:18.230448: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng35{k2=5,k5=2,k14=6} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593538.517703   66611 service.cc:146] XLA service 0x7f0f14003b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593538.517725   66611 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:18.530673: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:18.604129: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:52:19.307501: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.151586763s\n",
      "Trying algorithm eng55{k2=8,k13=1,k14=3,k18=1,k22=0,k23=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:19.775403: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng35{k2=2,k3=0} for conv (f32[64,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593539.921965   66658 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:52:20.828405: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.121110869s\n",
      "Trying algorithm eng56{k2=8,k12=1,k13=1,k14=3,k15=0,k17=16,k18=1,k22=0,k23=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:21.299968: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[10,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593541.420543   66627 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:52:22.363012: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.132761322s\n",
      "Trying algorithm eng35{k2=5,k5=2,k14=6} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:22.837810: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k2=2,k6=0,k13=2,k14=0,k22=1} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[64,11,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593542.966587   66691 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:52:23.903552: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.128225818s\n",
      "Trying algorithm eng35{k2=2,k3=0} for conv (f32[64,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:24.377503: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=4,k3=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[64,11,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593544.541532   66611 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:52:25.426704: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.126814189s\n",
      "Trying algorithm eng0{} for conv (f32[10,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:26.953830: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.116168548s\n",
      "Trying algorithm eng48{k2=2,k6=0,k13=2,k14=0,k22=1} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[64,11,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:28.483378: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.106076024s\n",
      "Trying algorithm eng28{k2=4,k3=0} for conv (f32[1,64,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[64,11,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "2024-10-10 22:52:38.569613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:52:38.577880: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:52:38.580317: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:52:38.586266: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:52:38.969087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593559.367625   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.380169   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.380223   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.382429   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.382468   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.382481   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.497789   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593559.497838   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:39.497845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593559.497870   69812 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:39.497882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-10 22:52:41.194183: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:52:43.712125: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.51799259s\n",
      "Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593563.786485   70047 service.cc:146] XLA service 0x7f8fdc00a7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593563.786529   70047 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:43.800439: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:43.884509: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:52:44.310911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:52:44.320170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:52:44.322672: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:52:44.328855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:52:44.708665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "I0000 00:00:1728593564.773989   70047 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593565.196129   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.213430   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.213517   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.216249   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.216305   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.216334   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.406385   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593565.406445   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:45.406454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593565.406484   70547 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:45.406497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5850 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-10 22:52:45.646482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:52:45.655114: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:52:45.657638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:52:45.663735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:52:46.043471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593566.463719   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.476762   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.476812   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.478653   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.478692   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.478705   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.601402   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593566.601472   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:46.601483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593566.601508   70676 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:46.601529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5837 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-10 22:52:46.729294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:52:46.737655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:52:46.740103: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:52:46.746129: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:52:47.126289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593567.448805   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.461419   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.461472   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.463687   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.463722   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.463735   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.582726   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593567.582781   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:47.582789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593567.582814   70804 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:52:47.582825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593568.390378   70757 service.cc:146] XLA service 0x7f155c004d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593568.390404   70757 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:48.403314: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:48.477521: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593569.336699   70757 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593570.042469   70917 service.cc:146] XLA service 0x7f7c0000ab70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593570.042497   70917 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:50.055720: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:50.200668: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593570.997091   70917 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593576.796810   71192 service.cc:146] XLA service 0x7f41bc00ae30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593576.796831   71192 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:52:56.809996: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:52:56.884796: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593577.656774   71192 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:53:19.936927: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=3,k3=0} for conv (f32[32,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:53:22.130390: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.19357831s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv (f32[32,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:53:23.252287: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:24.243309: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k2=2,k6=0,k13=2,k14=0,k22=2} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[64,64,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:25.028110: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.7759217s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:25.728781: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:26.562287: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.319215502s\n",
      "Trying algorithm eng48{k2=2,k6=0,k13=2,k14=0,k22=2} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[64,64,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:27.940642: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.211930744s\n",
      "Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:53:37.269026: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[64,32,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[32,1,1,3]{3,2,1,0}, f32[32]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:38.556155: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k2=15,k6=0,k13=0,k14=0,k22=1} for conv (f32[1,32,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[32,64,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:39.310516: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.041573695s\n",
      "Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[64,32,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[32,1,1,3]{3,2,1,0}, f32[32]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:40.856619: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.300564741s\n",
      "Trying algorithm eng48{k2=15,k6=0,k13=0,k14=0,k22=1} for conv (f32[1,32,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[32,64,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:53:55.637295: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=4,k3=0} for conv (f32[5,32,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,1,1,222]{3,2,1,0}, f32[32,1,1,3]{3,2,1,0}, f32[32]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:53:57.909466: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.272240161s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv (f32[5,32,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,1,1,222]{3,2,1,0}, f32[32,1,1,3]{3,2,1,0}, f32[32]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:54:01.133399: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k2=2,k6=0,k13=1,k14=0,k22=1} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:54:03.421672: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.28841298s\n",
      "Trying algorithm eng48{k2=2,k6=0,k13=1,k14=0,k22=1} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:54:05.453468: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:54:07.681509: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.228115349s\n",
      "Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:54:22.899930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:54:22.908705: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:54:22.912043: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:54:22.918129: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:54:23.364295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593663.935040   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593663.948013   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593663.948072   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593663.950058   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593663.950092   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593663.950106   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593664.045558   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593664.045615   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:54:24.045622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593664.045647   84147 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:54:24.045670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593672.002438   84345 service.cc:146] XLA service 0x7f567800af70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593672.002462   84345 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:54:32.016373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:54:32.090330: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1728593677.486990   84345 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:54:38.889864: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:54:42.306379: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.416613442s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:54:53.786676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:54:53.795501: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:54:53.798013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:54:53.804114: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:54:54.177798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593694.965545   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593694.979136   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593694.979194   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593694.982291   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593694.982345   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593694.982361   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593695.075475   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593695.075534   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:54:55.075542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593695.075567   86529 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:54:55.075580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1248 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593696.002219   86736 service.cc:146] XLA service 0x7f84c400a0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593696.002244   86736 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:54:56.015794: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:54:56.295528: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:54:59.926824: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593700.309925   86736 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:55:01.971320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:55:01.979816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:55:01.982404: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:55:01.988443: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:55:02.102209: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=1,k3=0} for conv (f32[1,32,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[32,11,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:02.426273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-10 22:55:02.494264: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.567519635s\n",
      "Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:02.630651: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.528729926s\n",
      "Trying algorithm eng28{k2=1,k3=0} for conv (f32[1,32,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[32,11,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593702.776271   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.789266   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.789320   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.791431   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.791468   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.791483   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.876860   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593702.876919   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:55:02.876927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593702.876954   87564 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:55:02.876969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2050 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-10-10 22:55:04.545813: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=3,k3=0} for conv (f32[1,16,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,10,1,222]{3,2,1,0}, f32[16,10,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:05.541316: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.995569586s\n",
      "Trying algorithm eng28{k2=3,k3=0} for conv (f32[1,16,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,10,1,222]{3,2,1,0}, f32[16,10,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:06.390846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:55:06.399341: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:55:06.401851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:55:06.407890: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:55:06.795690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593706.927338   87732 service.cc:146] XLA service 0x7ff51400a6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593706.927360   87732 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:55:06.940398: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:55:07.040875: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593707.180443   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.193062   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.193117   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.196393   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.196502   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.196521   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.309176   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593707.309235   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:55:07.309243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593707.309269   88132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:55:07.309282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1728593707.872298   87732 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593711.533483   88487 service.cc:146] XLA service 0x7f2eb400aa40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593711.533505   88487 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:55:11.546263: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:55:11.620871: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:55:11.866931: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1728593712.407699   88487 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:55:13.641549: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.774724724s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:15.165873: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=1,k3=0} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:16.370831: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.205040441s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:55:39.195881: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:55:40.914798: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.718993885s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv (f32[11,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:55:51.916441: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng41{k2=0,k12=6,k13=2,k14=3,k15=0,k17=5,k18=1,k22=0,k23=0} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:53.783730: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.867373345s\n",
      "Trying algorithm eng41{k2=0,k12=6,k13=2,k14=3,k15=0,k17=5,k18=1,k22=0,k23=0} for conv (f32[1,64,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,1,222]{3,2,1,0}, f32[64,32,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:55:55.798184: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:55:57.687843: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.889725339s\n",
      "Trying algorithm eng0{} for conv (f32[10,64,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,3]{3,2,1,0}, f32[64]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:56:31.495044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:56:31.503785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:56:31.506252: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:56:31.512344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:56:31.888669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593792.306694  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.322156  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.322246  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.324674  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.324787  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.324825  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.432319  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593792.432373  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:56:32.432380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593792.432405  100050 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:56:32.432417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593800.225390  100319 service.cc:146] XLA service 0x7f80ac003940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593800.225413  100319 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:56:40.238664: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:56:40.318483: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-10 22:56:40.839277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:56:40.848244: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:56:40.850818: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:56:40.857155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1728593801.152305  100319 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:56:41.271934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593801.580158  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.594335  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.594398  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.598234  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.598277  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.598291  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.749500  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593801.749546  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:56:41.749554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593801.749577  101703 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:56:41.749588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1640 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593802.736297  101905 service.cc:146] XLA service 0x7f9ca4004160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593802.736323  101905 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:56:42.750163: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:56:42.914566: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593805.913795  101905 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-10-10 22:56:47.769547: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:56:48.872028: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.102602937s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,5]{3,2,1,0}, f32[16]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:56:52.068788: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[64,16,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[16,1,1,3]{3,2,1,0}, f32[16]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:56:53.690839: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.622139857s\n",
      "Trying algorithm eng20{k2=2,k4=0,k5=0,k6=0,k7=0,k19=0} for conv (f32[64,16,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,1,222]{3,2,1,0}, f32[16,1,1,3]{3,2,1,0}, f32[16]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:56:55.700210: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=4,k3=0} for conv (f32[1,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[16,11,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:56:57.456794: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.75667818s\n",
      "Trying algorithm eng28{k2=4,k3=0} for conv (f32[1,16,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,11,1,222]{3,2,1,0}, f32[16,11,1,220]{3,2,1,0}), window={size=1x220}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:00.600960: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,3]{3,2,1,0}, f32[16]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:02.276140: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.675241369s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv (f32[11,16,1,220]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,1,222]{3,2,1,0}, f32[16,1,1,3]{3,2,1,0}, f32[16]{0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:02.667417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:57:02.676057: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:57:02.678694: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:57:02.684976: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 22:57:03.077386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593823.490690  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.503780  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.503835  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.506401  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.506471  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.506485  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.625881  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593823.625934  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:57:03.625941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593823.625966  104823 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:57:03.625979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593830.270434  105170 service.cc:146] XLA service 0x7fabe80044f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593830.270460  105170 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:57:10.283485: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:57:10.358088: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593831.206169  105170 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:57:13.850328: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=0,k3=0} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[32,64,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:15.622514: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.772266818s\n",
      "Trying algorithm eng28{k2=0,k3=0} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,222]{3,2,1,0}, f32[32,64,1,218]{3,2,1,0}), window={size=1x218}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:57:36.468597: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:57:38.192123: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.723606786s\n",
      "Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-10 22:57:40.227047: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[10,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:41.956887: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.730011128s\n",
      "Trying algorithm eng0{} for conv (f32[10,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:54.215578: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-10-10 22:57:55.954206: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.738702003s\n",
      "Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv (f32[32,64,1,218]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,1,222]{3,2,1,0}, f32[64,1,1,5]{3,2,1,0}, f32[64]{0}), window={size=1x5}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593885.391623   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.404467   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.404523   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.407385   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.407415   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.407432   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.486277   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728593885.486350   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:58:05.486366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728593885.486421   66027 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-10 22:58:05.486445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3146 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728593886.390291  113610 service.cc:146] XLA service 0x7f55800057f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728593886.390314  113610 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-10-10 22:58:06.403868: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-10 22:58:06.480968: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1728593887.281531  113610 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'model__pool_size': 3, 'model__learning_rate': 0.001, 'model__kernel_size': 3, 'model__filters': 64, 'model__dropout_rate': 0.25, 'epochs': 10, 'batch_size': 64}\n",
      "Best accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_model(filters=32, kernel_size=3, pool_size=2, dropout_rate=0.25, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(222, 1)),\n",
    "        MaxPooling1D(pool_size=pool_size),\n",
    "        Dropout(dropout_rate),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# CNN 모델을 KerasClassifier로 래핑\n",
    "model = KerasClassifier(model=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# 하이퍼파라미터 범위 설정\n",
    "param_dist = {\n",
    "    'model__filters': [16, 32, 64],\n",
    "    'model__kernel_size': [3, 5],\n",
    "    'model__pool_size': [2, 3],\n",
    "    'model__dropout_rate': [0.25, 0.5],\n",
    "    'model__learning_rate': [0.001, 0.0001],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# 입력 데이터의 차원 확장\n",
    "X_train_cnn = np.expand_dims(X_train_pad, axis=2)\n",
    "\n",
    "# RandomizedSearchCV 설정\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=20, cv=3, verbose=1, n_jobs=4, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "random_search_result = random_search.fit(X_train_cnn, y_train)\n",
    "\n",
    "# 최적 하이퍼파라미터 출력\n",
    "print(f\"Best parameters found: {random_search_result.best_params_}\")\n",
    "print(f\"Best accuracy: {random_search_result.best_score_:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
