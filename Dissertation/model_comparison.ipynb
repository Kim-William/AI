{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2202,"status":"ok","timestamp":1729617377222,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"DBPl837LuuGc","notebookRunGroups":{"groupValue":"1"},"outputId":"dda84084-24df-49fe-98aa-c6fa294f52da"},"outputs":[],"source":["import sys\n","sys.path.append('models')\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# sys.path.append('/content/drive/MyDrive/Dissertation/models')\n","# sys.path.append('/content/drive/MyDrive/Dissertation')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":12698,"status":"ok","timestamp":1729617389918,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"i_OV5qsByAR9","outputId":"83d88c51-58fc-487e-c400-7f94331f6e30"},"outputs":[],"source":["# !pip install dask_ml\n","# !pip install scikeras\n","# import nltk\n","# nltk.download('stopwords')\n","# import nltk\n","# nltk.download('punkt')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12703,"status":"ok","timestamp":1729617402618,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"Z6z3aV1muuGd","outputId":"ba7817cf-f945-4c0a-bc51-0cd9c7fa467d"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-23 13:32:33.608474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-23 13:32:33.616999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-23 13:32:33.619508: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-23 13:32:33.626026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-10-23 13:32:34.011696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  1\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1729683155.133688  355331 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","I0000 00:00:1729683155.137303  355331 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","I0000 00:00:1729683155.137342  355331 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n"]}],"source":["# importing libraries\n","import joblib\n","import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score\n","import tensorflow as tf\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","\n","from logstic_regression import Logistic_Regression\n","from XGBoost import XGBoost\n","from naive_bayes import Naive_Bayes\n","from rnn import RNN\n","from cnn import CNN\n","# from models.bert import BERT\n","from bilstm import BiLSTM\n","\n","# Load the TextPreprocessor class (assumed to be defined already)\n","from textpreprocessor import TextPreprocessor\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Set memory growth\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729617402618,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"wyNS08hbuuGe"},"outputs":[],"source":["NUM_SAMPLE = 10000\n","TEST_RATIO=0.2\n","BATCH_SIZE=32\n","EPOCHS = 5\n","MAX_WORD_COUNT = 5000\n","MAX_LENGTH = 100\n","OUTPUT_RESULT_DIR = \"Output/result\"\n","OUTPUT_MODELS_DIR = \"Output/models\"\n","USE_TEST_DATA = True\n","\n","os.makedirs(OUTPUT_RESULT_DIR, exist_ok=True)\n","os.makedirs(OUTPUT_MODELS_DIR, exist_ok=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729617402618,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"cIAG1a-CuuGe","notebookRunGroups":{"groupValue":"2"}},"outputs":[],"source":["# Define a function to plot training history\n","def plot_training_history(history, title=\"Model Training History\"):\n","    # Extract values from history\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs = range(1, len(acc) + 1)\n","\n","    # Plot training and validation accuracy\n","    plt.figure(figsize=(14, 5))\n","\n","    # Accuracy plot\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","    plt.title(f\"{title} - Accuracy\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Loss plot\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, loss, 'b', label='Training Loss')\n","    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","    plt.title(f\"{title} - Loss\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Function to plot training history from defaultdict data\n","def plot_training_history_from_dict(history, title=\"Model Training History\"):\n","    # Extract values from the dictionary\n","    acc = history['accuracy']\n","    val_acc = history['val_accuracy']\n","    loss = history['loss']\n","    val_loss = history['val_loss']\n","\n","    # Set up epoch range\n","    epochs = range(1, len(acc) + 1)\n","\n","    # Plot training and validation accuracy\n","    plt.figure(figsize=(14, 5))\n","\n","    # Accuracy plot\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","    plt.title(f\"{title} - Accuracy\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Loss plot\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, loss, 'b', label='Training Loss')\n","    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","    plt.title(f\"{title} - Loss\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Dictionary to store the results\n","results = {\n","    'Model': [],\n","    'Training-Time':[],\n","    'Accuracy': [],\n","    'Precision (Class 0)': [],\n","    'Precision (Class 1)': [],\n","    'Recall (Class 0)': [],\n","    'Recall (Class 1)': [],\n","    'F1-Score (Class 0)': [],\n","    'F1-Score (Class 1)': []\n","}\n","\n","# Function to calculate accuracy and classification report\n","def _evaluate_model(training_time, model_name, y_test, y_pred):\n","    accuracy = accuracy_score(y_test, y_pred) * 100\n","    report = classification_report(y_test, y_pred, output_dict=True)\n","\n","    # Store the results\n","    results['Model'].append(model_name)\n","    results['Training-Time'].append(training_time)\n","    results['Accuracy'].append(accuracy)\n","    results['Precision (Class 0)'].append(report['0']['precision'])\n","    results['Precision (Class 1)'].append(report['1']['precision'])\n","    results['Recall (Class 0)'].append(report['0']['recall'])\n","    results['Recall (Class 1)'].append(report['1']['recall'])\n","    results['F1-Score (Class 0)'].append(report['0']['f1-score'])\n","    results['F1-Score (Class 1)'].append(report['1']['f1-score'])\n","\n","def _predict_model(model,X):\n","    y_pred_prob = model.predict(X)\n","    return [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n","\n","def evaluate_model_class(model_class, X_test, y_test):\n","    y_pred = _predict_model(model_class.model, X_test)\n","    y_pred_random = _predict_model(model_class.random_search_cv.best_estimator_, X_test)\n","    y_pred_grid = _predict_model(model_class.grid_search_cv.best_estimator_, X_test)\n","    y_pred_best = _predict_model(model_class.best_model, X_test)\n","\n","    _evaluate_model(model_class.training_time, model_class.model_name, y_test, y_pred)\n","    _evaluate_model(model_class.random_search_time,  model_class.model_name + '_random_search', y_test, y_pred_random)\n","    _evaluate_model(model_class.grid_search_time,  model_class.model_name + '_grid_search', y_test, y_pred_grid)\n","    _evaluate_model(model_class.best_training_time,  model_class.model_name + '_best', y_test, y_pred_best)\n","\n","    df_results = pd.DataFrame(results)\n","    df_results.to_excel(os.path.join(OUTPUT_RESULT_DIR,'Model_Compare.xlsx'))\n","\n","def evaluate_xgboost_model_class(model_class, X_test, y_test):\n","    y_pred_xgb = _predict_model(model_class.model, model_class.convert_to_dmatrix(X_test, y_test))\n","    y_pred_xgb_random = _predict_model(model_class.random_search_cv.best_estimator_, X_test.toarray())\n","    y_pred_xgb_grid = _predict_model(model_class.grid_search_cv.best_estimator_, X_test.toarray())\n","    y_pred_xgb_best = _predict_model(model_class.best_model, model_class.convert_to_dmatrix(X_test, y_test))\n","\n","    # Call the function with your actual predictions (replace placeholders with your data)\n","    _evaluate_model(model_class.training_time, model_class.model_name, y_test, y_pred_xgb)\n","    _evaluate_model(model_class.random_search_time,  model_class.model_name + '_random_search', y_test, y_pred_xgb_random)\n","    _evaluate_model(model_class.grid_search_time,  model_class.model_name + '_grid_search', y_test, y_pred_xgb_grid)\n","    _evaluate_model(model_class.best_training_time,  model_class.model_name + '_best', y_test, y_pred_xgb_best)\n","\n","    df_results = pd.DataFrame(results)\n","    df_results.to_excel(os.path.join(OUTPUT_RESULT_DIR,'Model_Compare.xlsx'), index=False)\n","\n","def compare_models_accuracy_and_get_best_params(models, X_test, y_test):\n","    best_accuracy = 0\n","    best_params = None\n","    best_model_name = None\n","\n","    for model_name, model_class in models.items():\n","        # Get model's parameters (either from random search CV or from original model)\n","        if model_name!='Original':  # Check if it has random_search_cv\n","            y_pred_prob = model_class.predict(X_test)\n","            params = model_class.best_params_\n","        else:\n","            y_pred_prob = model_class.predict(X_test)\n","            params = model_class.get_params()\n","\n","        # Convert probabilities to binary predictions\n","        pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n","\n","        # Calculate accuracy\n","        accuracy = accuracy_score(y_test, pred) * 100\n","        print(f'{model_name} Accuracy: {accuracy}')\n","\n","        # Compare and keep track of the model with the highest accuracy\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = params\n","            best_model_name = model_name\n","\n","    print(f'Best Model: {best_model_name} with Accuracy: {best_accuracy}')\n","    print(f'Best Parameters: {best_params}')\n","    return best_model_name, best_params\n"]},{"cell_type":"markdown","metadata":{"id":"V57jKpwbuuGe"},"source":["00. Text Pre-Processing"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":596811,"status":"ok","timestamp":1729617999426,"user":{"displayName":"김웅걸","userId":"04955122552547240370"},"user_tz":-120},"id":"sS7ho_aUuuGf","notebookRunGroups":{"groupValue":"1"},"outputId":"cdbf39a1-a42c-4130-a603-1a934d5fbf3f"},"outputs":[],"source":["# Initialize the Text Preprocessor\n","processor = TextPreprocessor(MAX_WORD_COUNT, MAX_LENGTH)\n","\n","if USE_TEST_DATA:\n","    INPUT_DIR = f\"Output/proto_models_rev2_{NUM_SAMPLE}\"\n","    # Load data\n","    df_train = pd.read_csv(os.path.join(INPUT_DIR, 'train_cleaned.csv'))\n","    df_test = pd.read_csv(os.path.join(INPUT_DIR, 'test_cleaned.csv'))\n","    # df_test = processor.load_data()\n","    X_train = df_train['review']\n","    X_test = df_test['review']\n","    y_train = df_train['polarity']\n","    y_test = df_test['polarity']\n","    # X_train_seq_padded = pickle.load(os.path.join(INPUT_DIR, 'X_train_pad.pkl'))\n","    # X_test_seq_padded = pickle.load(os.path.join(INPUT_DIR, 'X_test_pad.pkl'))\n","else:\n","    # Load data\n","    df_train, df_test = processor.parallel_load_data()\n","\n","    df_train_step1 = processor.remove_stopwords(df_train.copy())\n","    df_test_step1 = processor.remove_stopwords(df_test.copy())\n","\n","    print('----------TRAIN DATA----------')\n","    df_train_step2 = processor.filter_by_length_of_sentence(df_train_step1.copy(),50)\n","    print('----------TEST DATA----------')\n","    df_test_step2 = processor.filter_by_length_of_sentence(df_test_step1.copy(),50)\n","\n","    df_train_step3 = processor.sampling_data(df_train_step2, NUM_SAMPLE)\n","    df_test_step3 = processor.sampling_data(df_test_step2, int(NUM_SAMPLE*TEST_RATIO))\n","\n","    # Preprocess data\n","    df_train_step3 = processor.map_polarity(df_train_step3.copy())\n","    df_test_step3 = processor.map_polarity(df_test_step3.copy())\n","\n","    # Split data\n","    X_train, y_train = processor.split_data(df_train_step3)\n","    X_test, y_test = processor.split_data(df_test_step3)\n","    \n","    INPUT_DIR = f\"Output/proto_models_rev2_{NUM_SAMPLE}\"\n","    os.makedirs(INPUT_DIR, exist_ok=True)\n","    # Save data\n","    df_train_step3.to_csv(os.path.join(INPUT_DIR, 'train_cleaned.csv'), index=False)\n","    df_test_step3.to_csv(os.path.join(INPUT_DIR, 'test_cleaned.csv'), index=False)\n","\n","X_train_tfidf, X_test_tfidf = processor.vectorize_text(X_train, X_test)\n","X_train_pad, X_test_pad = processor.tokenization_and_padding(X_train, X_test)\n","\n","MAX_LENGTH = processor.max_length"]},{"cell_type":"markdown","metadata":{"id":"0rTu0za1uuGf"},"source":["01. Logistic Regression\n","\n",">Original Accuracy: 85.42\n","<br>\n",">RandomizedSearchCV Accuracy: 85.42\n","<br>\n",">ElasticNet Accuracy: 85.45\n","<br>\n",">Best Model: ElasticNet with Accuracy: 85.45\n","<br>\n","Best Parameters: {'tol': 0.01, 'solver': 'saga', 'penalty': 'elasticnet', 'max_iter': 100, 'l1_ratio': 0.1, 'class_weight': None, 'C': 1.291549665014884}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"FODwm-oguuGg","outputId":"3155f0d1-fae4-4639-ab4a-465193541b95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 1500 candidates, totalling 15000 fits\n"]},{"name":"stderr","output_type":"stream","text":["/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/woong/AI/Dissertation/.venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["# 1. Train Model\n","logistic_regression = Logistic_Regression(verbose=1)\n","logistic_regression.train_model(X_train_tfidf, y_train)\n","\n","# 2. Random SearchCV\n","logistic_regression.random_search(X_train_tfidf, y_train, n_iter=1500, cv=10, random_state=42, n_jobs=-1)\n","logistic_regression.random_search_elasticnet(X_train_tfidf, y_train, n_iter=1500, cv=10, random_state=42, n_jobs=-1)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': logistic_regression.model,\n","                                                              'RandomizedSearchCV': logistic_regression.random_search_cv,\n","                                                              'ElasticNet': logistic_regression.random_search_cv_elasticnet}, X_test_tfidf, y_test)\n","\n","# 3. Grid SearchCV\n","logistic_regression.grid_search(X_train_tfidf, y_train, cv=10, n_jobs=-1,best_params=best_params)\n","\n","# 4. Train Best Model\n","logistic_regression.train_best_model(X_train_tfidf, y_train, logistic_regression.grid_search_cv.best_params_)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(logistic_regression,X_test_tfidf, y_test)\n","\n","logistic_regression.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'logistic_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'logistic_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'logistic_best_params.pkl')\n","    )"]},{"cell_type":"markdown","metadata":{"id":"Su5DcarbuuGg"},"source":["02. XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_xq1fsBFuuGg"},"outputs":[],"source":["# 1. Train Model\n","xgboost = XGBoost(verbose=1)\n","xgboost.train_model(X_train_tfidf, y_train)\n","\n","X_train_tfidf = X_train_tfidf.astype(np.float32)\n","\n","# 2. Random SearchCV\n","xgboost.random_search(X_train_tfidf, y_train, n_iter=2000, cv=10, random_state=42, n_jobs=-1)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': xgboost.model,\n","                                                              'RandomizedSearchCV': xgboost.random_search_cv}, X_test_tfidf.toarray(), y_test)\n","\n","# 3. Grid SearchCV\n","xgboost.grid_search(X_train_tfidf, y_train, cv=10,  n_jobs=-1, best_params=best_params)\n","\n","# 4. Train Best Model\n","xgboost.train_best_model(X_train_tfidf, y_train, xgboost.grid_search_cv.best_params_)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(xgboost, X_test_tfidf, y_test)\n","\n","xgboost.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'xgboost_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'xgboost_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'xgboost_best_params.pkl')\n","    )"]},{"cell_type":"markdown","metadata":{"id":"5zvDKipKuuGg"},"source":["03. Naive Bayes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILvKnsXBuuGg"},"outputs":[],"source":["# 1. Train Model\n","naive_bayes = Naive_Bayes(verbose=1)\n","naive_bayes.train_model(X_train_tfidf, y_train)\n","\n","# 2. Random SearchCV\n","# naive_bayes.random_search(X_train_tfidf, y_train, n_iter=30, cv=2, verbos=0, random_state=42, n_jobs=-1)\n","naive_bayes.random_search(X_train_tfidf, y_train, n_iter=5000, cv=10, random_state=42, n_jobs=-1)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': naive_bayes.model,\n","                                                              'RandomizedSearchCV': naive_bayes.random_search_cv}, X_test_tfidf, y_test)\n","\n","# 3. Grid SearchCV\n","# naive_bayes.grid_search(X_train_tfidf, y_train, naive_bayes.random_search_cv.best_params_, cv=2, verbos=1, n_jobs=-1)\n","naive_bayes.grid_search(X_train_tfidf, y_train, best_params=best_params, cv=10, n_jobs=-1)\n","\n","# 4. Train Best Model\n","naive_bayes.train_best_model(X_train_tfidf, y_train, naive_bayes.grid_search_cv.best_params_)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(naive_bayes,X_test_tfidf, y_test)\n","\n","naive_bayes.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'naivebayes_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'naivebayes_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'naivebayes_best_params.pkl')\n","    )"]},{"cell_type":"markdown","metadata":{"id":"WCN9So82uuGg"},"source":["04. Recurrent Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqA7WNHfuuGg"},"outputs":[],"source":["# 1. Train Model\n","rnn = RNN(max_feature=5000, max_length=100, epochs=10, batch_size=64, output_dim=128, optimizer='adam', embedding_dim=32, rnn_unit=64, verbose=1)\n","rnn.train_model(X_train_pad, y_train, validation_data=(X_test_pad, y_test))\n","\n","# 2. Random SearchCV\n","rnn.random_search(X_train_pad, y_train, (X_test_pad, y_test), n_iter=3000, cv=10,  random_state=42, n_jobs=1)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': rnn.model,\n","                                                              'RandomizedSearchCV': rnn.random_search_cv}, X_test_pad, y_test)\n","\n","# 3. Grid SearchCV\n","rnn.grid_search(X_train_pad, y_train, (X_test_pad, y_test), cv=10, n_jobs=1, best_params=best_params)\n","\n","# 4. Train Best Model\n","rnn.train_best_model(X_train_pad,y_train, validation_data=(X_test_pad, y_test), best_params= rnn.grid_search_cv.best_params_)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(rnn,X_test_pad, y_test)\n","\n","rnn.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'rnn_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'rnn_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'rnn_best_params.pkl')\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyqA4BvquuGh"},"outputs":[],"source":["# Plot for hist\n","plot_training_history_from_dict(rnn.model.history_, title=\"Initial Model Training History\")\n","\n","# Plot the training history from defaultdict data\n","plot_training_history_from_dict(rnn.best_model.history_, title=\"Best Model Training History\")"]},{"cell_type":"markdown","metadata":{"id":"8BCslbNLuuGh"},"source":["05. Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CEdqScLuuuGh"},"outputs":[],"source":["# 1. Train Model\n","cnn = CNN(max_feature=processor.max_features, max_length=processor.max_length, epochs=EPOCHS, batch_size=BATCH_SIZE, output_dim=128, optimizer='adam', embedding_dim=32, verbose=1)\n","cnn.train_model(X_train_pad, y_train, (X_test_pad, y_test))\n","\n","# 2. Random SearchCV\n","cnn.random_search(X_train_pad, y_train, (X_test_pad, y_test), n_iter=3000, cv=10, random_state=42, n_jobs=1, patience=3)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': cnn.model,\n","                                                              'RandomizedSearchCV': cnn.random_search_cv}, X_test_pad, y_test)\n","\n","# 3. Grid SearchCV\n","cnn.grid_search(X_train_pad, y_train, (X_test_pad, y_test), best_params=best_params, cv=10, n_jobs=1, patience=3)\n","\n","# 4. Train Best Model\n","cnn.train_best_model(X_train_pad, y_train, (X_test_pad, y_test), best_params=cnn.grid_search_cv.best_params_)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(cnn,X_test_pad, y_test)\n","\n","cnn.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'cnn_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'cnn_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'cnn_best_params.pkl')\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDd30ktyuuGh"},"outputs":[],"source":["# Plot for hist\n","plot_training_history_from_dict(cnn.model.history_, title=\"Initial Model Training History\")\n","\n","# Plot the training history from defaultdict data\n","plot_training_history_from_dict(cnn.best_model.history_, title=\"Best Model Training History\")"]},{"cell_type":"markdown","metadata":{"id":"cPbC8EiMuuGh"},"source":["06. Bidirectional Encoder Representations from Transformers(BERT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FrxQDKUuuGh"},"outputs":[],"source":["# bert = BERT(max_length=processor.max_features, epochs=1, batch_size=BATCH_SIZE, verbose=1)\n","# bert.train_model(X_train, y_train, X_test, y_test)\n","\n","# bert.random_search(X_train, y_train, X_test, y_test, max_trials=2, executions_per_trial=1, n_jobs=1)\n","\n","# # Predict on test data\n","# y_pred_prob = bert_model.predict({'input_ids': bert.X_test_tokens['input_ids'], 'attention_mask': bert.X_test_tokens['attention_mask']}).logits\n","# y_pred_bert = np.argmax(y_pred_prob, axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"upg3c1WRuuGh"},"source":["07. Bidirectional Long Short-Term Memory (BiLSTM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HLPsjV9uuGh"},"outputs":[],"source":["# 1. Train Model\n","bilstm = BiLSTM(processor.tokenizer, EPOCHS, BATCH_SIZE, verbose=1)\n","bilstm.train_model(X_train_pad, y_train, X_test_pad,y_test)\n","\n","# 2. Random SearchCV\n","bilstm.random_search(X_train_pad, y_train, X_test_pad,y_test, n_iter=3000, cv=10, random_state=42, n_jobs=1)\n","\n","_, best_params = compare_models_accuracy_and_get_best_params({'Original': bilstm.model,\n","                                                              'RandomizedSearchCV': bilstm.random_search_cv}, X_test_pad, y_test)\n","\n","# 3. Grid SearchCV\n","bilstm.grid_search(X_train_pad, y_train, X_test_pad, y_test, best_params= best_params, cv=10, n_jobs=1, patience=3)\n","\n","# 4. Train Best Model\n","bilstm.train_best_model(X_train_pad, y_train, X_test_pad, y_test, best_params=bilstm.grid_search_cv.best_params_, patience=3)\n","\n","# 5. Evaluate and Save Models\n","evaluate_model_class(bilstm,X_test_pad, y_test)\n","\n","bilstm.save_model_and_params(\n","    os.path.join(OUTPUT_MODELS_DIR, 'bilstm_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'bilstm_best_model.pkl'),\n","    os.path.join(OUTPUT_MODELS_DIR, 'bilstm_best_params.pkl')\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OqMYHQ4vuuGh"},"outputs":[],"source":["# Plot for hist\n","plot_training_history_from_dict(bilstm.model.history_, title=\"Initial Model Training History\")\n","\n","# Plot the training history from defaultdict data\n","plot_training_history_from_dict(bilstm.best_model.history_, title=\"Best Model Training History\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rdscrJAuuGh"},"outputs":[],"source":["df_results = pd.DataFrame(results)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":0}
