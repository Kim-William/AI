{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 15:03:55.329739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 15:03:55.338242: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 15:03:55.340835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 15:03:55.347610: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 15:03:56.123402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726664637.263709  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664637.294809  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664637.294847  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, Dropout, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "try:\n",
    "  import tensorflow.keras.backend as K\n",
    "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "except:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPUs found\")\n",
    "else:\n",
    "    print(f\"GPUs available: {gpus}\")\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "BATCH_SIZE = 64  # Batch size for training.\n",
    "EPOCHS = 3000  # Number of epochs to train for.\n",
    "LATENT_DIM = 512  # Latent dimensionality of the encoding space.\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: Output/Em100_Bat64_Epo3000\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = f'Em{EMBEDDING_DIM}_Bat{BATCH_SIZE}_Epo{EPOCHS}'\n",
    "\n",
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "PATH_DATA_ROOT = 'Input'\n",
    "PATH_SAVEMODEL_ROOT = os.path.join('Output/%s' % RUN_NAME)\n",
    "\n",
    "PATH_FILE_TRAIN = os.path.join('%s/WikiQA-train.tsv' % PATH_DATA_ROOT)\n",
    "PATH_FILE_TEST = os.path.join('%s/WikiQA-test.tsv' % PATH_DATA_ROOT)\n",
    "PATH_FILE_DEV = os.path.join('%s/WikiQA-dev.tsv' % PATH_DATA_ROOT)\n",
    "\n",
    "PATH_EMBEDDING = f'{PATH_DATA_ROOT}/glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "\n",
    "PATH_TOKENIZER_OUTPUT = os.path.join('%s/tokenizer_output.pickle' % PATH_SAVEMODEL_ROOT)\n",
    "PATH_TOKENIZER_INPUT = os.path.join('%s/tokenizer_input.pickle' % PATH_SAVEMODEL_ROOT)\n",
    "\n",
    "PATH_MODEL= os.path.join('%s/s2s.h5' % PATH_SAVEMODEL_ROOT)\n",
    "PATH_ENCODER_MODEL = os.path.join('%s/encoder_model.h5' % PATH_SAVEMODEL_ROOT)\n",
    "PATH_DECODER_MODEL = os.path.join('%s/decoder_model.h5' % PATH_SAVEMODEL_ROOT)\n",
    "\n",
    "PATH_SEQUENCE_FILE = os.path.join('%s/input_sequences.pkl' % PATH_SAVEMODEL_ROOT)\n",
    "PATH_TARGET_SEQUENCE_FILE = os.path.join('%s/target_sequences.pkl' % PATH_SAVEMODEL_ROOT)\n",
    "\n",
    "if not os.path.exists(PATH_SAVEMODEL_ROOT):\n",
    "    os.makedirs(PATH_SAVEMODEL_ROOT)\n",
    "    print(f'Folder has been created: {PATH_SAVEMODEL_ROOT}')\n",
    "else:\n",
    "    print(f\"Folder already exists: {PATH_SAVEMODEL_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filer_data_label0(data_frame):\n",
    "    filtered_data_frame = data_frame[data_frame['Label'] == 1]\n",
    "    return filtered_data_frame\n",
    "\n",
    "def filter_data_drop_na(data_frame, col):\n",
    "    filtered_data_frame = data_frame.dropna(subset=col)\n",
    "    return filtered_data_frame\n",
    "\n",
    "def drop_not_use_columns(data_frame):\n",
    "    data_frame.drop(columns=['QuestionID'], inplace=True)\n",
    "    data_frame.drop(columns=['DocumentID'], inplace=True)\n",
    "    data_frame.drop(columns=['DocumentTitle'], inplace=True)\n",
    "    data_frame.drop(columns=['SentenceID'], inplace=True)\n",
    "    return data_frame\n",
    "\n",
    "def drop_duplicate_rows(data_frame):\n",
    "    data_frame.drop_duplicates(subset='Question')\n",
    "    return data_frame\n",
    "\n",
    "def data_cleaning(data_frame):\n",
    "    cleaned_data_frame = filer_data_label0(data_frame)\n",
    "    cleaned_data_frame = filter_data_drop_na(cleaned_data_frame, 'Sentence')\n",
    "    cleaned_data_frame = drop_not_use_columns(cleaned_data_frame)\n",
    "    cleaned_data_frame = drop_duplicate_rows(cleaned_data_frame)\n",
    "    return cleaned_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>DocumentTitle</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-0</td>\n",
       "      <td>A partly submerged glacier cave on Perito More...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-1</td>\n",
       "      <td>The ice facade is approximately 60 m high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-2</td>\n",
       "      <td>Ice formations in the Titlis glacier cave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-3</td>\n",
       "      <td>A glacier cave is a cave formed within the ice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-4</td>\n",
       "      <td>Glacier caves are often called ice caves , but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20342</th>\n",
       "      <td>Q3043</td>\n",
       "      <td>what is section eight housing</td>\n",
       "      <td>D2807</td>\n",
       "      <td>Section 8 (housing)</td>\n",
       "      <td>D2807-8</td>\n",
       "      <td>A tenant who leaves a subsidized project will ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20343</th>\n",
       "      <td>Q3043</td>\n",
       "      <td>what is section eight housing</td>\n",
       "      <td>D2807</td>\n",
       "      <td>Section 8 (housing)</td>\n",
       "      <td>D2807-9</td>\n",
       "      <td>The United States Department of Housing and Ur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20344</th>\n",
       "      <td>Q3044</td>\n",
       "      <td>what is the main type of restaurant</td>\n",
       "      <td>D2808</td>\n",
       "      <td>Category:Types of restaurants</td>\n",
       "      <td>D2808-0</td>\n",
       "      <td>Restaurants categorized by type and informatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20345</th>\n",
       "      <td>Q3046</td>\n",
       "      <td>what is us dollar worth based on</td>\n",
       "      <td>D2810</td>\n",
       "      <td>History of the United States dollar</td>\n",
       "      <td>D2810-0</td>\n",
       "      <td>U.S. Federal Reserve notes in the mid-1990s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20346</th>\n",
       "      <td>Q3046</td>\n",
       "      <td>what is us dollar worth based on</td>\n",
       "      <td>D2810</td>\n",
       "      <td>History of the United States dollar</td>\n",
       "      <td>D2810-1</td>\n",
       "      <td>The history of the United States dollar covers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20347 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      QuestionID                             Question DocumentID  \\\n",
       "0             Q1        how are glacier caves formed?         D1   \n",
       "1             Q1        how are glacier caves formed?         D1   \n",
       "2             Q1        how are glacier caves formed?         D1   \n",
       "3             Q1        how are glacier caves formed?         D1   \n",
       "4             Q1        how are glacier caves formed?         D1   \n",
       "...          ...                                  ...        ...   \n",
       "20342      Q3043        what is section eight housing      D2807   \n",
       "20343      Q3043        what is section eight housing      D2807   \n",
       "20344      Q3044  what is the main type of restaurant      D2808   \n",
       "20345      Q3046     what is us dollar worth based on      D2810   \n",
       "20346      Q3046     what is us dollar worth based on      D2810   \n",
       "\n",
       "                             DocumentTitle SentenceID  \\\n",
       "0                             Glacier cave       D1-0   \n",
       "1                             Glacier cave       D1-1   \n",
       "2                             Glacier cave       D1-2   \n",
       "3                             Glacier cave       D1-3   \n",
       "4                             Glacier cave       D1-4   \n",
       "...                                    ...        ...   \n",
       "20342                  Section 8 (housing)    D2807-8   \n",
       "20343                  Section 8 (housing)    D2807-9   \n",
       "20344        Category:Types of restaurants    D2808-0   \n",
       "20345  History of the United States dollar    D2810-0   \n",
       "20346  History of the United States dollar    D2810-1   \n",
       "\n",
       "                                                Sentence  Label  \n",
       "0      A partly submerged glacier cave on Perito More...      0  \n",
       "1              The ice facade is approximately 60 m high      0  \n",
       "2              Ice formations in the Titlis glacier cave      0  \n",
       "3      A glacier cave is a cave formed within the ice...      1  \n",
       "4      Glacier caves are often called ice caves , but...      0  \n",
       "...                                                  ...    ...  \n",
       "20342  A tenant who leaves a subsidized project will ...      0  \n",
       "20343  The United States Department of Housing and Ur...      0  \n",
       "20344  Restaurants categorized by type and informatio...      0  \n",
       "20345        U.S. Federal Reserve notes in the mid-1990s      0  \n",
       "20346  The history of the United States dollar covers...      0  \n",
       "\n",
       "[20347 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(PATH_FILE_TRAIN, sep='\\t')\n",
    "data_test = pd.read_csv(PATH_FILE_TEST, sep='\\t')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>A glacier cave is a cave formed within the ice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>This tablespoon has a capacity of about 15 mL.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>In the USA one tablespoon (measurement unit) i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>In Australia one tablespoon (measurement unit)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>how much are the harry potter movies worth</td>\n",
       "      <td>The series also originated much tie-in merchan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20292</th>\n",
       "      <td>What is an economic feature?</td>\n",
       "      <td>At the turn of the 21st century, the expanding...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>what is the average american income</td>\n",
       "      <td>U.S. median household income fell from $51,144...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20325</th>\n",
       "      <td>When was Apple Computer founded</td>\n",
       "      <td>The company was founded on April 1, 1976, and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>what is section eight housing</td>\n",
       "      <td>Section 8 of the Housing Act of 1937 (), often...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>what is section eight housing</td>\n",
       "      <td>It operates through several programs, the larg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Question  \\\n",
       "3                   how are glacier caves formed?   \n",
       "75              how much is 1 tablespoon of water   \n",
       "83              how much is 1 tablespoon of water   \n",
       "84              how much is 1 tablespoon of water   \n",
       "98     how much are the harry potter movies worth   \n",
       "...                                           ...   \n",
       "20292                What is an economic feature?   \n",
       "20307         what is the average american income   \n",
       "20325             When was Apple Computer founded   \n",
       "20335               what is section eight housing   \n",
       "20336               what is section eight housing   \n",
       "\n",
       "                                                Sentence  Label  \n",
       "3      A glacier cave is a cave formed within the ice...      1  \n",
       "75        This tablespoon has a capacity of about 15 mL.      1  \n",
       "83     In the USA one tablespoon (measurement unit) i...      1  \n",
       "84     In Australia one tablespoon (measurement unit)...      1  \n",
       "98     The series also originated much tie-in merchan...      1  \n",
       "...                                                  ...    ...  \n",
       "20292  At the turn of the 21st century, the expanding...      1  \n",
       "20307  U.S. median household income fell from $51,144...      1  \n",
       "20325  The company was founded on April 1, 1976, and ...      1  \n",
       "20335  Section 8 of the Housing Act of 1937 (), often...      1  \n",
       "20336  It operates through several programs, the larg...      1  \n",
       "\n",
       "[1039 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_filtered = data_cleaning(data_train)\n",
    "data_test_filtered = data_cleaning(data_train)\n",
    "data_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 1039\n"
     ]
    }
   ],
   "source": [
    "# 리스트 초기화\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "target_texts_inputs = []\n",
    "\n",
    "for index, row in data_train_filtered.iterrows():\n",
    "    \n",
    "    input_text = row['Question'].strip()\n",
    "    target = row['Sentence'].strip()\n",
    "\n",
    "    # 목표 텍스트 생성\n",
    "    target_text = target + ' <eos>'  \n",
    "    target_text_input = '<sos> ' + target  \n",
    "\n",
    "    # 각 리스트에 저장\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "# 각 요소의 단어 수를 계산하여 리스트에 저장\n",
    "target_texts_inputs_word_count = [len(text.split()) for text in target_texts_inputs]\n",
    "\n",
    "# 결과 확인\n",
    "print(max(target_texts_inputs_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 1, 3: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 60: 1, 61: 1, 62: 1, 63: 1, 65: 1, 67: 1, 69: 1, 70: 1, 167: 1, 74: 1, 77: 1, 78: 1}\n"
     ]
    }
   ],
   "source": [
    "words_freq ={}\n",
    "\n",
    "for words in set(target_texts_inputs_word_count):\n",
    "    if words not in words_freq:\n",
    "        words_freq[words] = 1\n",
    "    else:\n",
    "        words_freq[words] = words_freq[words] +1\n",
    "\n",
    "print(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "data_train_filtered.to_csv(os.path.join('%s/train_filtered.csv' % PATH_SAVEMODEL_ROOT))\n",
    "data_test_filtered.to_csv(os.path.join('%s/test_filtered.csv' % PATH_SAVEMODEL_ROOT))\n",
    "\n",
    "max_word_count = max(words_freq.keys())\n",
    "print(max_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 8, 658, 659, 101], [5, 35, 2, 78, 187, 6, 79], [5, 35, 2, 78, 187, 6, 79], [5, 35, 2, 78, 187, 6, 79], [5, 35, 8, 3, 102, 134, 660, 188], [5, 9, 661, 189, 305], [5, 8, 662, 20, 663, 664, 20, 665], [5, 13, 666, 306, 51], [5, 8, 667, 668, 669, 190], [5, 307, 103, 80, 670, 16, 307, 671], [5, 44, 14, 672, 673, 308, 3, 674], [5, 104, 14, 306, 675, 676], [5, 35, 2, 677, 678, 188], [5, 135, 2, 679, 680], [5, 44, 2, 681, 682, 3, 309], [5, 44, 2, 3, 136, 683, 684], [5, 104, 14, 191, 81, 9, 36], [5, 44, 137, 3, 685, 686, 11, 687], [5, 8, 3, 6, 688, 4, 689, 690, 691], [5, 15, 310, 6, 3, 33], [5, 44, 2, 692, 693], [5, 8, 192, 193, 311], [5, 8, 192, 193, 311], [1, 312, 18, 3, 313, 314, 315, 6, 316], [1, 312, 18, 3, 313, 314, 315, 6, 316], [1, 13, 694, 695, 17, 317, 38], [1, 52, 8, 696, 3, 697, 698], [5, 13, 699, 700, 701, 51], [5, 15, 138, 702, 30, 703, 22, 318], [5, 17, 194, 195, 196, 197, 198], [5, 17, 194, 195, 196, 197, 198], [5, 17, 194, 195, 196, 197, 198], [1, 13, 3, 704, 82, 18, 705, 3, 139, 6, 3, 706], [1, 26, 2, 707, 708, 199, 4], [1, 10, 9, 319, 709, 16, 22, 319, 83], [1, 320, 8, 710, 320], [5, 15, 200, 22, 3, 105], [5, 15, 56, 20, 711, 8, 712, 713], [1, 26, 2, 714, 4, 321], [1, 322, 8, 4, 3, 323], [1, 322, 8, 4, 3, 323], [5, 15, 193, 8, 4, 3, 135, 324], [5, 2, 325, 326, 327, 21], [5, 2, 325, 326, 327, 21], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 64, 23, 53, 65], [1, 715, 2, 716], [5, 15, 45, 57, 4, 328, 329], [5, 15, 45, 57, 4, 328, 329], [1, 10, 46, 27, 18, 80, 9, 717, 29], [5, 104, 103, 84, 80, 4, 3, 330, 331], [1, 26, 4, 321, 2, 718, 47, 4], [1, 58, 719, 332, 3, 720, 16, 721, 140, 106, 48, 3, 722, 723, 724, 725, 726, 201, 727], [5, 10, 9, 107, 38], [5, 10, 9, 107, 38], [5, 10, 9, 107, 38], [5, 10, 9, 107, 38], [5, 10, 9, 107, 38], [1, 13, 333, 728, 51], [5, 15, 34, 729, 13, 730, 731, 30], [5, 15, 732, 8, 59, 4, 733], [1, 85, 66, 2, 334], [1, 85, 66, 2, 334], [1, 10, 734, 27], [1, 13, 335, 17], [1, 13, 335, 17], [1, 10, 336, 20, 735, 108, 16], [5, 2, 736, 141, 142], [5, 17, 737, 337], [1, 37, 13, 738, 739, 4], [5, 15, 338, 8, 4, 740, 741], [5, 15, 742, 4, 67, 743], [1, 10, 744, 339, 17], [1, 10, 78, 32, 27, 18, 3, 202], [1, 2, 745, 746, 4, 747, 308, 340], [5, 341, 748, 305], [1, 52, 8, 4, 749, 109], [5, 10, 9, 203, 189, 38], [5, 10, 9, 203, 189, 38], [1, 26, 2, 750, 204, 4], [1, 26, 2, 751, 752, 86, 4], [1, 13, 753, 754, 17], [1, 10, 3, 755, 205, 6, 756, 29], [5, 15, 33, 757, 110, 4, 758, 24], [5, 15, 759, 342, 206, 4, 760], [1, 26, 2, 343, 199], [1, 26, 2, 343, 199], [5, 15, 207, 13, 761, 762, 39, 4, 9, 763], [1, 10, 9, 764, 18, 765, 9, 766, 27], [1, 10, 3, 143, 27, 16, 767, 344], [1, 17, 768, 345], [1, 13, 769, 770, 346], [5, 15, 347, 208, 8, 59, 4, 348], [1, 10, 3, 771, 6, 772, 773, 774, 775, 33], [1, 776, 2, 349], [1, 10, 3, 31, 777, 27, 4, 778], [5, 13, 779, 780, 781, 51], [5, 15, 209, 782], [1, 210, 2, 28, 783, 6, 784], [1, 10, 211, 212, 144], [1, 10, 211, 212, 144], [1, 10, 211, 212, 144], [5, 15, 785, 10, 3, 213, 67, 32, 145], [5, 15, 786, 60, 350, 787, 214], [5, 2, 9, 788, 21], [1, 37, 2, 351, 4], [5, 2, 789, 790, 791], [1, 352, 2, 21, 19, 792, 215], [1, 37, 2, 793, 4], [5, 15, 794, 22, 3, 28, 49, 105], [5, 10, 9, 795, 796], [1, 26, 2, 146, 111, 797, 4], [1, 26, 2, 798, 86, 4], [1, 353, 18, 354, 355, 799], [5, 15, 216, 800, 10, 801, 802, 30], [1, 147, 803], [1, 42, 6, 356, 804, 2, 46, 18, 805, 806, 18, 807, 59, 808], [5, 2, 357, 358, 217, 19, 358], [5, 10, 218, 219, 3, 54, 68], [5, 10, 218, 219, 3, 54, 68], [5, 10, 218, 219, 3, 54, 68], [5, 15, 45, 57, 4, 809, 359], [5, 15, 148, 4, 3, 54, 68], [5, 13, 810, 24, 220], [1, 26, 2, 811, 812, 4], [1, 46, 2, 9, 813, 221], [1, 814, 815, 816], [1, 817, 2, 818, 29, 149], [1, 10, 3, 819, 820, 821, 27], [1, 17, 822, 823], [5, 35, 824, 2, 4, 9, 222, 6, 825], [5, 13, 3, 826, 827, 828, 829], [1, 10, 69, 87, 150, 830, 27], [5, 35, 348, 831, 4, 112], [5, 14, 3, 360, 101], [5, 14, 3, 360, 101], [1, 13, 832, 151, 17, 55, 36], [5, 15, 310, 30, 223, 224], [1, 10, 833, 834], [5, 15, 835, 225, 8, 59], [1, 226, 13, 3, 49, 70, 24, 39], [1, 10, 836, 837, 17], [1, 85, 66, 2, 361], [1, 85, 66, 2, 361], [5, 15, 838, 207, 13, 839, 362, 363], [1, 26, 2, 362, 840], [5, 10, 841, 842, 141], [5, 35, 10, 227, 56, 843, 22, 141, 142], [1, 10, 46, 61, 18, 39, 9, 364, 4, 844], [5, 10, 113, 152, 337], [5, 88, 845, 846, 8, 153], [5, 14, 3, 228, 89], [5, 15, 365, 4, 847, 20, 848], [5, 13, 849, 850, 51], [5, 15, 851, 17, 852, 30], [1, 42, 6, 225, 10, 853, 854, 855], [1, 26, 2, 856, 857, 4], [1, 10, 3, 366, 367, 154], [1, 10, 3, 366, 367, 154], [5, 13, 3, 368, 24, 220], [5, 2, 3, 858, 101], [5, 35, 369, 229, 10, 859, 114, 18, 45, 50, 860, 155], [1, 10, 861, 862, 17], [5, 10, 9, 370, 29, 371, 38], [5, 10, 9, 370, 29, 371, 38], [5, 104, 13, 3, 863, 864, 145], [5, 35, 10, 230, 231, 865, 22, 141, 142, 372, 866], [1, 867, 868, 869], [5, 2, 232, 233, 234], [5, 2, 232, 233, 234], [5, 2, 232, 233, 234], [1, 115, 2, 870, 29, 235, 4], [5, 104, 30, 871, 872, 223, 873], [5, 15, 373, 374, 45, 8, 59, 4, 3, 33], [1, 10, 874, 27], [5, 10, 875, 140, 375], [5, 15, 236, 8, 4, 3, 876, 156, 2, 376, 6, 877, 236], [1, 13, 146, 878, 17], [5, 17, 84, 879, 377, 880, 2, 3, 881, 882], [1, 26, 2, 237, 883, 378, 4, 884], [5, 2, 9, 238, 23], [1, 10, 885, 20, 886, 27], [1, 26, 2, 887, 888, 4], [1, 13, 889, 890, 891, 17], [1, 71, 9, 892, 4, 893, 894], [5, 2, 54, 895, 896], [1, 10, 9, 897, 898, 17], [1, 52, 899, 900], [5, 15, 379, 60, 901, 214, 18, 380, 226], [1, 17, 902, 903, 904], [1, 26, 2, 905, 381, 4], [5, 2, 192, 906, 90], [5, 15, 907, 13, 382, 3, 908, 30], [1, 37, 8, 909, 383, 19], [5, 15, 225, 4, 116], [5, 15, 200, 8, 22, 3, 49, 105], [5, 15, 200, 8, 22, 3, 49, 105], [1, 17, 910, 17], [1, 10, 239, 384, 108, 16], [1, 10, 239, 384, 108, 16], [1, 37, 2, 3, 240, 911], [1, 10, 385, 27], [1, 10, 385, 27], [1, 10, 241, 6, 912, 144], [1, 10, 913, 914, 915, 22, 916, 27], [1, 26, 2, 917, 918, 4], [1, 919, 30, 386, 920, 242], [5, 44, 9, 243, 921, 922], [5, 15, 45, 137, 110, 4, 3, 923], [1, 103, 924, 80, 23, 16], [1, 925, 2, 926, 22], [1, 17, 927, 17], [1, 42, 9, 2, 928], [5, 15, 929, 930, 4, 227, 56], [1, 931, 932, 933, 62, 387, 79], [5, 15, 934, 935, 8, 59], [1, 936, 3, 937, 938], [5, 2, 939, 940], [1, 71, 388, 941], [1, 10, 942, 943, 944, 27], [5, 15, 389, 60, 9, 157, 244, 16, 3, 245], [5, 15, 389, 60, 9, 157, 244, 16, 3, 245], [5, 15, 945, 6, 946, 137, 59], [1, 10, 46, 27, 377, 947, 948, 949], [1, 390, 58, 2, 950, 246], [1, 951, 4, 3, 391], [1, 13, 952, 17, 953, 954, 955], [1, 956, 49, 149, 957], [5, 15, 148, 4, 3, 68], [5, 15, 148, 4, 3, 68], [5, 35, 10, 9, 216, 392, 393], [5, 35, 10, 9, 216, 392, 393], [5, 15, 958, 10, 959, 960, 30], [1, 10, 25, 961, 247, 962], [1, 10, 3, 394, 27, 22, 3, 963, 105], [5, 964, 17, 965, 30, 966], [1, 115, 2, 967, 204, 235], [1, 10, 3, 968, 969, 91, 6, 3, 388, 17], [5, 15, 970, 10, 9, 54, 30], [1, 9, 971, 972], [1, 158, 2, 395], [1, 158, 2, 395], [1, 2, 3, 396, 6, 973, 974], [1, 71, 975, 976, 977], [5, 15, 978, 117, 18, 979, 980], [1, 83, 2, 3, 397, 6, 146, 981], [1, 982, 2, 983, 984], [5, 14, 158, 398, 4, 118], [5, 14, 158, 398, 4, 118], [1, 985, 30, 40, 50, 986], [1, 159, 28, 987, 62, 399, 400], [1, 10, 3, 988, 989, 18], [5, 15, 52, 8, 990, 6, 3, 349], [5, 15, 991, 8, 992, 4, 3, 33], [1, 10, 9, 993, 4, 9, 994, 401, 995, 6], [1, 344, 17, 84, 996, 4, 402, 18, 160, 9, 997, 998], [1, 10, 403, 999], [1, 17, 404, 405, 406], [1, 17, 404, 405, 406], [5, 44, 44, 2, 1000, 1001, 156], [5, 15, 1002, 4, 1003], [1, 52, 1004, 1005, 18, 1006, 1007, 4, 3, 407], [5, 2, 408, 119], [5, 15, 161, 2, 9, 248, 162], [5, 15, 161, 2, 9, 248, 162], [5, 15, 161, 2, 9, 248, 162], [1, 1008, 2, 409, 1009], [1, 37, 2, 1010, 1011, 4], [1, 71, 1012, 1013], [1, 353, 18, 1014, 1015], [1, 147, 3, 34, 24, 120], [1, 147, 3, 34, 24, 120], [5, 15, 45, 51, 19, 1016, 1017, 372, 32], [5, 15, 1018, 4, 1019, 1020], [1, 37, 60, 3, 121, 1021, 4, 3, 34], [1, 37, 2, 1022, 4], [5, 35, 6, 1023, 2, 1024, 1025, 79], [5, 2, 1026, 1027, 21], [1, 10, 1028, 1029, 27], [1, 37, 2, 410, 4], [1, 37, 2, 410, 4], [1, 26, 2, 1030, 1031, 47, 4], [5, 15, 379, 60, 1032, 214, 4, 317, 1033], [1, 17, 1034, 345], [1, 10, 9, 1035, 17], [1, 46, 411, 249, 106], [1, 46, 411, 249, 106], [1, 26, 2, 1036, 1037], [1, 163, 8, 92, 164], [1, 163, 8, 92, 164], [1, 163, 8, 92, 164], [1, 163, 8, 92, 164], [1, 10, 3, 36, 6, 3, 112, 17], [1, 10, 3, 36, 6, 3, 112, 17], [1, 10, 3, 36, 6, 3, 112, 17], [5, 15, 209, 6, 1038, 1039, 8, 59], [5, 2, 1040, 1041], [1, 42, 6, 250, 2, 412, 413], [1, 42, 6, 250, 2, 412, 413], [1, 26, 2, 1042, 414, 4], [5, 10, 1043, 415], [5, 15, 52, 30, 416, 55, 25, 165, 166], [1, 52, 8, 4, 417, 418], [1, 52, 8, 4, 417, 418], [5, 15, 1044, 122, 25, 165, 167], [1, 1045, 6, 3, 407, 2, 1046, 400], [1, 71, 3, 209], [1, 10, 1047, 1048, 27], [1, 10, 1049, 1050, 27], [5, 17, 84, 160, 1051, 1052], [5, 10, 1053, 1054, 1055, 38], [5, 359, 419, 9, 29], [5, 15, 1056, 206, 112], [5, 10, 1057, 1058, 1059, 1060, 18, 1061, 3, 28, 29], [5, 15, 1062, 4, 3, 33, 251], [1, 10, 1063, 17], [1, 71, 420, 53], [1, 71, 420, 53], [1, 83, 2, 3, 421, 210, 16, 422, 423, 252, 424], [1, 85, 66, 2, 1064], [5, 15, 1065, 8, 4, 9, 1066, 1067, 1068], [1, 42, 6, 1069, 14, 1070], [1, 42, 6, 425, 14, 1071, 1072], [1, 10, 1073, 1074, 4, 9, 1075, 1076], [7, 10, 426, 1077, 123, 16], [1, 8, 427, 1078], [1, 2, 1079, 1080, 1081], [1, 21, 3, 70, 24, 217, 19, 1082], [12, 18, 428, 1083, 1084, 21, 1085, 1086], [1, 32, 14, 3, 1087, 1088, 89], [7, 110, 1089, 1090], [1, 8, 3, 165, 168, 6, 429], [7, 124, 430, 22, 3, 1091, 106, 1092, 6, 3, 431], [7, 43, 432, 169], [1, 8, 3, 217, 1093, 6, 1094, 37, 1095], [1, 8, 82, 170], [1, 8, 82, 170], [1, 8, 82, 170], [7, 1096, 1097], [1, 2, 25, 433, 4, 434], [1, 2, 25, 433, 4, 434], [11, 13, 3, 387, 24, 39], [1, 29, 2, 1098, 1099, 4], [1, 29, 2, 1100, 4], [1, 40, 2, 435, 4, 1101, 436, 253, 436], [1, 2, 9, 171, 437], [7, 103, 125, 1102, 1103, 1104], [7, 90, 254], [1, 8, 3, 1105], [7, 93, 1106, 1107, 1108], [12, 17, 1109, 1110, 4, 67, 1111, 115], [1, 2, 9, 172, 255, 1112], [1, 256, 6, 257, 8, 1113, 1114], [12, 13, 438, 439, 72], [12, 13, 438, 439, 72], [1, 2, 25, 1115, 4, 440], [1, 2, 78, 1116, 1117, 4, 227, 56, 1118], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [12, 13, 3, 73, 24, 61, 74], [11, 13, 1119, 441, 3, 1120, 1121, 1122], [1, 91, 6, 3, 1123, 2, 1124], [12, 13, 442, 41, 19], [12, 13, 442, 41, 19], [1, 161, 6, 1125, 1126, 8, 19, 351, 20, 1127], [1, 443, 338, 2, 1128, 4], [1, 8, 3, 1129, 6, 1130], [11, 33, 1131, 1132, 444, 1133], [1, 42, 6, 258, 173, 2, 3, 259], [1, 42, 6, 258, 173, 2, 3, 259], [1, 42, 6, 258, 173, 2, 3, 259], [1, 256, 6, 167, 2, 1134, 1135], [1, 8, 1136, 1137], [11, 10, 3, 1138, 1139, 1140], [11, 1141, 1142, 14, 75], [7, 43, 1143, 6, 3, 1144, 1145], [1, 2, 9, 445, 125], [1, 2, 9, 445, 125], [1, 8, 1146, 16], [7, 1147, 174, 336, 9, 1148, 6, 446, 1149], [7, 260, 447, 448, 1150], [1, 32, 13, 1151, 1152, 1153, 364, 1154], [1, 8, 150, 168, 4, 429], [1, 24, 449, 18, 261, 262], [1, 2, 9, 1155, 1156], [12, 4, 3, 34, 8, 1157, 1158], [1, 32, 13, 3, 450, 159, 94, 50, 3, 40, 174, 451, 452, 263, 453], [1, 32, 13, 3, 450, 159, 94, 50, 3, 40, 174, 451, 452, 263, 453], [1, 2, 9, 1159, 175], [7, 95, 126, 40, 9, 1160, 2, 1161, 18, 41], [1, 2, 9, 375, 6, 356, 1162], [7, 43, 1163, 87, 31, 1164], [1, 2, 9, 446, 4, 1165], [11, 13, 1166, 1167, 1168, 3, 1169, 1170], [7, 93, 138, 1171], [1, 56, 30, 1172, 1173], [1, 56, 8, 22, 3, 1174, 1175], [11, 36, 81, 1176], [11, 13, 1177, 41, 22, 3, 444], [11, 13, 1178, 363], [1, 8, 257, 21, 127, 6], [1, 8, 257, 21, 127, 6], [1, 2, 9, 454, 96, 229], [1, 45, 23, 1179, 1180, 156], [7, 128, 55, 135, 264], [7, 128, 55, 135, 264], [7, 1181, 252, 1182, 3, 1183, 6, 455, 22, 3, 1184, 1185], [7, 265, 1186], [11, 13, 1187, 1188, 51], [1, 2, 9, 456, 266, 22, 9, 247], [7, 76, 1189, 245, 1190], [7, 93, 1191, 1192], [7, 190, 3, 1193], [1, 8, 267, 268, 23, 16], [1, 8, 267, 268, 23, 16], [1, 8, 267, 268, 23, 16], [1, 2, 9, 140, 1194], [7, 457, 3, 1195, 1196], [7, 76, 3, 1197, 176, 177], [1, 8, 3, 178, 6, 1198], [11, 13, 350, 458], [1, 2, 9, 1199, 123, 207], [11, 13, 3, 70, 24, 39, 20, 12], [1, 8, 3, 459, 1200, 4, 3, 34], [12, 3, 1201, 30, 460, 31, 1202, 269], [12, 13, 3, 1203, 138], [1, 2, 9, 1204, 4, 1205], [7, 1206, 55, 9, 1207, 1208, 4, 86], [12, 13, 461, 462, 123, 1209, 440], [1, 168, 8, 270, 4, 88, 179], [1, 168, 8, 270, 4, 88, 179], [7, 463, 1210, 464, 33], [1, 8, 465, 466, 21, 6], [1, 8, 465, 466, 21, 6], [7, 271, 9, 1211, 2, 188, 9, 1212, 1213], [7, 119, 1214, 18, 3, 167], [7, 10, 1215, 1216], [1, 206, 76, 176, 177], [7, 43, 1217, 3, 1218, 1219], [11, 13, 1220, 180, 1221], [1, 2, 9, 1222, 1223, 50, 25, 1224], [1, 2, 9, 1225, 1226], [7, 1227, 3, 1228, 1229, 437], [12, 10, 3, 1230, 1231, 22, 1232, 41, 19], [1, 8, 1233, 1234], [7, 95, 3, 467, 3, 468, 469, 94], [7, 95, 3, 467, 3, 468, 469, 94], [12, 10, 3, 470, 471, 117, 22, 472], [12, 10, 3, 470, 471, 117, 22, 472], [1, 2, 9, 1235, 1236], [1, 2, 1237, 16], [1, 29, 14, 3, 70, 24, 4], [12, 13, 3, 473, 474, 57], [12, 13, 3, 473, 474, 57], [1, 32, 14, 1238, 24], [1, 230, 231, 1239, 1240, 60, 223, 1241, 22, 3, 1242, 1243, 1244, 1245, 1246, 1247], [11, 13, 1248, 28, 1249], [12, 13, 1250, 1251, 138, 4, 1252], [1, 2, 9, 1253, 1254], [1, 8, 475, 476, 477], [1, 8, 475, 476, 477], [7, 89, 3, 478], [1, 42, 6, 479, 2, 380, 2, 480, 18, 1255], [7, 124, 481, 4, 102, 134], [7, 124, 481, 4, 102, 134], [1, 482, 1256], [7, 244, 3, 28, 332, 483, 48, 1257, 272], [7, 122, 1258, 484], [7, 13, 191, 81, 485, 18, 55, 3, 486, 487], [7, 13, 191, 81, 485, 18, 55, 3, 486, 487], [1, 32, 13, 3, 145, 1259, 117, 1260, 1261], [1, 8, 1262, 21, 19], [11, 13, 488, 489, 28, 41, 94], [1, 129, 17, 1263, 123, 4, 3, 1264, 273], [1, 29, 2, 67, 1265, 4], [7, 124, 1266, 4, 391, 1267], [7, 222, 447, 448], [1, 8, 3, 1268, 1269], [1, 32, 13, 422, 423, 252, 51], [1, 18, 441, 50, 1270], [1, 373, 374, 52, 30, 3, 121, 34, 274, 1271], [7, 376, 3, 1272, 275, 1273], [1, 88, 1274, 26, 2, 1275, 4], [1, 8, 49, 45, 6, 490, 491, 97], [1, 8, 49, 45, 6, 490, 491, 97], [11, 10, 1276, 39], [1, 2, 9, 1277, 1278, 4, 9, 238], [12, 10, 1279, 41, 19], [7, 89, 492, 1280], [1, 493, 494, 4, 495, 20, 496], [1, 493, 494, 4, 495, 20, 496], [1, 2, 9, 497, 498], [1, 2, 9, 497, 498], [7, 43, 3, 40, 4, 3, 1281], [1, 2, 1282, 118, 499], [1, 1283, 8, 1284], [11, 10, 399, 1285, 1286], [1, 8, 500, 213, 501], [1, 8, 500, 213, 501], [7, 435, 3, 1287, 1288, 40], [11, 13, 1289, 72], [1, 32, 13, 1290, 127, 50, 3, 1291, 72], [1, 150, 1292, 502, 18, 1293, 1294], [1, 1295, 3, 70, 24], [1, 2, 9, 208, 503], [1, 2, 9, 208, 503], [1, 8, 484, 21, 6], [7, 110, 276, 1296, 4, 1297, 1298], [12, 17, 504, 1299, 1300, 1301, 19], [7, 76, 3, 1302, 34, 274], [7, 93, 1303], [7, 43, 1304, 1305], [1, 8, 3, 277, 20, 278, 6, 3, 28, 279, 280, 77], [1, 8, 3, 277, 20, 278, 6, 3, 28, 279, 280, 77], [1, 8, 3, 277, 20, 278, 6, 3, 28, 279, 280, 77], [1, 2, 9, 505, 1306, 4, 402], [1, 91, 6, 1307, 8, 1308, 250, 19], [12, 10, 1309, 340, 1310], [1, 2, 9, 1311, 1312], [7, 128, 1313, 4, 87, 1314, 9, 1315], [1, 2, 9, 239, 1316, 1317], [1, 29, 2, 85, 66, 1318], [1, 2, 1319, 1320, 1321], [1, 8, 506, 181, 170], [1, 1322, 2, 1323, 1324, 1325, 4], [11, 13, 1326, 1327, 57], [11, 13, 3, 70, 1328, 182, 72], [7, 76, 1329, 34, 274, 281], [11, 13, 492, 1330, 160, 89], [7, 222, 98, 1331], [1, 29, 2, 67, 1332, 4], [1, 12, 3, 121, 1333, 1334, 126, 449, 18, 3, 1335, 6, 3, 1336, 4, 507], [11, 13, 1337, 1338, 260, 508], [1, 2, 9, 1339, 1340], [1, 3, 509, 6, 1341, 243], [7, 90, 3, 1342, 182], [1, 2, 25, 1343, 125], [1, 2, 9, 510, 1344], [1, 2, 9, 1345, 22, 9, 430], [1, 2, 25, 511, 96, 129, 4, 118], [1, 2, 25, 511, 96, 129, 4, 118], [7, 1346, 3, 120, 1347, 6, 318, 1348, 20, 1349], [1, 2, 9, 205, 1350, 512, 171], [11, 106, 1351, 1352, 130], [7, 110, 1353, 282], [11, 102, 1354, 1355, 1356], [7, 93, 1357, 1358], [1, 122, 9, 513, 202], [1, 122, 9, 513, 202], [11, 13, 514, 1359, 51], [7, 21, 3, 1360, 142, 515], [1, 56, 10, 1361, 1362, 1363, 1364], [11, 17, 1365, 1366, 415], [12, 17, 1367, 41, 19], [1, 1368, 2, 1369, 6, 155], [1, 1370, 516, 139, 123, 4, 9, 1371, 157], [1, 91, 6, 3, 273, 1372, 3, 33, 517, 401], [1, 29, 2, 3, 518, 4], [1, 8, 1373, 1374, 97], [1, 2, 9, 1375, 519], [7, 93, 1376, 1377], [1, 1378, 2, 1379, 520], [7, 271, 114, 131, 521, 62, 114, 131, 283], [7, 271, 114, 131, 521, 62, 114, 131, 283], [1, 36, 14, 1380, 1381], [7, 1382, 4, 1383], [1, 2, 522, 63], [1, 2, 522, 63], [7, 90, 1384], [7, 21, 1385, 1386], [1, 8, 1387, 1388], [11, 13, 1389, 1390, 523], [1, 8, 1391, 1392], [1, 8, 510, 1393, 1394], [7, 43, 1395, 1396], [11, 13, 1397, 524, 28, 1398], [12, 10, 284, 152, 41, 19], [12, 10, 284, 152, 41, 19], [12, 10, 284, 152, 41, 19], [7, 43, 3, 40, 1399], [11, 13, 261, 262, 160, 1400], [7, 76, 525, 120, 6, 1401, 1402], [1, 2, 9, 1403, 4, 1404], [7, 128, 526, 527, 4, 3, 528], [1, 2, 25, 1405, 4, 9, 1406, 529], [11, 10, 113, 99, 39, 16, 169], [11, 10, 113, 99, 39, 16, 169], [11, 10, 113, 99, 39, 16, 169], [7, 95, 1, 9, 1407, 34], [1, 1408, 2, 3, 36, 1409], [1, 182, 14, 111, 530, 531, 9, 91, 6], [1, 182, 14, 111, 530, 531, 9, 91, 6], [1, 285, 532, 8, 3, 533, 534, 22], [1, 285, 532, 8, 3, 533, 534, 22], [1, 8, 3, 178, 6, 25, 286, 58], [1, 8, 3, 178, 6, 25, 286, 58], [1, 8, 3, 178, 6, 25, 286, 58], [1, 8, 69, 100], [1, 8, 69, 100], [1, 8, 69, 100], [1, 8, 69, 100], [1, 8, 69, 100], [1, 8, 69, 100], [1, 8, 183, 535], [1, 8, 183, 535], [1, 443, 13, 1410, 1411, 1412], [1, 1413, 2, 1414, 287], [1, 2, 9, 1415, 1416, 149, 157], [7, 1417, 1418, 273], [1, 32, 13, 88, 179, 180, 9, 1419, 4, 1420], [1, 2, 9, 536, 6, 221], [1, 2, 9, 536, 6, 221], [7, 13, 98, 537, 282, 483, 538], [7, 43, 108, 132, 131], [1, 8, 539, 23, 16], [1, 8, 539, 23, 16], [1, 8, 3, 509, 6, 3, 1421, 1422], [12, 13, 3, 1423, 1424, 4, 109], [11, 13, 1425, 260, 508], [11, 13, 34, 24, 120, 220], [1, 2, 9, 540, 266], [1, 2, 9, 540, 266], [1, 8, 1426, 1427], [1, 2, 9, 1428, 1429], [1, 2, 9, 541, 1430, 23, 16], [7, 89, 3, 1431], [1, 8, 3, 542, 543, 16, 544, 63], [1, 8, 3, 542, 543, 16, 544, 63], [1, 8, 9, 20, 1432, 1433], [1, 1434, 2, 9, 1435], [12, 10, 355, 1436, 57], [11, 3, 1437, 1438, 545, 1439], [7, 21, 254], [1, 8, 3, 546, 547, 6, 3, 548, 549], [1, 8, 3, 546, 547, 6, 3, 548, 549], [12, 17, 84, 1440, 1441], [1, 8, 550, 551], [1, 8, 550, 551], [7, 124, 3, 383, 4, 3, 1442, 1443, 1444, 4, 507], [1, 36, 21, 1445, 18, 428, 552], [7, 95, 1446, 1447], [1, 2, 9, 553, 4, 3, 1448], [11, 139, 1449, 80, 130], [11, 13, 519, 6, 1450, 72], [11, 13, 1451, 554, 365], [1, 8, 555, 20, 287], [1, 8, 555, 20, 287], [1, 56, 60, 3, 1452, 1453], [11, 13, 1454, 1455, 1456, 4, 1457], [7, 43, 3, 40, 1458, 1459], [1, 8, 556, 557], [1, 8, 556, 557], [11, 13, 3, 67, 1460, 39], [1, 32, 13, 249, 174, 1461, 558, 18, 1462, 9, 1463], [11, 13, 1464, 1465, 229, 39], [1, 1466, 6, 455, 2, 1467, 4], [1, 32, 1468, 6, 1469, 21], [1, 2, 125, 1470, 156], [1, 559, 1471, 1472, 3, 1473, 6, 1474, 1475, 1476], [1, 560, 2, 9, 1477, 1478, 1479], [11, 561, 562], [11, 561, 562], [1, 482, 288, 403], [1, 2, 9, 563, 564], [1, 2, 9, 563, 564], [7, 1480, 565, 464, 46, 419, 9, 29], [11, 13, 566, 567, 180, 36], [11, 13, 566, 567, 180, 36], [7, 95, 1481, 115], [7, 76, 3, 121, 1482, 1483], [11, 13, 3, 1484, 1485, 72], [1, 8, 3, 253, 1486], [11, 1487, 159, 94], [1, 29, 2, 414], [1, 1488, 1489, 1490, 10, 1491, 30], [7, 1492, 87, 352, 1493], [7, 1494, 1495, 1496], [1, 8, 1497, 1498], [7, 1499, 460, 243, 1500, 1501], [1, 2, 9, 1502, 1503], [12, 13, 34, 24, 78, 39], [1, 32, 14, 289, 480, 558, 18, 30, 1504, 458], [11, 103, 84, 82, 9, 1505], [7, 90, 3, 1506, 1507], [1, 8, 3, 1508, 4, 1509], [7, 43, 3, 40, 9, 1510, 369, 37, 1511, 126], [7, 122, 1512], [11, 10, 9, 1513, 1514, 1515], [1, 2, 9, 1516, 290], [1, 8, 3, 1517, 148], [11, 13, 3, 1518, 523], [12, 2, 3, 54, 1519, 47], [1, 2, 92, 9, 568, 175], [11, 14, 545, 1520, 4, 3, 1521, 6, 1522], [1, 2, 20, 12, 2, 1523, 1524, 291, 20, 23, 16], [12, 8, 569, 570, 21], [12, 8, 569, 570, 21], [1, 2, 292, 143, 4, 3, 33], [1, 2, 292, 143, 4, 3, 33], [1, 2, 292, 143, 4, 3, 33], [1, 2, 92, 18, 80, 9, 1525], [1, 2, 571, 290], [1, 2, 571, 290], [1, 2, 147, 132, 3, 54, 1526, 1527], [11, 14, 3, 28, 526, 527, 171, 572], [1, 2, 1528, 166], [1, 2, 3, 573, 6, 3, 1529, 1530], [1, 2, 293, 62, 294], [1, 2, 293, 62, 294], [1, 2, 293, 62, 294], [1, 14, 81, 574, 6], [1, 14, 81, 574, 6], [7, 2, 111, 19, 276, 1531, 7, 8, 3, 1532, 1533], [1, 2, 151, 133, 16], [1, 2, 151, 133, 16], [1, 2, 151, 133, 16], [1, 2, 1534, 1535, 1536], [7, 2, 1537, 462, 19, 1538, 431, 57], [1, 14, 3, 517, 1539, 1540, 4, 1541], [7, 2, 3, 58, 575], [7, 2, 3, 58, 575], [11, 14, 1542, 1543, 90], [1, 2, 3, 421, 283, 576], [11, 14, 1544, 75], [7, 2, 3, 1545, 6, 254], [1, 2, 3, 240, 1546], [12, 2, 3, 1547, 47, 4, 25, 1548], [7, 2, 22, 3, 1549, 577, 295], [1, 2, 1550, 133, 16], [12, 2, 461, 1551, 19], [7, 2, 1552, 1553, 18, 3, 1554, 1555], [1, 2, 1556, 1557, 23, 16], [11, 14, 409, 565, 4], [1, 2, 1558, 23, 16], [1, 2, 1559, 16, 1560], [7, 14, 578, 275, 181, 579], [7, 14, 578, 275, 181, 579], [1, 2, 580, 31, 16, 3, 568, 1561], [12, 2, 394, 1562, 1563, 19], [12, 2, 3, 581, 48, 4, 582, 1564], [11, 14, 3, 34, 6, 488, 489, 190], [11, 2, 1565, 1566, 1567, 16, 1568], [1, 2, 3, 583, 296, 4, 109, 20, 12, 2, 2, 47], [1, 14, 3, 28, 584, 175], [1, 14, 3, 28, 584, 175], [11, 14, 1569, 1570, 426, 21], [1, 2, 1571, 1572], [7, 2, 3, 1573, 6, 3, 1574, 479], [7, 2, 585, 4, 3, 116], [7, 2, 585, 4, 3, 116], [1, 2, 117, 1575, 339], [12, 2, 3, 37, 1576, 47], [1, 2, 3, 583, 162, 4, 1577], [1, 2, 586, 297], [1, 2, 586, 297], [1, 2, 587, 588, 96], [1, 2, 587, 588, 96], [12, 2, 1578, 4, 1579], [1, 2, 506, 181, 589, 23, 16], [1, 2, 3, 1580, 1581], [7, 2, 3, 1582, 136, 4, 172, 1583, 50, 1584, 4, 3, 1585, 1586], [7, 2, 3, 1587, 1588, 1589, 6, 3, 230, 231, 330, 331], [11, 14, 3, 49, 1590, 590, 101], [1, 2, 3, 240, 591, 590], [1, 2, 3, 136, 354, 1591, 454, 31], [1, 2, 1592, 6, 1593], [7, 2, 276, 1594, 6, 1595, 1596], [1, 2, 25, 592, 593, 594], [1, 2, 25, 592, 593, 594], [1, 2, 297, 21, 19], [1, 2, 87, 1597, 1598, 595, 48, 390, 1599], [1, 2, 3, 31, 16, 25, 44, 425, 1600, 1601], [12, 14, 3, 1602, 4, 1603], [1, 2, 3, 1604, 6, 1605, 1606], [1, 2, 1607, 1608], [7, 14, 1609, 1610, 1611, 4, 368, 24], [1, 2, 580, 31, 16, 1612], [7, 14, 1613, 50, 512, 596, 3, 1614, 48, 87, 1615], [1, 2, 597, 201, 77], [1, 2, 597, 201, 77], [1, 2, 598, 172, 255], [1, 2, 598, 172, 255], [1, 2, 3, 1616, 6, 1617, 1618, 38], [1, 2, 599, 1619, 1620], [1, 2, 3, 129, 6, 600], [1, 2, 3, 129, 6, 600], [1, 2, 1621, 228, 1622], [1, 2, 601, 23, 16], [1, 2, 601, 23, 16], [1, 2, 46, 1623, 48, 1624, 1625], [1, 2, 1626, 1627, 1628], [11, 2, 1629, 1630, 83], [12, 2, 1631, 1632, 19], [12, 8, 3, 1633, 20, 1634, 1635, 1636], [1, 2, 203, 132, 1637, 427], [12, 2, 3, 1638, 1639, 47, 22, 9, 602], [1, 2, 1640, 1641], [1, 2, 70, 1642, 77], [12, 2, 88, 378, 4, 1643], [7, 14, 98, 537, 282, 127, 538], [1, 2, 3, 463, 1644, 154, 133, 55], [11, 14, 1645, 153, 55, 36], [12, 14, 298, 1646, 1647, 19], [1, 2, 236, 96], [12, 14, 3, 176, 177, 4, 1648], [11, 14, 603, 246, 224], [11, 14, 603, 246, 224], [7, 8, 3, 1649, 4, 1650, 4, 525, 524], [11, 14, 1651, 111, 1652, 1653], [12, 8, 1654, 1655], [1, 2, 604, 605, 20, 7, 606], [1, 2, 604, 605, 20, 7, 606], [7, 2, 2, 3, 136, 1656], [1, 2, 184, 9, 16], [1, 2, 184, 9, 16], [1, 2, 3, 518, 115, 6, 299], [11, 2, 46, 1657, 83], [1, 14, 241, 607], [1, 14, 241, 607], [12, 2, 1658, 1659, 582, 1660, 1661], [1, 14, 3, 31, 3, 28, 1662, 1663, 1664], [11, 14, 204, 153, 36], [12, 2, 3, 1665, 67, 1666], [1, 2, 4, 215], [1, 2, 4, 215], [1, 2, 1667, 1668, 1669], [7, 2, 3, 1670, 4, 3, 1671, 7, 2, 386], [1, 2, 608, 609, 610], [1, 2, 608, 609, 610], [11, 14, 1672, 1673, 75], [1, 2, 611, 612], [1, 2, 611, 612], [12, 8, 3, 121, 1674, 6, 1675, 1676], [1, 2, 1677, 1678, 210], [7, 14, 3, 28, 1679, 4, 3, 1680], [12, 2, 300, 119], [12, 2, 300, 119], [12, 2, 300, 119], [1, 2, 3, 1681, 1682, 1683, 20, 1684, 1685], [12, 2, 613, 237, 1686], [1, 2, 1687, 3, 1688], [11, 14, 613, 1689], [7, 2, 22, 3, 614, 295], [11, 14, 1690, 1691, 75], [7, 2, 1692, 1693, 1694], [1, 2, 3, 615, 6, 3, 616, 272], [1, 2, 3, 615, 6, 3, 616, 272], [1, 2, 1695, 1696, 1697, 2, 9, 256, 6], [11, 14, 3, 1698, 48, 1699, 502], [1, 2, 3, 396, 6, 1700, 381, 16, 281], [1, 2, 1701, 416], [7, 2, 3, 1702, 6, 1703, 1704], [1, 14, 1705, 1706, 617, 28, 31], [1, 2, 1707, 1708, 554], [1, 2, 3, 1709, 6, 3, 1710], [12, 2, 1711, 1712, 19], [1, 2, 3, 185, 16, 618], [1, 2, 3, 185, 16, 618], [1, 2, 3, 1713, 6, 1714, 155], [1, 2, 619, 1715], [1, 2, 1716, 1717, 1718, 620], [7, 2, 382, 1719, 424], [1, 2, 3, 63, 621, 6, 3, 622], [1, 2, 3, 63, 621, 6, 3, 622], [1, 2, 1720, 21, 6], [12, 2, 1721, 47, 623], [1, 2, 1722, 4, 1723, 1724], [7, 8, 3, 150, 1725, 6, 552], [7, 2, 1726, 514, 1727], [1, 2, 624, 625, 626], [1, 2, 624, 625, 626], [12, 2, 1728, 299], [1, 2, 3, 1729, 1730, 97], [1, 2, 1731, 617, 1732], [1, 2, 3, 1733, 6, 9, 1734, 1735], [1, 2, 113, 1736, 1737, 63], [1, 2, 1738, 23, 16], [11, 14, 1739, 75], [1, 2, 1740, 1741], [1, 2, 1742, 21, 6], [12, 2, 1743, 3, 1744, 620], [1, 2, 1745, 1746, 1747, 31], [12, 2, 1748, 4, 179], [1, 2, 4, 3, 1749, 6, 3, 251], [11, 14, 3, 478, 457], [12, 2, 1750, 140, 1751], [11, 14, 1752, 333, 1753, 153], [7, 14, 98, 1754, 1755], [7, 14, 22, 3, 614, 577, 295], [1, 2, 79, 1756, 1757], [7, 2, 1758, 19, 1759], [1, 2, 3, 559, 1760, 1761], [1, 2, 627, 628, 629], [7, 2, 1762, 4, 3, 116], [12, 8, 3, 324, 1763, 4, 3, 116], [1, 2, 1764, 1765], [7, 2, 3, 1766, 1767, 6, 623], [7, 2, 1768, 1769, 1770, 596], [12, 8, 1771, 1772, 515, 291], [12, 2, 630, 631, 48], [12, 2, 630, 631, 48], [1, 2, 3, 516, 6, 3, 1773, 1774, 173], [1, 2, 127, 50, 1775, 1776], [1, 2, 126, 1777, 22, 3, 1778, 6, 1779, 504], [12, 2, 186, 1780, 109, 1781], [1, 2, 288, 301], [1, 2, 288, 301], [11, 14, 3, 28, 176, 177], [1, 2, 3, 1782, 6, 1783], [1, 2, 3, 165, 166, 6, 109], [1, 2, 1784, 1785, 1786], [12, 2, 1787, 1788], [1, 2, 1789, 576], [1, 2, 599, 1790, 4, 342], [1, 2, 25, 1791, 1792, 589, 1793], [11, 14, 3, 1794, 24], [12, 2, 3, 1795, 1796], [1, 2, 3, 1797, 560, 1798, 1799, 4, 1800], [11, 2, 1801, 1802], [11, 2, 1803, 1804, 1805], [1, 2, 1806, 21, 19], [12, 2, 632, 20, 633, 86], [12, 2, 632, 20, 633, 86], [1, 2, 1807, 66], [11, 14, 1808, 1809, 75], [12, 14, 3, 1810, 1811, 205, 21], [7, 2, 4, 3, 58, 1812, 1813, 253], [1, 2, 1814, 1815, 634, 591], [11, 2, 1816, 1817, 83], [12, 2, 581, 1818, 86], [1, 2, 185, 6, 155], [11, 14, 3, 1819, 154, 1820], [1, 2, 9, 1821, 1822, 228], [1, 14, 3, 635, 20, 636, 637, 638], [1, 14, 3, 635, 20, 636, 637, 638], [1, 2, 619, 1823, 4, 627, 628], [12, 8, 1824, 1825, 1826, 1827], [12, 137, 3, 1828, 1829, 4, 1830], [11, 14, 3, 639, 640, 641, 40, 130], [11, 14, 3, 639, 640, 641, 40, 130], [1, 2, 1831, 1832, 62, 1833, 357], [1, 2, 1834, 1835], [12, 2, 235, 6, 1836, 1837, 1838, 47], [1, 2, 3, 31, 6, 3, 1839, 1840, 553, 44, 1841], [11, 14, 3, 251, 572], [1, 2, 3, 82, 6, 9, 1842, 1843], [1, 2, 1844, 3, 1845], [11, 14, 3, 642, 341, 4, 643], [1, 2, 456, 9, 247], [11, 14, 3, 28, 1846, 1847, 167, 130], [1, 2, 541, 1848], [1, 2, 3, 31, 6, 1849, 1850, 299], [7, 2, 3, 1851, 6, 643, 1852], [11, 2, 3, 1853, 29, 1854], [11, 14, 3, 29, 6, 1855, 1856], [1, 2, 3, 269, 6, 644, 298], [1, 2, 3, 269, 6, 644, 298], [1, 2, 3, 573, 6, 3, 1857, 1858], [12, 2, 1859, 19], [11, 2, 34, 24, 1860, 528, 41], [12, 14, 98, 1861, 75], [1, 2, 3, 1862, 1863, 4, 25, 1864, 1865], [1, 2, 1866, 21, 6], [1, 2, 1867, 21, 6], [1, 2, 1868, 23, 16], [1, 2, 184, 645, 23, 16], [1, 2, 184, 645, 23, 16], [1, 2, 1869, 108, 16], [1, 2, 1870, 6, 3, 1871], [7, 14, 3, 28, 1872, 18, 346, 301], [1, 2, 1873, 629], [1, 2, 3, 529, 6, 3, 1874, 1875], [1, 2, 25, 1876, 499, 1877], [1, 2, 3, 1878, 31, 6, 9, 1879, 264], [11, 2, 3, 397, 6, 146, 1880], [12, 2, 1881, 1882, 19], [1, 2, 646, 19, 646, 20, 1883], [1, 2, 4, 9, 139], [1, 2, 3, 1884, 16, 1885, 281], [1, 2, 408, 4], [1, 2, 1886, 4, 1887], [1, 2, 3, 1888, 1889, 1890], [1, 2, 1891, 6, 647, 27], [11, 14, 1892, 1893, 132, 1894, 1895, 21], [7, 2, 3, 309, 126, 128, 102, 134], [1, 2, 3, 1896, 595, 6, 1897], [12, 2, 1898, 19], [1, 2, 3, 1899, 1900, 4, 149, 97], [1, 2, 3, 185, 97], [7, 2, 3, 171, 3, 1901, 4, 3, 1902, 132], [7, 8, 3, 289, 19, 3, 505, 289, 183], [1, 2, 1903, 520, 145, 31], [1, 14, 1904, 1905, 1906], [1, 2, 1907, 1908, 1909], [7, 2, 1910, 6, 3, 285], [1, 2, 1911, 63], [7, 2, 1912, 1913, 183], [1, 2, 3, 31, 6, 3, 648, 6, 649], [1, 2, 3, 31, 6, 3, 648, 6, 649], [1, 2, 1914, 1915, 31], [11, 14, 1916, 1917, 265], [1, 2, 3, 302, 6, 186, 99], [1, 2, 3, 302, 6, 186, 99], [1, 2, 3, 302, 6, 186, 99], [12, 2, 3, 642, 1918, 47, 22, 9, 33, 602], [1, 14, 3, 226, 6, 261, 262], [1, 2, 3, 1919, 16, 166], [12, 8, 3, 1920, 4, 263, 68], [1, 2, 650, 651], [1, 2, 650, 651], [1, 2, 432, 1921, 21, 6], [12, 2, 3, 1922, 291], [1, 2, 3, 1923, 6, 237, 49, 1924, 1925, 647], [1, 2, 4, 3, 652, 296, 242], [1, 2, 4, 3, 652, 296, 242], [12, 2, 1926, 270], [1, 2, 54, 1927], [12, 2, 1928, 98, 1929, 48], [1, 2, 459, 1930, 4, 33], [12, 2, 653, 654], [12, 2, 653, 654], [1, 2, 1931, 20, 1932, 31], [1, 2, 1933, 20, 1934, 77], [1, 2, 25, 303, 304], [1, 2, 25, 303, 304], [1, 2, 25, 303, 304], [1, 2, 3, 1935, 49, 634], [11, 14, 347, 238, 265], [1, 2, 655, 656, 657], [1, 2, 655, 656, 657]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_inputs = Tokenizer(num_words=20000)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_INPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_inputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1935 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=20000, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8462 unique output tokens.\n",
      "encoder_inputs.shape: (1039, 19)\n",
      "encoder_inputs[0]: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   8 658 659\n",
      " 101]\n",
      "decoder_inputs[0]: [   9    4 1481  941    7    4  941  176  116    1 1482    2    4 1481\n",
      "   11    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder_inputs.shape: (1039, 167)\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 저장\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_OUTPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(PATH_EMBEDDING, encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/myenv/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1726664640.958969  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664640.959049  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664640.959088  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664641.087391  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726664641.087430  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-18 15:04:01.087438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1726664641.087461  649689 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-18 15:04:01.087475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  trainable=True\n",
    ")\n",
    "\n",
    "##### build the model #####\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "x= Bidirectional(LSTM(LATENT_DIM, return_sequences=True))(x)\n",
    "encoder_outputs, state_h, state_c = LSTM(\n",
    "    LATENT_DIM, return_state=True)(x)\n",
    "\n",
    "# Concatenate forward and backward states\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "decoder_outputs = Dropout(0.5)(decoder_outputs)\n",
    "\n",
    "# Final dense layer to predict words\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Create model\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)  # 학습률 조정\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    # y_true를 int32로 명시적으로 변환\n",
    "    y_true = K.cast(y_true, dtype='int32')\n",
    "\n",
    "    pred = K.argmax(y_pred, axis=-1)  # 예측된 값에서 가장 높은 확률의 인덱스 추출\n",
    "    pred = K.cast(pred, dtype='int32')  # pred도 int32로 변환\n",
    "    correct = K.cast(K.equal(y_true, pred), dtype='float32')\n",
    "\n",
    "    # 패딩 값 0을 제외한 부분에 대한 마스킹\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    n_correct = K.sum(mask * correct)\n",
    "    n_total = K.sum(mask)\n",
    "    return n_correct / n_total\n",
    "\n",
    "\n",
    "\n",
    "# encoder_inputs, decoder_inputs, decoder_targets을 int32로 변환\n",
    "encoder_inputs = np.array(encoder_inputs, dtype='int32')\n",
    "decoder_inputs = np.array(decoder_inputs, dtype='int32')\n",
    "decoder_targets = np.array(decoder_targets, dtype='int32')\n",
    "# embedding_matrix는 float32로 유지\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM), dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 시 custom loss 대신 SparseCategoricalCrossentropy 사용\n",
    "model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience  # 얼리스토핑에 사용할 patience\n",
    "        self.wait = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.stop_training_flag = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_acc = logs.get('acc')\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        current_loss = logs.get('loss')\n",
    "        \n",
    "        if current_val_loss > self.best_val_loss or current_loss > self.best_val_loss:\n",
    "            self.wait += 1\n",
    "            print(f\"Early stopping condition met. Waiting: {self.wait}/{self.patience}\")\n",
    "            \n",
    "            if self.wait >= self.patience:\n",
    "                self.stop_training_flag = True\n",
    "                self.model.stop_training = True  # 학습 중단\n",
    "        else:\n",
    "            # 더 나은 val_loss 또는 loss가 나오면 best_val_loss 갱신 및 wait 리셋\n",
    "            self.best_val_loss = min(current_val_loss, current_loss)\n",
    "            self.wait = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 15:04:03.419445: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5978 - loss: 8.9754 - val_accuracy: 0.8341 - val_loss: 8.3876\n",
      "Epoch 2/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8358 - loss: 7.5152 - val_accuracy: 0.8316 - val_loss: 5.0098\n",
      "Epoch 3/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8340 - loss: 4.3981 - val_accuracy: 0.8316 - val_loss: 2.6000\n",
      "Epoch 4/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8342 - loss: 2.2703 - val_accuracy: 0.8316 - val_loss: 1.6579\n",
      "Epoch 5/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8339 - loss: 1.6098 - val_accuracy: 0.8316 - val_loss: 1.4900\n",
      "Epoch 6/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8335 - loss: 1.4658 - val_accuracy: 0.8316 - val_loss: 1.4158\n",
      "Epoch 7/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8328 - loss: 1.4056 - val_accuracy: 0.8316 - val_loss: 1.3832\n",
      "Epoch 8/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8349 - loss: 1.3563 - val_accuracy: 0.8316 - val_loss: 1.3640\n",
      "Epoch 9/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8378 - loss: 1.3142 - val_accuracy: 0.8316 - val_loss: 1.3491\n",
      "Epoch 10/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8340 - loss: 1.3235 - val_accuracy: 0.8316 - val_loss: 1.3358\n",
      "Epoch 11/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8349 - loss: 1.3065Early stopping condition met. Waiting: 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8349 - loss: 1.3064 - val_accuracy: 0.8316 - val_loss: 1.3236\n",
      "Epoch 12/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8355 - loss: 1.2862 - val_accuracy: 0.8333 - val_loss: 1.3115\n",
      "Epoch 13/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8361 - loss: 1.2690Early stopping condition met. Waiting: 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8361 - loss: 1.2691 - val_accuracy: 0.8355 - val_loss: 1.2996\n",
      "Epoch 14/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8363 - loss: 1.2611Early stopping condition met. Waiting: 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8363 - loss: 1.2607 - val_accuracy: 0.8363 - val_loss: 1.2909\n",
      "Epoch 15/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8352 - loss: 1.2684 - val_accuracy: 0.8369 - val_loss: 1.2837\n",
      "Epoch 16/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8359 - loss: 1.2534Early stopping condition met. Waiting: 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8361 - loss: 1.2522 - val_accuracy: 0.8372 - val_loss: 1.2778\n",
      "Epoch 17/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8409 - loss: 1.2041Early stopping condition met. Waiting: 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8407 - loss: 1.2054 - val_accuracy: 0.8372 - val_loss: 1.2730\n",
      "Epoch 18/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8350 - loss: 1.2476Early stopping condition met. Waiting: 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8353 - loss: 1.2458 - val_accuracy: 0.8373 - val_loss: 1.2690\n",
      "Epoch 19/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8364 - loss: 1.2259Early stopping condition met. Waiting: 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8365 - loss: 1.2250 - val_accuracy: 0.8377 - val_loss: 1.2655\n",
      "Epoch 20/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8373 - loss: 1.2234Early stopping condition met. Waiting: 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8374 - loss: 1.2223 - val_accuracy: 0.8378 - val_loss: 1.2630\n",
      "Epoch 21/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8404 - loss: 1.1901Early stopping condition met. Waiting: 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8404 - loss: 1.1907 - val_accuracy: 0.8380 - val_loss: 1.2609\n",
      "Epoch 22/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8373 - loss: 1.2149Early stopping condition met. Waiting: 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8375 - loss: 1.2137 - val_accuracy: 0.8382 - val_loss: 1.2596\n",
      "Epoch 23/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8381 - loss: 1.2033Early stopping condition met. Waiting: 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8383 - loss: 1.2025 - val_accuracy: 0.8382 - val_loss: 1.2584\n",
      "Epoch 24/3000\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8398 - loss: 1.1900Early stopping condition met. Waiting: 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8399 - loss: 1.1898 - val_accuracy: 0.8387 - val_loss: 1.2572\n",
      "Epoch 25/3000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8420 - loss: 1.1722Early stopping condition met. Waiting: 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8419 - loss: 1.1730 - val_accuracy: 0.8387 - val_loss: 1.2567\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = CustomEarlyStopping(patience=10)\n",
    "\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs], decoder_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.1,\n",
    "  callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 가중치 비교\n",
    "original_weights = model.get_weights()\n",
    "\n",
    "# 모델을 저장\n",
    "model.save(PATH_MODEL)\n",
    "\n",
    "# 모델을 불러옴\n",
    "model_loaded = load_model(PATH_MODEL, custom_objects={'custom_loss': custom_loss, 'acc': acc})\n",
    "\n",
    "# 불러온 모델의 가중치\n",
    "loaded_weights = model_loaded.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n"
     ]
    }
   ],
   "source": [
    "# 가중치 비교\n",
    "for original, loaded in zip(original_weights, loaded_weights):\n",
    "    if np.array_equal(original, loaded):\n",
    "        print(\"가중치 일치\")\n",
    "    else:\n",
    "        print(\"가중치 불일치\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# this time, we want to keep the states too, to be output\n",
    "# by our sampling model\n",
    "decoder_outputs, h, c = decoder_lstm(\n",
    "  decoder_inputs_single_x,\n",
    "  initial_state=decoder_states_inputs\n",
    ")\n",
    "# decoder_outputs, state_h = decoder_lstm(\n",
    "#   decoder_inputs_single_x,\n",
    "#   initial_state=decoder_states_inputs\n",
    "# ) #gru\n",
    "decoder_states = [h, c]\n",
    "# decoder_states = [h] # gru\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The sampling model\n",
    "# inputs: y(t-1), h(t-1), c(t-1)\n",
    "# outputs: y(t), h(t), c(t)\n",
    "decoder_model = Model(\n",
    "  [decoder_inputs_single] + decoder_states_inputs, \n",
    "  [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  print('Input Sequences: ', input_seq)\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "  print('Target Sequences: ', target_seq)\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    output_tokens, h, c = decoder_model.predict(\n",
    "      [target_seq] + states_value\n",
    "    )\n",
    "    \n",
    "    print('Output Tokens: ', output_tokens)\n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "    # Get next wordgfhjfghj\n",
    "    idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    # states_value = [h] # gru\n",
    "\n",
    "  return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_model.save(PATH_ENCODER_MODEL)\n",
    "decoder_model.save(PATH_DECODER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequences:  [[  0   0   0   0   0   0   0   0   0   0   0   0   0   5  88 845 846   8\n",
      "  153]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Target Sequences:  [[9.]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Output Tokens:  [[[1.31606525e-02 1.14762664e-01 2.70915702e-02 ... 1.36199296e-05\n",
      "   1.08727445e-05 8.01032547e-06]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[8.8965222e-03 7.6641150e-02 2.2780219e-02 ... 1.8010574e-05\n",
      "   1.4980042e-05 1.1612610e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[8.2620932e-03 6.5810353e-02 2.2007747e-02 ... 1.9189007e-05\n",
      "   1.6481852e-05 1.2895747e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Output Tokens:  [[[8.2875928e-03 6.1595108e-02 2.2659479e-02 ... 1.9279416e-05\n",
      "   1.6810129e-05 1.3212479e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[8.5541075e-03 5.9410557e-02 2.3884255e-02 ... 1.9061827e-05\n",
      "   1.6601971e-05 1.3247091e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[8.8899033e-03 5.7963178e-02 2.5214411e-02 ... 1.8831755e-05\n",
      "   1.6257802e-05 1.3289860e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Output Tokens:  [[[9.21409763e-03 5.67882657e-02 2.63488702e-02 ... 1.87878068e-05\n",
      "   1.60782783e-05 1.34227885e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.5758885e-03 5.5647645e-02 2.7346019e-02 ... 1.8974821e-05\n",
      "   1.6176582e-05 1.3648445e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Output Tokens:  [[[1.00541245e-02 5.42863980e-02 2.83312816e-02 ... 1.92473071e-05\n",
      "   1.65966721e-05 1.38607174e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[1.0746649e-02 5.2536268e-02 2.9256348e-02 ... 1.9410694e-05\n",
      "   1.7250803e-05 1.3945020e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[1.1764068e-02 5.0788935e-02 3.0027863e-02 ... 1.9560077e-05\n",
      "   1.7873392e-05 1.3922001e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[1.3159600e-02 4.9384233e-02 3.0654933e-02 ... 1.9802665e-05\n",
      "   1.8267399e-05 1.3885196e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[1.4825719e-02 4.8273750e-02 3.1117057e-02 ... 2.0068112e-05\n",
      "   1.8414201e-05 1.3890599e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[1.6542848e-02 4.7357649e-02 3.1373505e-02 ... 2.0292673e-05\n",
      "   1.8392153e-05 1.3939257e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[1.8220665e-02 4.6593636e-02 3.1450257e-02 ... 2.0448420e-05\n",
      "   1.8255127e-05 1.4006839e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Output Tokens:  [[[1.9979279e-02 4.5947731e-02 3.1357665e-02 ... 2.0497746e-05\n",
      "   1.8015238e-05 1.4065972e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[2.1941774e-02 4.5370866e-02 3.1154674e-02 ... 2.0452640e-05\n",
      "   1.7696015e-05 1.4111869e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[2.4050923e-02 4.4810597e-02 3.0966571e-02 ... 2.0391870e-05\n",
      "   1.7358920e-05 1.4167952e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[2.6169367e-02 4.4272937e-02 3.0836713e-02 ... 2.0350637e-05\n",
      "   1.7062641e-05 1.4238368e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Output Tokens:  [[[2.8213572e-02 4.3794133e-02 3.0739967e-02 ... 2.0315367e-05\n",
      "   1.6832804e-05 1.4305101e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Output Tokens:  [[[3.0181818e-02 4.3400746e-02 3.0651528e-02 ... 2.0269445e-05\n",
      "   1.6660044e-05 1.4347994e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Output Tokens:  [[[3.2093745e-02 4.3105848e-02 3.0576523e-02 ... 2.0206955e-05\n",
      "   1.6511100e-05 1.4352496e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[3.3947863e-02 4.2909205e-02 3.0537836e-02 ... 2.0132400e-05\n",
      "   1.6353957e-05 1.4314351e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[3.5740364e-02 4.2800769e-02 3.0548962e-02 ... 2.0053305e-05\n",
      "   1.6176480e-05 1.4239153e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Output Tokens:  [[[3.7479918e-02 4.2768013e-02 3.0608196e-02 ... 1.9973100e-05\n",
      "   1.5981839e-05 1.4136149e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[3.9175447e-02 4.2798683e-02 3.0706130e-02 ... 1.9890398e-05\n",
      "   1.5777303e-05 1.4013807e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Output Tokens:  [[[4.0824998e-02 4.2879060e-02 3.0830467e-02 ... 1.9802226e-05\n",
      "   1.5569261e-05 1.3879081e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[4.2420190e-02 4.2993147e-02 3.0967690e-02 ... 1.9706958e-05\n",
      "   1.5362260e-05 1.3737797e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[4.3958087e-02 4.3123730e-02 3.1104330e-02 ... 1.9605544e-05\n",
      "   1.5158532e-05 1.3594605e-05]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[2.1704461e-01 3.9348803e-02 2.8204354e-02 ... 1.4363499e-05\n",
      "   1.0737961e-05 9.4112102e-06]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Output Tokens:  [[[6.59640968e-01 1.49330497e-02 1.07062645e-02 ... 6.94051369e-06\n",
      "   4.88842807e-06 4.31506805e-06]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.0968150e-01 3.6155602e-03 2.5504110e-03 ... 1.9677168e-06\n",
      "   1.2024077e-06 1.1012499e-06]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Output Tokens:  [[[9.6625727e-01 1.2783784e-03 9.0723264e-04 ... 7.7079426e-07\n",
      "   4.0609677e-07 3.8110534e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.8014110e-01 7.3733705e-04 5.3397979e-04 ... 4.7045705e-07\n",
      "   2.2486684e-07 2.1266850e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Output Tokens:  [[[9.8471129e-01 5.6715950e-04 4.1485179e-04 ... 3.7359632e-07\n",
      "   1.6922344e-07 1.6120931e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.8678142e-01 4.9033063e-04 3.5839024e-04 ... 3.3418578e-07\n",
      "   1.4577847e-07 1.4211959e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Output Tokens:  [[[9.8809040e-01 4.3939488e-04 3.2184884e-04 ... 3.1228691e-07\n",
      "   1.3112164e-07 1.3306285e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.8919171e-01 3.9544050e-04 2.9025643e-04 ... 2.9396966e-07\n",
      "   1.1823722e-07 1.2571746e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9010193e-01 3.5899319e-04 2.6304822e-04 ... 2.7734700e-07\n",
      "   1.0763131e-07 1.1820288e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Output Tokens:  [[[9.90710318e-01 3.33673961e-04 2.45709671e-04 ... 2.65655871e-07\n",
      "   1.01017356e-07 1.11871380e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91114736e-01 3.15701851e-04 2.35281652e-04 ... 2.58126391e-07\n",
      "   9.71244631e-08 1.06874815e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.9135560e-01 3.0472016e-04 2.2946752e-04 ... 2.5371085e-07\n",
      "   9.4948689e-08 1.0366675e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Output Tokens:  [[[9.9146855e-01 2.9960804e-04 2.2683622e-04 ... 2.5160531e-07\n",
      "   9.3925365e-08 1.0211831e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91514564e-01 2.97572813e-04 2.25792392e-04 ... 2.50738339e-07\n",
      "   9.34994873e-08 1.01483444e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9153262e-01 2.9679600e-04 2.2539162e-04 ... 2.5039853e-07\n",
      "   9.3327643e-08 1.0123473e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Output Tokens:  [[[9.91539776e-01 2.96492333e-04 2.25232710e-04 ... 2.50260712e-07\n",
      "   9.32555366e-08 1.01133935e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.9154282e-01 2.9636573e-04 2.2516488e-04 ... 2.5019943e-07\n",
      "   9.3222930e-08 1.0108932e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91544485e-01 2.96307728e-04 2.25133059e-04 ... 2.50168796e-07\n",
      "   9.32063742e-08 1.01067116e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91545379e-01 2.96276907e-04 2.25115684e-04 ... 2.50150919e-07\n",
      "   9.31968600e-08 1.01054304e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Output Tokens:  [[[9.9154574e-01 2.9625921e-04 2.2510566e-04 ... 2.5013910e-07\n",
      "   9.3190849e-08 1.0104605e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91546094e-01 2.96247163e-04 2.25098644e-04 ... 2.50130597e-07\n",
      "   9.31866140e-08 1.01040115e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154633e-01 2.9623846e-04 2.2509354e-04 ... 2.5012397e-07\n",
      "   9.3183438e-08 1.0103552e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.9154645e-01 2.9623200e-04 2.2509015e-04 ... 2.5011920e-07\n",
      "   9.3181136e-08 1.0103205e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91546571e-01 2.96227518e-04 2.25087599e-04 ... 2.50115448e-07\n",
      "   9.31793664e-08 1.01029364e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91546571e-01 2.96223297e-04 2.25085227e-04 ... 2.50112095e-07\n",
      "   9.31777677e-08 1.01027055e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Output Tokens:  [[[9.9154705e-01 2.9622007e-04 2.2508339e-04 ... 2.5010937e-07\n",
      "   9.3176752e-08 1.0102517e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547048e-01 2.96217797e-04 2.25082345e-04 ... 2.50107689e-07\n",
      "   9.31756787e-08 1.01023836e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "Output Tokens:  [[[9.9154717e-01 2.9621558e-04 2.2508108e-04 ... 2.5010581e-07\n",
      "   9.3174982e-08 1.0102249e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Output Tokens:  [[[9.9154717e-01 2.9621445e-04 2.2508044e-04 ... 2.5010462e-07\n",
      "   9.3174272e-08 1.0102153e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.91547287e-01 2.96212791e-04 2.25079595e-04 ... 2.50103227e-07\n",
      "   9.31737461e-08 1.01020575e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Output Tokens:  [[[9.9154729e-01 2.9621192e-04 2.2507919e-04 ... 2.5010272e-07\n",
      "   9.3173391e-08 1.0102000e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9621110e-04 2.2507878e-04 ... 2.5010181e-07\n",
      "   9.3173050e-08 1.0101943e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9621029e-04 2.2507833e-04 ... 2.5010132e-07\n",
      "   9.3172694e-08 1.0101885e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96209415e-04 2.25077907e-04 ... 2.50100385e-07\n",
      "   9.31725168e-08 1.01018465e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620915e-04 2.2507791e-04 ... 2.5010016e-07\n",
      "   9.3172162e-08 1.0101809e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620886e-04 2.2507769e-04 ... 2.5009990e-07\n",
      "   9.3172162e-08 1.0101789e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96208280e-04 2.25077471e-04 ... 2.50099447e-07\n",
      "   9.31718063e-08 1.01017505e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96207989e-04 2.25077281e-04 ... 2.50098964e-07\n",
      "   9.31718063e-08 1.01017314e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620773e-04 2.2507705e-04 ... 2.5009896e-07\n",
      "   9.3171622e-08 1.0101712e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620773e-04 2.2507705e-04 ... 2.5009896e-07\n",
      "   9.3171622e-08 1.0101712e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620744e-04 2.2507705e-04 ... 2.5009848e-07\n",
      "   9.3171451e-08 1.0101693e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507684e-04 ... 2.5009848e-07\n",
      "   9.3171273e-08 1.0101674e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507684e-04 ... 2.5009848e-07\n",
      "   9.3171273e-08 1.0101674e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507684e-04 ... 2.5009822e-07\n",
      "   9.3171273e-08 1.0101674e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507684e-04 ... 2.5009800e-07\n",
      "   9.3171273e-08 1.0101654e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507684e-04 ... 2.5009800e-07\n",
      "   9.3171273e-08 1.0101654e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620688e-04 2.2507684e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101654e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620688e-04 2.2507684e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620688e-04 2.2507684e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620714e-04 2.2507705e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620688e-04 2.2507705e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620662e-04 2.2507663e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.9154741e-01 2.9620662e-04 2.2507663e-04 ... 2.5009800e-07\n",
      "   9.3171096e-08 1.0101635e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31710957e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31710957e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31710957e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31710957e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Output Tokens:  [[[9.91547406e-01 2.96206330e-04 2.25076627e-04 ... 2.50097514e-07\n",
      "   9.31709110e-08 1.01016155e-07]]]\n",
      "-\n",
      "Input: how south african leaders are elected\n",
      "Translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "# Do some test translations\n",
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
