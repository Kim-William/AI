{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow[and-cuda]\n",
    "#asdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# # https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
    "# get the data at: http://www.manythings.org/anki/\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "  import tensorflow.keras.backend as K\n",
    "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "except:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPUs found\")\n",
    "else:\n",
    "    print(f\"GPUs available: {gpus}\")\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "# some config\n",
    "BATCH_SIZE = 64  # Batch size for training.\n",
    "EPOCHS = 2000  # Number of epochs to train for.\n",
    "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\n",
    "NUM_SAMPLES = 20360  # Number of samples to train on.\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "\n",
    "PATH_SAVEMODEL = 'SavedModel/240912_1640'\n",
    "PATH_DATA_ROOT = 'Data'\n",
    "\n",
    "PATH_EMBEDDING = f'{PATH_DATA_ROOT}/glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "\n",
    "PATH_TOKENIZER_OUTPUT = os.path.join('%s/tokenizer_output.pickle' % PATH_SAVEMODEL)\n",
    "PATH_TOKENIZER_INPUT = os.path.join('%s/tokenizer_input.pickle' % PATH_SAVEMODEL)\n",
    "\n",
    "PATH_MODEL= os.path.join('%s/s2s.h5' % PATH_SAVEMODEL)\n",
    "PATH_TRAIN = os.path.join('%s/train.txt' % PATH_DATA_ROOT)\n",
    "PATH_ENCODER_MODEL = os.path.join('%s/encoder_model.h5' % PATH_SAVEMODEL)\n",
    "PATH_DECODER_MODEL = os.path.join('%s/decoder_model.h5' % PATH_SAVEMODEL)\n",
    "\n",
    "PATH_SEQUENCE_FILE = os.path.join('%s/input_sequences.pkl' % PATH_SAVEMODEL)\n",
    "PATH_TARGET_SEQUENCE_FILE = os.path.join('%s/target_sequences.pkl' % PATH_SAVEMODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 행의 개수: 20359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# 파일에서 DataFrame 읽기 (예: CSV 파일)\n",
    "df = pd.read_csv(PATH_TRAIN, delimiter='\\t')\n",
    "\n",
    "# 전체 행의 수 확인\n",
    "print(f\"전체 행의 개수: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 2118\n"
     ]
    }
   ],
   "source": [
    "# 중복된 input_text를 추적할 집합을 생성\n",
    "seen_input_texts = set()\n",
    "t=0\n",
    "for line in open(PATH_TRAIN, encoding='utf-8'):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "\n",
    "    # input and target are separated by tab\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    line_split = line.rstrip().split('\\t')\n",
    "\n",
    "    # 두 번째 열 (인덱스 1)에 해당하는 input_text\n",
    "    input_text = line_split[0].strip()  # 공백 제거\n",
    "\n",
    "    # 중복된 input_text가 이미 처리되었는지 확인\n",
    "    if input_text in seen_input_texts:\n",
    "        continue  # 중복된 경우 스킵\n",
    "\n",
    "    # 중복되지 않은 input_text는 집합에 추가\n",
    "    seen_input_texts.add(input_text)\n",
    "\n",
    "    # 다섯 번째 열 (인덱스 4)에 해당하는 translation\n",
    "    translation = line_split[1].strip()  # 공백 제거\n",
    "\n",
    "    # split up the input and translation\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4048 unique input tokens.\n",
      "Found 9782 unique output tokens.\n",
      "encoder_inputs.shape: (2118, 23)\n",
      "encoder_inputs[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    5    9 1301 1302  164]\n",
      "decoder_inputs[0]: [   9    5 3973 3974 2357 3975   22 3976 3977 2357    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder_inputs.shape: (2118, 237)\n",
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Filling pre-trained embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/myenv/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# Tokenizer 저장\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_INPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_inputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # Tokenizer 불러오기\n",
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer_inputs = pickle.load(handle)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# Tokenizer 저장\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_OUTPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "\n",
    "\n",
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(PATH_EMBEDDING, encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n",
    "\n",
    "##### build the model #####\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_state=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "# encoder_outputs, h = encoder(x) #gru\n",
    "\n",
    "# keep only the states to pass into decoder\n",
    "encoder_states = [h, c]\n",
    "# encoder_states = [state_h] # gru\n",
    "\n",
    "# Set up the decoder, using [h, c] as initial state.\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# since the decoder is a \"to-many\" model we want to have\n",
    "# return_sequences=True\n",
    "decoder_lstm = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  return_state=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "  decoder_inputs_x,\n",
    "  initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# decoder_outputs, _ = decoder_gru(\n",
    "#   decoder_inputs_x,\n",
    "#   initial_state=encoder_states\n",
    "# )\n",
    "\n",
    "# final dense layer for predictions\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "# Create the model object\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    # y_true를 int32로 명시적으로 변환\n",
    "    y_true = K.cast(y_true, dtype='int32')\n",
    "\n",
    "    pred = K.argmax(y_pred, axis=-1)  # 예측된 값에서 가장 높은 확률의 인덱스 추출\n",
    "    pred = K.cast(pred, dtype='int32')  # pred도 int32로 변환\n",
    "    correct = K.cast(K.equal(y_true, pred), dtype='float32')\n",
    "\n",
    "    # 패딩 값 0을 제외한 부분에 대한 마스킹\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    n_correct = K.sum(mask * correct)\n",
    "    n_total = K.sum(mask)\n",
    "    return n_correct / n_total\n",
    "\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# encoder_inputs, decoder_inputs, decoder_targets을 int32로 변환\n",
    "encoder_inputs = np.array(encoder_inputs, dtype='int32')\n",
    "decoder_inputs = np.array(decoder_inputs, dtype='int32')\n",
    "decoder_targets = np.array(decoder_targets, dtype='int32')\n",
    "# embedding_matrix는 float32로 유지\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM), dtype='float32')\n",
    "\n",
    "# 모델 컴파일 시 custom loss 대신 SparseCategoricalCrossentropy 사용\n",
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(), metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience  # 얼리스토핑에 사용할 patience\n",
    "        self.wait = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.monitor_acc_threshold = 1  # acc 90% 이상일 때부터 모니터링\n",
    "        self.stop_training_flag = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_acc = logs.get('acc')\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        current_loss = logs.get('loss')\n",
    "        \n",
    "        # acc가 90% 이상일 때부터 모니터링 시작\n",
    "        if current_acc >= self.monitor_acc_threshold:\n",
    "            if current_val_loss > self.best_val_loss or current_loss > self.best_val_loss:\n",
    "                self.wait += 1\n",
    "                print(f\"Early stopping condition met. Waiting: {self.wait}/{self.patience}\")\n",
    "                \n",
    "                if self.wait >= self.patience:\n",
    "                    self.stop_training_flag = True\n",
    "                    self.model.stop_training = True  # 학습 중단\n",
    "            else:\n",
    "                # 더 나은 val_loss 또는 loss가 나오면 best_val_loss 갱신 및 wait 리셋\n",
    "                self.best_val_loss = min(current_val_loss, current_loss)\n",
    "                self.wait = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - acc: 0.0051 - loss: 6.3451 - val_acc: 0.0000e+00 - val_loss: 1.0168\n",
      "Epoch 2/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - acc: 0.0000e+00 - loss: 0.9620 - val_acc: 0.0000e+00 - val_loss: 0.8184\n",
      "Epoch 3/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.0000e+00 - loss: 0.7908 - val_acc: 0.0000e+00 - val_loss: 0.7574\n",
      "Epoch 4/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.0095 - loss: 0.7220 - val_acc: 0.0428 - val_loss: 0.7308\n",
      "Epoch 5/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.0477 - loss: 0.7118 - val_acc: 0.0720 - val_loss: 0.7225\n",
      "Epoch 6/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.0722 - loss: 0.7126 - val_acc: 0.0796 - val_loss: 0.7176\n",
      "Epoch 7/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.0821 - loss: 0.6917 - val_acc: 0.0949 - val_loss: 0.7141\n",
      "Epoch 8/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.0942 - loss: 0.6975 - val_acc: 0.0969 - val_loss: 0.7108\n",
      "Epoch 9/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.0974 - loss: 0.6816 - val_acc: 0.1084 - val_loss: 0.7077\n",
      "Epoch 10/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.1061 - loss: 0.6563 - val_acc: 0.1153 - val_loss: 0.7050\n",
      "Epoch 11/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.1111 - loss: 0.6701 - val_acc: 0.1273 - val_loss: 0.7033\n",
      "Epoch 12/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - acc: 0.1243 - loss: 0.6549 - val_acc: 0.1318 - val_loss: 0.7014\n",
      "Epoch 13/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - acc: 0.1350 - loss: 0.6563 - val_acc: 0.1371 - val_loss: 0.6993\n",
      "Epoch 14/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.1407 - loss: 0.6576 - val_acc: 0.1426 - val_loss: 0.6976\n",
      "Epoch 15/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.1426 - loss: 0.6464 - val_acc: 0.1471 - val_loss: 0.6955\n",
      "Epoch 16/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.1466 - loss: 0.6393 - val_acc: 0.1459 - val_loss: 0.6934\n",
      "Epoch 17/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.1543 - loss: 0.6317 - val_acc: 0.1619 - val_loss: 0.6901\n",
      "Epoch 18/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.1604 - loss: 0.6234 - val_acc: 0.1676 - val_loss: 0.6878\n",
      "Epoch 19/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.1699 - loss: 0.6101 - val_acc: 0.1724 - val_loss: 0.6846\n",
      "Epoch 20/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.1738 - loss: 0.6049 - val_acc: 0.1779 - val_loss: 0.6814\n",
      "Epoch 21/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.1787 - loss: 0.6084 - val_acc: 0.1780 - val_loss: 0.6784\n",
      "Epoch 22/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.1804 - loss: 0.5946 - val_acc: 0.1822 - val_loss: 0.6762\n",
      "Epoch 23/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.1840 - loss: 0.5863 - val_acc: 0.1839 - val_loss: 0.6742\n",
      "Epoch 24/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.1889 - loss: 0.5768 - val_acc: 0.1866 - val_loss: 0.6723\n",
      "Epoch 25/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.1896 - loss: 0.5846 - val_acc: 0.1876 - val_loss: 0.6703\n",
      "Epoch 26/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.1932 - loss: 0.5701 - val_acc: 0.1878 - val_loss: 0.6699\n",
      "Epoch 27/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.1964 - loss: 0.5695 - val_acc: 0.1922 - val_loss: 0.6681\n",
      "Epoch 28/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.2003 - loss: 0.5613 - val_acc: 0.1930 - val_loss: 0.6660\n",
      "Epoch 29/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.2055 - loss: 0.5498 - val_acc: 0.1941 - val_loss: 0.6668\n",
      "Epoch 30/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.2049 - loss: 0.5392 - val_acc: 0.1981 - val_loss: 0.6651\n",
      "Epoch 31/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.2158 - loss: 0.5319 - val_acc: 0.2033 - val_loss: 0.6647\n",
      "Epoch 32/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.2192 - loss: 0.5296 - val_acc: 0.2069 - val_loss: 0.6636\n",
      "Epoch 33/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.2204 - loss: 0.5084 - val_acc: 0.2063 - val_loss: 0.6632\n",
      "Epoch 34/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.2297 - loss: 0.5060 - val_acc: 0.2078 - val_loss: 0.6627\n",
      "Epoch 35/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.2340 - loss: 0.5117 - val_acc: 0.2107 - val_loss: 0.6618\n",
      "Epoch 36/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.2437 - loss: 0.4978 - val_acc: 0.2121 - val_loss: 0.6619\n",
      "Epoch 37/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.2436 - loss: 0.4999 - val_acc: 0.2152 - val_loss: 0.6606\n",
      "Epoch 38/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2504 - loss: 0.4897 - val_acc: 0.2132 - val_loss: 0.6603\n",
      "Epoch 39/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.2536 - loss: 0.4820 - val_acc: 0.2173 - val_loss: 0.6601\n",
      "Epoch 40/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2630 - loss: 0.4785 - val_acc: 0.2173 - val_loss: 0.6595\n",
      "Epoch 41/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2674 - loss: 0.4678 - val_acc: 0.2190 - val_loss: 0.6600\n",
      "Epoch 42/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2727 - loss: 0.4589 - val_acc: 0.2203 - val_loss: 0.6598\n",
      "Epoch 43/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.2804 - loss: 0.4518 - val_acc: 0.2184 - val_loss: 0.6604\n",
      "Epoch 44/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2812 - loss: 0.4526 - val_acc: 0.2200 - val_loss: 0.6607\n",
      "Epoch 45/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.2891 - loss: 0.4408 - val_acc: 0.2239 - val_loss: 0.6618\n",
      "Epoch 46/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.2939 - loss: 0.4295 - val_acc: 0.2236 - val_loss: 0.6614\n",
      "Epoch 47/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.3013 - loss: 0.4246 - val_acc: 0.2233 - val_loss: 0.6627\n",
      "Epoch 48/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.3015 - loss: 0.4161 - val_acc: 0.2241 - val_loss: 0.6628\n",
      "Epoch 49/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.3083 - loss: 0.4093 - val_acc: 0.2260 - val_loss: 0.6632\n",
      "Epoch 50/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.3208 - loss: 0.4054 - val_acc: 0.2262 - val_loss: 0.6648\n",
      "Epoch 51/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.3220 - loss: 0.4032 - val_acc: 0.2227 - val_loss: 0.6648\n",
      "Epoch 52/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.3300 - loss: 0.3936 - val_acc: 0.2244 - val_loss: 0.6663\n",
      "Epoch 53/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.3356 - loss: 0.3918 - val_acc: 0.2245 - val_loss: 0.6671\n",
      "Epoch 54/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.3475 - loss: 0.3736 - val_acc: 0.2239 - val_loss: 0.6677\n",
      "Epoch 55/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.3488 - loss: 0.3676 - val_acc: 0.2258 - val_loss: 0.6687\n",
      "Epoch 56/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.3569 - loss: 0.3643 - val_acc: 0.2244 - val_loss: 0.6700\n",
      "Epoch 57/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.3641 - loss: 0.3577 - val_acc: 0.2261 - val_loss: 0.6719\n",
      "Epoch 58/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - acc: 0.3711 - loss: 0.3417 - val_acc: 0.2237 - val_loss: 0.6727\n",
      "Epoch 59/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - acc: 0.3764 - loss: 0.3483 - val_acc: 0.2262 - val_loss: 0.6741\n",
      "Epoch 60/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.3849 - loss: 0.3472 - val_acc: 0.2260 - val_loss: 0.6749\n",
      "Epoch 61/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.3976 - loss: 0.3299 - val_acc: 0.2242 - val_loss: 0.6762\n",
      "Epoch 62/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.4091 - loss: 0.3280 - val_acc: 0.2257 - val_loss: 0.6780\n",
      "Epoch 63/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.4130 - loss: 0.3204 - val_acc: 0.2226 - val_loss: 0.6804\n",
      "Epoch 64/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.4247 - loss: 0.3121 - val_acc: 0.2225 - val_loss: 0.6810\n",
      "Epoch 65/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - acc: 0.4326 - loss: 0.3143 - val_acc: 0.2252 - val_loss: 0.6817\n",
      "Epoch 66/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - acc: 0.4481 - loss: 0.3008 - val_acc: 0.2244 - val_loss: 0.6829\n",
      "Epoch 67/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - acc: 0.4530 - loss: 0.2987 - val_acc: 0.2230 - val_loss: 0.6856\n",
      "Epoch 68/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - acc: 0.4727 - loss: 0.2875 - val_acc: 0.2254 - val_loss: 0.6867\n",
      "Epoch 69/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.4790 - loss: 0.2860 - val_acc: 0.2250 - val_loss: 0.6877\n",
      "Epoch 70/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.4990 - loss: 0.2775 - val_acc: 0.2251 - val_loss: 0.6894\n",
      "Epoch 71/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.5029 - loss: 0.2708 - val_acc: 0.2258 - val_loss: 0.6920\n",
      "Epoch 72/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.5231 - loss: 0.2605 - val_acc: 0.2258 - val_loss: 0.6925\n",
      "Epoch 73/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.5283 - loss: 0.2620 - val_acc: 0.2240 - val_loss: 0.6932\n",
      "Epoch 74/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.5376 - loss: 0.2496 - val_acc: 0.2226 - val_loss: 0.6960\n",
      "Epoch 75/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.5596 - loss: 0.2436 - val_acc: 0.2239 - val_loss: 0.6979\n",
      "Epoch 76/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.5675 - loss: 0.2364 - val_acc: 0.2235 - val_loss: 0.6989\n",
      "Epoch 77/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.5708 - loss: 0.2398 - val_acc: 0.2258 - val_loss: 0.7007\n",
      "Epoch 78/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.5899 - loss: 0.2279 - val_acc: 0.2228 - val_loss: 0.7023\n",
      "Epoch 79/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - acc: 0.5970 - loss: 0.2265 - val_acc: 0.2256 - val_loss: 0.7034\n",
      "Epoch 80/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.6089 - loss: 0.2166 - val_acc: 0.2261 - val_loss: 0.7061\n",
      "Epoch 81/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.6225 - loss: 0.2119 - val_acc: 0.2261 - val_loss: 0.7075\n",
      "Epoch 82/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.6358 - loss: 0.2017 - val_acc: 0.2242 - val_loss: 0.7088\n",
      "Epoch 83/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.6475 - loss: 0.2017 - val_acc: 0.2243 - val_loss: 0.7111\n",
      "Epoch 84/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.6513 - loss: 0.1960 - val_acc: 0.2282 - val_loss: 0.7116\n",
      "Epoch 85/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.6617 - loss: 0.1865 - val_acc: 0.2253 - val_loss: 0.7151\n",
      "Epoch 86/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.6721 - loss: 0.1914 - val_acc: 0.2272 - val_loss: 0.7157\n",
      "Epoch 87/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.6860 - loss: 0.1796 - val_acc: 0.2234 - val_loss: 0.7185\n",
      "Epoch 88/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.6929 - loss: 0.1812 - val_acc: 0.2255 - val_loss: 0.7188\n",
      "Epoch 89/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.7032 - loss: 0.1719 - val_acc: 0.2244 - val_loss: 0.7215\n",
      "Epoch 90/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.7064 - loss: 0.1748 - val_acc: 0.2245 - val_loss: 0.7233\n",
      "Epoch 91/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.7192 - loss: 0.1669 - val_acc: 0.2233 - val_loss: 0.7244\n",
      "Epoch 92/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.7321 - loss: 0.1594 - val_acc: 0.2265 - val_loss: 0.7254\n",
      "Epoch 93/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.7360 - loss: 0.1597 - val_acc: 0.2225 - val_loss: 0.7281\n",
      "Epoch 94/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.7415 - loss: 0.1513 - val_acc: 0.2258 - val_loss: 0.7289\n",
      "Epoch 95/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - acc: 0.7521 - loss: 0.1492 - val_acc: 0.2235 - val_loss: 0.7314\n",
      "Epoch 96/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - acc: 0.7653 - loss: 0.1466 - val_acc: 0.2258 - val_loss: 0.7325\n",
      "Epoch 97/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.7632 - loss: 0.1400 - val_acc: 0.2256 - val_loss: 0.7345\n",
      "Epoch 98/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.7758 - loss: 0.1359 - val_acc: 0.2266 - val_loss: 0.7374\n",
      "Epoch 99/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.7780 - loss: 0.1355 - val_acc: 0.2221 - val_loss: 0.7387\n",
      "Epoch 100/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - acc: 0.7889 - loss: 0.1307 - val_acc: 0.2244 - val_loss: 0.7408\n",
      "Epoch 101/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - acc: 0.7977 - loss: 0.1266 - val_acc: 0.2246 - val_loss: 0.7424\n",
      "Epoch 102/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.8011 - loss: 0.1273 - val_acc: 0.2212 - val_loss: 0.7440\n",
      "Epoch 103/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.8051 - loss: 0.1227 - val_acc: 0.2207 - val_loss: 0.7466\n",
      "Epoch 104/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - acc: 0.8146 - loss: 0.1186 - val_acc: 0.2224 - val_loss: 0.7475\n",
      "Epoch 105/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.8180 - loss: 0.1160 - val_acc: 0.2199 - val_loss: 0.7494\n",
      "Epoch 106/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.8286 - loss: 0.1103 - val_acc: 0.2226 - val_loss: 0.7502\n",
      "Epoch 107/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.8327 - loss: 0.1123 - val_acc: 0.2209 - val_loss: 0.7525\n",
      "Epoch 108/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - acc: 0.8408 - loss: 0.1050 - val_acc: 0.2231 - val_loss: 0.7544\n",
      "Epoch 109/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.8445 - loss: 0.1036 - val_acc: 0.2239 - val_loss: 0.7555\n",
      "Epoch 110/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.8524 - loss: 0.1011 - val_acc: 0.2208 - val_loss: 0.7584\n",
      "Epoch 111/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.8570 - loss: 0.0974 - val_acc: 0.2216 - val_loss: 0.7594\n",
      "Epoch 112/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.8586 - loss: 0.0971 - val_acc: 0.2239 - val_loss: 0.7597\n",
      "Epoch 113/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.8625 - loss: 0.0934 - val_acc: 0.2245 - val_loss: 0.7625\n",
      "Epoch 114/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.8684 - loss: 0.0914 - val_acc: 0.2240 - val_loss: 0.7638\n",
      "Epoch 115/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.8696 - loss: 0.0904 - val_acc: 0.2237 - val_loss: 0.7666\n",
      "Epoch 116/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.8777 - loss: 0.0865 - val_acc: 0.2227 - val_loss: 0.7679\n",
      "Epoch 117/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.8808 - loss: 0.0843 - val_acc: 0.2225 - val_loss: 0.7688\n",
      "Epoch 118/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - acc: 0.8877 - loss: 0.0832 - val_acc: 0.2221 - val_loss: 0.7710\n",
      "Epoch 119/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.8881 - loss: 0.0796 - val_acc: 0.2200 - val_loss: 0.7729\n",
      "Epoch 120/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.8888 - loss: 0.0811 - val_acc: 0.2184 - val_loss: 0.7752\n",
      "Epoch 121/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.8953 - loss: 0.0766 - val_acc: 0.2235 - val_loss: 0.7755\n",
      "Epoch 122/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9013 - loss: 0.0735 - val_acc: 0.2215 - val_loss: 0.7765\n",
      "Epoch 123/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9034 - loss: 0.0715 - val_acc: 0.2201 - val_loss: 0.7780\n",
      "Epoch 124/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9083 - loss: 0.0693 - val_acc: 0.2207 - val_loss: 0.7801\n",
      "Epoch 125/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9104 - loss: 0.0697 - val_acc: 0.2219 - val_loss: 0.7821\n",
      "Epoch 126/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9148 - loss: 0.0665 - val_acc: 0.2182 - val_loss: 0.7846\n",
      "Epoch 127/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9142 - loss: 0.0654 - val_acc: 0.2221 - val_loss: 0.7862\n",
      "Epoch 128/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9210 - loss: 0.0626 - val_acc: 0.2221 - val_loss: 0.7871\n",
      "Epoch 129/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9233 - loss: 0.0632 - val_acc: 0.2216 - val_loss: 0.7891\n",
      "Epoch 130/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9281 - loss: 0.0596 - val_acc: 0.2211 - val_loss: 0.7895\n",
      "Epoch 131/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9264 - loss: 0.0604 - val_acc: 0.2219 - val_loss: 0.7915\n",
      "Epoch 132/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9332 - loss: 0.0567 - val_acc: 0.2221 - val_loss: 0.7918\n",
      "Epoch 133/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9300 - loss: 0.0567 - val_acc: 0.2192 - val_loss: 0.7958\n",
      "Epoch 134/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9377 - loss: 0.0544 - val_acc: 0.2195 - val_loss: 0.7966\n",
      "Epoch 135/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.9426 - loss: 0.0509 - val_acc: 0.2182 - val_loss: 0.7968\n",
      "Epoch 136/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9417 - loss: 0.0511 - val_acc: 0.2192 - val_loss: 0.7999\n",
      "Epoch 137/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9439 - loss: 0.0511 - val_acc: 0.2204 - val_loss: 0.8003\n",
      "Epoch 138/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9466 - loss: 0.0486 - val_acc: 0.2179 - val_loss: 0.8026\n",
      "Epoch 139/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9477 - loss: 0.0475 - val_acc: 0.2179 - val_loss: 0.8040\n",
      "Epoch 140/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9503 - loss: 0.0477 - val_acc: 0.2172 - val_loss: 0.8068\n",
      "Epoch 141/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9545 - loss: 0.0444 - val_acc: 0.2180 - val_loss: 0.8072\n",
      "Epoch 142/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9555 - loss: 0.0445 - val_acc: 0.2182 - val_loss: 0.8094\n",
      "Epoch 143/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9559 - loss: 0.0440 - val_acc: 0.2203 - val_loss: 0.8107\n",
      "Epoch 144/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9563 - loss: 0.0425 - val_acc: 0.2175 - val_loss: 0.8118\n",
      "Epoch 145/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9619 - loss: 0.0405 - val_acc: 0.2195 - val_loss: 0.8134\n",
      "Epoch 146/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9603 - loss: 0.0404 - val_acc: 0.2182 - val_loss: 0.8142\n",
      "Epoch 147/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9630 - loss: 0.0393 - val_acc: 0.2200 - val_loss: 0.8166\n",
      "Epoch 148/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9644 - loss: 0.0384 - val_acc: 0.2198 - val_loss: 0.8180\n",
      "Epoch 149/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9657 - loss: 0.0368 - val_acc: 0.2187 - val_loss: 0.8189\n",
      "Epoch 150/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - acc: 0.9686 - loss: 0.0358 - val_acc: 0.2174 - val_loss: 0.8211\n",
      "Epoch 151/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9706 - loss: 0.0356 - val_acc: 0.2194 - val_loss: 0.8226\n",
      "Epoch 152/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9716 - loss: 0.0333 - val_acc: 0.2169 - val_loss: 0.8255\n",
      "Epoch 153/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.9728 - loss: 0.0331 - val_acc: 0.2169 - val_loss: 0.8246\n",
      "Epoch 154/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.9736 - loss: 0.0313 - val_acc: 0.2168 - val_loss: 0.8274\n",
      "Epoch 155/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.9752 - loss: 0.0314 - val_acc: 0.2180 - val_loss: 0.8288\n",
      "Epoch 156/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - acc: 0.9752 - loss: 0.0319 - val_acc: 0.2183 - val_loss: 0.8302\n",
      "Epoch 157/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - acc: 0.9772 - loss: 0.0303 - val_acc: 0.2177 - val_loss: 0.8316\n",
      "Epoch 158/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9760 - loss: 0.0310 - val_acc: 0.2157 - val_loss: 0.8338\n",
      "Epoch 159/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.9770 - loss: 0.0306 - val_acc: 0.2176 - val_loss: 0.8353\n",
      "Epoch 160/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - acc: 0.9808 - loss: 0.0282 - val_acc: 0.2183 - val_loss: 0.8355\n",
      "Epoch 161/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - acc: 0.9822 - loss: 0.0272 - val_acc: 0.2155 - val_loss: 0.8370\n",
      "Epoch 162/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.9823 - loss: 0.0259 - val_acc: 0.2170 - val_loss: 0.8387\n",
      "Epoch 163/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.9833 - loss: 0.0261 - val_acc: 0.2177 - val_loss: 0.8399\n",
      "Epoch 164/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - acc: 0.9830 - loss: 0.0254 - val_acc: 0.2178 - val_loss: 0.8409\n",
      "Epoch 165/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9854 - loss: 0.0244 - val_acc: 0.2165 - val_loss: 0.8421\n",
      "Epoch 166/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9852 - loss: 0.0242 - val_acc: 0.2172 - val_loss: 0.8432\n",
      "Epoch 167/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9873 - loss: 0.0230 - val_acc: 0.2173 - val_loss: 0.8454\n",
      "Epoch 168/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9864 - loss: 0.0224 - val_acc: 0.2164 - val_loss: 0.8472\n",
      "Epoch 169/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9872 - loss: 0.0225 - val_acc: 0.2164 - val_loss: 0.8488\n",
      "Epoch 170/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9857 - loss: 0.0228 - val_acc: 0.2152 - val_loss: 0.8498\n",
      "Epoch 171/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9868 - loss: 0.0227 - val_acc: 0.2153 - val_loss: 0.8507\n",
      "Epoch 172/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.9875 - loss: 0.0217 - val_acc: 0.2157 - val_loss: 0.8512\n",
      "Epoch 173/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - acc: 0.9885 - loss: 0.0206 - val_acc: 0.2155 - val_loss: 0.8518\n",
      "Epoch 174/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.9898 - loss: 0.0204 - val_acc: 0.2170 - val_loss: 0.8542\n",
      "Epoch 175/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.9909 - loss: 0.0195 - val_acc: 0.2177 - val_loss: 0.8550\n",
      "Epoch 176/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.9909 - loss: 0.0191 - val_acc: 0.2146 - val_loss: 0.8559\n",
      "Epoch 177/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.9917 - loss: 0.0191 - val_acc: 0.2167 - val_loss: 0.8567\n",
      "Epoch 178/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.9918 - loss: 0.0184 - val_acc: 0.2149 - val_loss: 0.8586\n",
      "Epoch 179/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - acc: 0.9927 - loss: 0.0172 - val_acc: 0.2153 - val_loss: 0.8607\n",
      "Epoch 180/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.9939 - loss: 0.0166 - val_acc: 0.2170 - val_loss: 0.8610\n",
      "Epoch 181/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.9940 - loss: 0.0160 - val_acc: 0.2154 - val_loss: 0.8629\n",
      "Epoch 182/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9943 - loss: 0.0161 - val_acc: 0.2133 - val_loss: 0.8642\n",
      "Epoch 183/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9948 - loss: 0.0158 - val_acc: 0.2155 - val_loss: 0.8646\n",
      "Epoch 184/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9937 - loss: 0.0161 - val_acc: 0.2138 - val_loss: 0.8681\n",
      "Epoch 185/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9949 - loss: 0.0150 - val_acc: 0.2166 - val_loss: 0.8678\n",
      "Epoch 186/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9946 - loss: 0.0151 - val_acc: 0.2143 - val_loss: 0.8677\n",
      "Epoch 187/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9923 - loss: 0.0168 - val_acc: 0.2158 - val_loss: 0.8681\n",
      "Epoch 188/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9907 - loss: 0.0172 - val_acc: 0.2149 - val_loss: 0.8703\n",
      "Epoch 189/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9938 - loss: 0.0156 - val_acc: 0.2165 - val_loss: 0.8673\n",
      "Epoch 190/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9945 - loss: 0.0152 - val_acc: 0.2168 - val_loss: 0.8697\n",
      "Epoch 191/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9958 - loss: 0.0137 - val_acc: 0.2159 - val_loss: 0.8713\n",
      "Epoch 192/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9967 - loss: 0.0130 - val_acc: 0.2153 - val_loss: 0.8734\n",
      "Epoch 193/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9971 - loss: 0.0127 - val_acc: 0.2154 - val_loss: 0.8737\n",
      "Epoch 194/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9974 - loss: 0.0123 - val_acc: 0.2147 - val_loss: 0.8762\n",
      "Epoch 195/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9973 - loss: 0.0120 - val_acc: 0.2136 - val_loss: 0.8776\n",
      "Epoch 196/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9973 - loss: 0.0113 - val_acc: 0.2127 - val_loss: 0.8790\n",
      "Epoch 197/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9976 - loss: 0.0116 - val_acc: 0.2126 - val_loss: 0.8796\n",
      "Epoch 198/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9975 - loss: 0.0112 - val_acc: 0.2128 - val_loss: 0.8809\n",
      "Epoch 199/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9984 - loss: 0.0108 - val_acc: 0.2133 - val_loss: 0.8818\n",
      "Epoch 200/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9978 - loss: 0.0108 - val_acc: 0.2139 - val_loss: 0.8837\n",
      "Epoch 201/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9983 - loss: 0.0102 - val_acc: 0.2135 - val_loss: 0.8845\n",
      "Epoch 202/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9987 - loss: 0.0100 - val_acc: 0.2130 - val_loss: 0.8869\n",
      "Epoch 203/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 0.9984 - loss: 0.0099 - val_acc: 0.2125 - val_loss: 0.8868\n",
      "Epoch 204/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9984 - loss: 0.0097 - val_acc: 0.2114 - val_loss: 0.8878\n",
      "Epoch 205/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - acc: 0.9986 - loss: 0.0098 - val_acc: 0.2118 - val_loss: 0.8888\n",
      "Epoch 206/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - acc: 0.9981 - loss: 0.0096 - val_acc: 0.2125 - val_loss: 0.8905\n",
      "Epoch 207/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9988 - loss: 0.0093 - val_acc: 0.2134 - val_loss: 0.8913\n",
      "Epoch 208/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9986 - loss: 0.0095 - val_acc: 0.2128 - val_loss: 0.8928\n",
      "Epoch 209/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9990 - loss: 0.0086 - val_acc: 0.2109 - val_loss: 0.8938\n",
      "Epoch 210/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9981 - loss: 0.0092 - val_acc: 0.2142 - val_loss: 0.8931\n",
      "Epoch 211/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9979 - loss: 0.0095 - val_acc: 0.2154 - val_loss: 0.8917\n",
      "Epoch 212/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9969 - loss: 0.0100 - val_acc: 0.2144 - val_loss: 0.8927\n",
      "Epoch 213/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9972 - loss: 0.0102 - val_acc: 0.2166 - val_loss: 0.8936\n",
      "Epoch 214/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9985 - loss: 0.0094 - val_acc: 0.2177 - val_loss: 0.8932\n",
      "Epoch 215/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9988 - loss: 0.0087 - val_acc: 0.2144 - val_loss: 0.8953\n",
      "Epoch 216/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9991 - loss: 0.0083 - val_acc: 0.2137 - val_loss: 0.8961\n",
      "Epoch 217/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9993 - loss: 0.0077 - val_acc: 0.2159 - val_loss: 0.8963\n",
      "Epoch 218/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9988 - loss: 0.0080 - val_acc: 0.2139 - val_loss: 0.8991\n",
      "Epoch 219/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9990 - loss: 0.0073 - val_acc: 0.2131 - val_loss: 0.8989\n",
      "Epoch 220/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - acc: 0.9995 - loss: 0.0070 - val_acc: 0.2139 - val_loss: 0.9006\n",
      "Epoch 221/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - acc: 0.9996 - loss: 0.0071 - val_acc: 0.2139 - val_loss: 0.9017\n",
      "Epoch 222/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - acc: 0.9994 - loss: 0.0069 - val_acc: 0.2129 - val_loss: 0.9029\n",
      "Epoch 223/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.9995 - loss: 0.0065 - val_acc: 0.2117 - val_loss: 0.9046\n",
      "Epoch 224/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.9996 - loss: 0.0063 - val_acc: 0.2123 - val_loss: 0.9058\n",
      "Epoch 225/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - acc: 0.9996 - loss: 0.0062 - val_acc: 0.2119 - val_loss: 0.9072\n",
      "Epoch 226/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.9997 - loss: 0.0061 - val_acc: 0.2136 - val_loss: 0.9074\n",
      "Epoch 227/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.9998 - loss: 0.0061 - val_acc: 0.2124 - val_loss: 0.9085\n",
      "Epoch 228/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - acc: 0.9997 - loss: 0.0059 - val_acc: 0.2119 - val_loss: 0.9098\n",
      "Epoch 229/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - acc: 0.9998 - loss: 0.0058 - val_acc: 0.2104 - val_loss: 0.9106\n",
      "Epoch 230/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - acc: 0.9996 - loss: 0.0058 - val_acc: 0.2118 - val_loss: 0.9119\n",
      "Epoch 231/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - acc: 0.9998 - loss: 0.0055 - val_acc: 0.2130 - val_loss: 0.9124\n",
      "Epoch 232/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - acc: 0.9998 - loss: 0.0056 - val_acc: 0.2121 - val_loss: 0.9134\n",
      "Epoch 233/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - acc: 0.9999 - loss: 0.0056 - val_acc: 0.2136 - val_loss: 0.9137\n",
      "Epoch 234/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0054 - val_acc: 0.2142 - val_loss: 0.9157\n",
      "Epoch 235/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0053 - val_acc: 0.2120 - val_loss: 0.9161\n",
      "Epoch 236/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9997 - loss: 0.0055 - val_acc: 0.2127 - val_loss: 0.9161\n",
      "Epoch 237/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0053 - val_acc: 0.2126 - val_loss: 0.9170\n",
      "Epoch 238/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9997 - loss: 0.0056 - val_acc: 0.2130 - val_loss: 0.9173\n",
      "Epoch 239/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9993 - loss: 0.0061 - val_acc: 0.2168 - val_loss: 0.9174\n",
      "Epoch 240/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - acc: 0.9987 - loss: 0.0066 - val_acc: 0.2158 - val_loss: 0.9168\n",
      "Epoch 241/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9980 - loss: 0.0069 - val_acc: 0.2126 - val_loss: 0.9155\n",
      "Epoch 242/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 0.9966 - loss: 0.0079 - val_acc: 0.2161 - val_loss: 0.9139\n",
      "Epoch 243/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9962 - loss: 0.0081 - val_acc: 0.2159 - val_loss: 0.9149\n",
      "Epoch 244/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9970 - loss: 0.0077 - val_acc: 0.2171 - val_loss: 0.9122\n",
      "Epoch 245/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9983 - loss: 0.0069 - val_acc: 0.2160 - val_loss: 0.9133\n",
      "Epoch 246/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9984 - loss: 0.0064 - val_acc: 0.2177 - val_loss: 0.9134\n",
      "Epoch 247/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9991 - loss: 0.0059 - val_acc: 0.2204 - val_loss: 0.9138\n",
      "Epoch 248/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9994 - loss: 0.0054 - val_acc: 0.2167 - val_loss: 0.9164\n",
      "Epoch 249/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9998 - loss: 0.0047 - val_acc: 0.2184 - val_loss: 0.9175\n",
      "Epoch 250/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9999 - loss: 0.0044 - val_acc: 0.2190 - val_loss: 0.9193\n",
      "Epoch 251/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9998 - loss: 0.0043 - val_acc: 0.2185 - val_loss: 0.9202\n",
      "Epoch 252/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 1.0000 - loss: 0.0042 - val_acc: 0.2182 - val_loss: 0.9213\n",
      "Epoch 253/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 1.0000 - loss: 0.0042 - val_acc: 0.2176 - val_loss: 0.9226\n",
      "Epoch 254/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 1.0000 - loss: 0.0040 - val_acc: 0.2180 - val_loss: 0.9234\n",
      "Epoch 255/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 1.0000 - loss: 0.0038 - val_acc: 0.2185 - val_loss: 0.9248\n",
      "Epoch 256/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - acc: 1.0000 - loss: 0.0037 - val_acc: 0.2177 - val_loss: 0.9253\n",
      "Epoch 257/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 1.0000 - loss: 0.0038 - val_acc: 0.2190 - val_loss: 0.9265\n",
      "Epoch 258/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9999 - loss: 0.0036 - val_acc: 0.2181 - val_loss: 0.9273\n",
      "Epoch 259/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 1.0000 - loss: 0.0038 - val_acc: 0.2182 - val_loss: 0.9286\n",
      "Epoch 260/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0036 - val_acc: 0.2181 - val_loss: 0.9292\n",
      "Epoch 261/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - acc: 0.9999 - loss: 0.0035 - val_acc: 0.2178 - val_loss: 0.9303\n",
      "Epoch 262/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0035 - val_acc: 0.2181 - val_loss: 0.9309\n",
      "Epoch 263/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9999 - loss: 0.0035 - val_acc: 0.2181 - val_loss: 0.9317\n",
      "Epoch 264/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - acc: 1.0000 - loss: 0.0034 - val_acc: 0.2172 - val_loss: 0.9327\n",
      "Epoch 265/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9999 - loss: 0.0035 - val_acc: 0.2174 - val_loss: 0.9334\n",
      "Epoch 266/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0033 - val_acc: 0.2179 - val_loss: 0.9341\n",
      "Epoch 267/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9998 - loss: 0.0034 - val_acc: 0.2166 - val_loss: 0.9348\n",
      "Epoch 268/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9995 - loss: 0.0036 - val_acc: 0.2149 - val_loss: 0.9362\n",
      "Epoch 269/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - acc: 0.9996 - loss: 0.0036 - val_acc: 0.2175 - val_loss: 0.9357\n",
      "Epoch 270/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9995 - loss: 0.0038 - val_acc: 0.2157 - val_loss: 0.9356\n",
      "Epoch 271/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9998 - loss: 0.0036 - val_acc: 0.2179 - val_loss: 0.9348\n",
      "Epoch 272/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0035 - val_acc: 0.2169 - val_loss: 0.9367\n",
      "Epoch 273/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9999 - loss: 0.0033 - val_acc: 0.2151 - val_loss: 0.9363\n",
      "Epoch 274/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9996 - loss: 0.0038 - val_acc: 0.2184 - val_loss: 0.9359\n",
      "Epoch 275/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9981 - loss: 0.0049 - val_acc: 0.2172 - val_loss: 0.9353\n",
      "Epoch 276/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 0.9992 - loss: 0.0044 - val_acc: 0.2196 - val_loss: 0.9343\n",
      "Epoch 277/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 0.9995 - loss: 0.0040 - val_acc: 0.2166 - val_loss: 0.9348\n",
      "Epoch 278/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0037 - val_acc: 0.2190 - val_loss: 0.9356\n",
      "Epoch 279/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9998 - loss: 0.0035 - val_acc: 0.2191 - val_loss: 0.9381\n",
      "Epoch 280/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - acc: 0.9999 - loss: 0.0031 - val_acc: 0.2176 - val_loss: 0.9387\n",
      "Epoch 281/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0030 - val_acc: 0.2187 - val_loss: 0.9396\n",
      "Epoch 282/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0028 - val_acc: 0.2188 - val_loss: 0.9409\n",
      "Epoch 283/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - acc: 1.0000 - loss: 0.0027Early stopping condition met. Waiting: 1/2\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - acc: 1.0000 - loss: 0.0027 - val_acc: 0.2179 - val_loss: 0.9416\n",
      "Epoch 284/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0027 - val_acc: 0.2174 - val_loss: 0.9425\n",
      "Epoch 285/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - acc: 1.0000 - loss: 0.0027Early stopping condition met. Waiting: 2/2\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - acc: 1.0000 - loss: 0.0027 - val_acc: 0.2173 - val_loss: 0.9436\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 중 얼리스토핑 콜백 적용\n",
    "early_stopping_callback = CustomEarlyStopping(patience=2)  # patience는 얼리스토핑 전에 기다리는 에포크 수\n",
    "\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs], decoder_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    "  callbacks=[early_stopping_callback]  # 얼리 스토핑 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 가중치 비교\n",
    "original_weights = model.get_weights()\n",
    "\n",
    "# 모델을 저장\n",
    "model.save(PATH_MODEL)\n",
    "\n",
    "# 모델을 불러옴\n",
    "model_loaded = load_model(PATH_MODEL, custom_objects={'custom_loss': custom_loss, 'acc': acc})\n",
    "\n",
    "# 불러온 모델의 가중치\n",
    "loaded_weights = model_loaded.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n"
     ]
    }
   ],
   "source": [
    "# 가중치 비교\n",
    "for original, loaded in zip(original_weights, loaded_weights):\n",
    "    if np.array_equal(original, loaded):\n",
    "        print(\"가중치 일치\")\n",
    "    else:\n",
    "        print(\"가중치 불일치\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# this time, we want to keep the states too, to be output\n",
    "# by our sampling model\n",
    "decoder_outputs, h, c = decoder_lstm(\n",
    "  decoder_inputs_single_x,\n",
    "  initial_state=decoder_states_inputs\n",
    ")\n",
    "# decoder_outputs, state_h = decoder_lstm(\n",
    "#   decoder_inputs_single_x,\n",
    "#   initial_state=decoder_states_inputs\n",
    "# ) #gru\n",
    "decoder_states = [h, c]\n",
    "# decoder_states = [h] # gru\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The sampling model\n",
    "# inputs: y(t-1), h(t-1), c(t-1)\n",
    "# outputs: y(t), h(t), c(t)\n",
    "decoder_model = Model(\n",
    "  [decoder_inputs_single] + decoder_states_inputs, \n",
    "  [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    output_tokens, h, c = decoder_model.predict(\n",
    "      [target_seq] + states_value\n",
    "    )\n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "    # Get next wordgfhjfghj\n",
    "    idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    # states_value = [h] # gru\n",
    "\n",
    "  return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_model.save(PATH_ENCODER_MODEL)\n",
    "decoder_model.save(PATH_DECODER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "-\n",
      "Input: when did playhouse square reopen ?\n",
      "Translation: playhousesquare , in the cleveland theater district in downtown cleveland , ohio , is the second-largest theater complex in the united states , second only to new york city 's lincoln center ) .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Do some test translations\n",
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "-\n",
      "Input: How are the directions of the velocity and force vectors related in a circular motion\n",
      "Translation: in physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path .\n"
     ]
    }
   ],
   "source": [
    "  # Do some test translations\n",
    "i = 1\n",
    "print(i)\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
