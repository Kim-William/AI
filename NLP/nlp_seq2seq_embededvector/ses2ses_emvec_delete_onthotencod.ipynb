{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow[and-cuda]\n",
    "#asdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n",
      "Data/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "# # https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
    "# get the data at: http://www.manythings.org/anki/\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "  import tensorflow.keras.backend as K\n",
    "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "except:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPUs found\")\n",
    "else:\n",
    "    print(f\"GPUs available: {gpus}\")\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "# some config\n",
    "BATCH_SIZE = 64  # Batch size for training.\n",
    "EPOCHS = 2000  # Number of epochs to train for.\n",
    "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\n",
    "NUM_SAMPLES = 20360  # Number of samples to train on.\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "\n",
    "PATH_SAVEMODEL = 'SavedModel/240912_1640'\n",
    "PATH_DATA_ROOT = 'Data'\n",
    "\n",
    "PATH_EMBEDDING = f'{PATH_DATA_ROOT}/glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "\n",
    "PATH_TOKENIZER_OUTPUT = os.path.join('%s/tokenizer_output.pickle' % PATH_SAVEMODEL)\n",
    "PATH_TOKENIZER_INPUT = os.path.join('%s/tokenizer_input.pickle' % PATH_SAVEMODEL)\n",
    "\n",
    "PATH_MODEL= os.path.join('%s/s2s.h5' % PATH_SAVEMODEL)\n",
    "PATH_TRAIN = os.path.join('%s/train.txt' % PATH_DATA_ROOT)\n",
    "PATH_ENCODER_MODEL = os.path.join('%s/encoder_model.h5' % PATH_SAVEMODEL)\n",
    "PATH_DECODER_MODEL = os.path.join('%s/decoder_model.h5' % PATH_SAVEMODEL)\n",
    "\n",
    "PATH_SEQUENCE_FILE = os.path.join('%s/input_sequences.pkl' % PATH_SAVEMODEL)\n",
    "PATH_TARGET_SEQUENCE_FILE = os.path.join('%s/target_sequences.pkl' % PATH_SAVEMODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 행의 개수: 20359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# 파일에서 DataFrame 읽기 (예: CSV 파일)\n",
    "df = pd.read_csv(PATH_TRAIN, delimiter='\\t')\n",
    "\n",
    "# 전체 행의 수 확인\n",
    "print(f\"전체 행의 개수: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 2118\n"
     ]
    }
   ],
   "source": [
    "# 중복된 input_text를 추적할 집합을 생성\n",
    "seen_input_texts = set()\n",
    "t=0\n",
    "for line in open(PATH_TRAIN, encoding='utf-8'):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "\n",
    "    # input and target are separated by tab\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    line_split = line.rstrip().split('\\t')\n",
    "\n",
    "    # 두 번째 열 (인덱스 1)에 해당하는 input_text\n",
    "    input_text = line_split[0].strip()  # 공백 제거\n",
    "\n",
    "    # 중복된 input_text가 이미 처리되었는지 확인\n",
    "    if input_text in seen_input_texts:\n",
    "        continue  # 중복된 경우 스킵\n",
    "\n",
    "    # 중복되지 않은 input_text는 집합에 추가\n",
    "    seen_input_texts.add(input_text)\n",
    "\n",
    "    # 다섯 번째 열 (인덱스 4)에 해당하는 translation\n",
    "    translation = line_split[1].strip()  # 공백 제거\n",
    "\n",
    "    # split up the input and translation\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4048 unique input tokens.\n",
      "Found 9782 unique output tokens.\n",
      "encoder_inputs.shape: (2118, 23)\n",
      "encoder_inputs[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    5    9 1301 1302  164]\n",
      "decoder_inputs[0]: [   9    5 3973 3974 2357 3975   22 3976 3977 2357    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder_inputs.shape: (2118, 237)\n",
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Filling pre-trained embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woong/study_ai/nlp_seq2seq_embededvector/.venv/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1726138965.991007  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726138965.991098  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726138965.991124  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726138966.235875  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726138966.235977  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-12 13:02:46.235991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1726138966.236035  542972 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-12 13:02:46.236062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# Tokenizer 저장\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_INPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_inputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # Tokenizer 불러오기\n",
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer_inputs = pickle.load(handle)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# Tokenizer 저장\n",
    "import pickle\n",
    "with open(PATH_TOKENIZER_OUTPUT, 'wb') as handle:\n",
    "    pickle.dump(tokenizer_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "\n",
    "\n",
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(PATH_EMBEDDING, encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n",
    "\n",
    "##### build the model #####\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_state=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "# encoder_outputs, h = encoder(x) #gru\n",
    "\n",
    "# keep only the states to pass into decoder\n",
    "encoder_states = [h, c]\n",
    "# encoder_states = [state_h] # gru\n",
    "\n",
    "# Set up the decoder, using [h, c] as initial state.\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# since the decoder is a \"to-many\" model we want to have\n",
    "# return_sequences=True\n",
    "decoder_lstm = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  return_state=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "  decoder_inputs_x,\n",
    "  initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# decoder_outputs, _ = decoder_gru(\n",
    "#   decoder_inputs_x,\n",
    "#   initial_state=encoder_states\n",
    "# )\n",
    "\n",
    "# final dense layer for predictions\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "# Create the model object\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    # y_true를 int32로 명시적으로 변환\n",
    "    y_true = K.cast(y_true, dtype='int32')\n",
    "\n",
    "    pred = K.argmax(y_pred, axis=-1)  # 예측된 값에서 가장 높은 확률의 인덱스 추출\n",
    "    pred = K.cast(pred, dtype='int32')  # pred도 int32로 변환\n",
    "    correct = K.cast(K.equal(y_true, pred), dtype='float32')\n",
    "\n",
    "    # 패딩 값 0을 제외한 부분에 대한 마스킹\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    n_correct = K.sum(mask * correct)\n",
    "    n_total = K.sum(mask)\n",
    "    return n_correct / n_total\n",
    "\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# encoder_inputs, decoder_inputs, decoder_targets을 int32로 변환\n",
    "encoder_inputs = np.array(encoder_inputs, dtype='int32')\n",
    "decoder_inputs = np.array(decoder_inputs, dtype='int32')\n",
    "decoder_targets = np.array(decoder_targets, dtype='int32')\n",
    "# embedding_matrix는 float32로 유지\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM), dtype='float32')\n",
    "\n",
    "# 모델 컴파일 시 custom loss 대신 SparseCategoricalCrossentropy 사용\n",
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(), metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience  # 얼리스토핑에 사용할 patience\n",
    "        self.wait = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.monitor_acc_threshold = 1  # acc 90% 이상일 때부터 모니터링\n",
    "        self.stop_training_flag = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_acc = logs.get('acc')\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        current_loss = logs.get('loss')\n",
    "        \n",
    "        # acc가 90% 이상일 때부터 모니터링 시작\n",
    "        if current_acc >= self.monitor_acc_threshold:\n",
    "            if current_val_loss > self.best_val_loss or current_loss > self.best_val_loss:\n",
    "                self.wait += 1\n",
    "                print(f\"Early stopping condition met. Waiting: {self.wait}/{self.patience}\")\n",
    "                \n",
    "                if self.wait >= self.patience:\n",
    "                    self.stop_training_flag = True\n",
    "                    self.model.stop_training = True  # 학습 중단\n",
    "            else:\n",
    "                # 더 나은 val_loss 또는 loss가 나오면 best_val_loss 갱신 및 wait 리셋\n",
    "                self.best_val_loss = min(current_val_loss, current_loss)\n",
    "                self.wait = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:02:50.097392: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step - acc: 0.0034 - loss: 6.5239 - val_acc: 0.0000e+00 - val_loss: 1.0120\n",
      "Epoch 2/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.0000e+00 - loss: 0.9803 - val_acc: 0.0000e+00 - val_loss: 0.8755\n",
      "Epoch 3/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - acc: 0.0000e+00 - loss: 0.8267 - val_acc: 0.0000e+00 - val_loss: 0.7743\n",
      "Epoch 4/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.0029 - loss: 0.7414 - val_acc: 0.0251 - val_loss: 0.7392\n",
      "Epoch 5/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.0374 - loss: 0.7196 - val_acc: 0.0627 - val_loss: 0.7252\n",
      "Epoch 6/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.0570 - loss: 0.7012 - val_acc: 0.0722 - val_loss: 0.7198\n",
      "Epoch 7/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.0750 - loss: 0.7028 - val_acc: 0.0905 - val_loss: 0.7163\n",
      "Epoch 8/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.0863 - loss: 0.6968 - val_acc: 0.0965 - val_loss: 0.7132\n",
      "Epoch 9/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.0974 - loss: 0.6838 - val_acc: 0.1182 - val_loss: 0.7102\n",
      "Epoch 10/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.1134 - loss: 0.6904 - val_acc: 0.1301 - val_loss: 0.7073\n",
      "Epoch 11/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.1266 - loss: 0.6849 - val_acc: 0.1391 - val_loss: 0.7044\n",
      "Epoch 12/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.1373 - loss: 0.6528 - val_acc: 0.1362 - val_loss: 0.7017\n",
      "Epoch 13/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.1363 - loss: 0.6643 - val_acc: 0.1386 - val_loss: 0.6997\n",
      "Epoch 14/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - acc: 0.1392 - loss: 0.6448 - val_acc: 0.1385 - val_loss: 0.6972\n",
      "Epoch 15/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1404 - loss: 0.6437 - val_acc: 0.1455 - val_loss: 0.6944\n",
      "Epoch 16/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.1431 - loss: 0.6496 - val_acc: 0.1488 - val_loss: 0.6920\n",
      "Epoch 17/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.1499 - loss: 0.6344 - val_acc: 0.1601 - val_loss: 0.6886\n",
      "Epoch 18/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1571 - loss: 0.6176 - val_acc: 0.1667 - val_loss: 0.6849\n",
      "Epoch 19/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1657 - loss: 0.6316 - val_acc: 0.1743 - val_loss: 0.6815\n",
      "Epoch 20/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1738 - loss: 0.6156 - val_acc: 0.1762 - val_loss: 0.6781\n",
      "Epoch 21/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.1748 - loss: 0.6077 - val_acc: 0.1797 - val_loss: 0.6752\n",
      "Epoch 22/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1798 - loss: 0.5833 - val_acc: 0.1827 - val_loss: 0.6732\n",
      "Epoch 23/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1852 - loss: 0.5924 - val_acc: 0.1861 - val_loss: 0.6703\n",
      "Epoch 24/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1875 - loss: 0.5873 - val_acc: 0.1873 - val_loss: 0.6683\n",
      "Epoch 25/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1923 - loss: 0.5807 - val_acc: 0.1896 - val_loss: 0.6664\n",
      "Epoch 26/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.1963 - loss: 0.5580 - val_acc: 0.1905 - val_loss: 0.6652\n",
      "Epoch 27/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.1991 - loss: 0.5633 - val_acc: 0.1921 - val_loss: 0.6637\n",
      "Epoch 28/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - acc: 0.2010 - loss: 0.5560 - val_acc: 0.1928 - val_loss: 0.6626\n",
      "Epoch 29/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2032 - loss: 0.5664 - val_acc: 0.1943 - val_loss: 0.6613\n",
      "Epoch 30/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2124 - loss: 0.5477 - val_acc: 0.2002 - val_loss: 0.6606\n",
      "Epoch 31/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2181 - loss: 0.5381 - val_acc: 0.2015 - val_loss: 0.6596\n",
      "Epoch 32/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - acc: 0.2250 - loss: 0.5303 - val_acc: 0.2048 - val_loss: 0.6592\n",
      "Epoch 33/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.2308 - loss: 0.5156 - val_acc: 0.2074 - val_loss: 0.6574\n",
      "Epoch 34/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - acc: 0.2362 - loss: 0.5148 - val_acc: 0.2093 - val_loss: 0.6567\n",
      "Epoch 35/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.2456 - loss: 0.4968 - val_acc: 0.2085 - val_loss: 0.6566\n",
      "Epoch 36/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2460 - loss: 0.5081 - val_acc: 0.2110 - val_loss: 0.6561\n",
      "Epoch 37/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.2554 - loss: 0.4852 - val_acc: 0.2135 - val_loss: 0.6556\n",
      "Epoch 38/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.2622 - loss: 0.4800 - val_acc: 0.2116 - val_loss: 0.6565\n",
      "Epoch 39/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2667 - loss: 0.4820 - val_acc: 0.2140 - val_loss: 0.6557\n",
      "Epoch 40/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.2742 - loss: 0.4591 - val_acc: 0.2135 - val_loss: 0.6557\n",
      "Epoch 41/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2756 - loss: 0.4636 - val_acc: 0.2140 - val_loss: 0.6566\n",
      "Epoch 42/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - acc: 0.2812 - loss: 0.4584 - val_acc: 0.2139 - val_loss: 0.6570\n",
      "Epoch 43/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.2867 - loss: 0.4553 - val_acc: 0.2146 - val_loss: 0.6574\n",
      "Epoch 44/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2904 - loss: 0.4404 - val_acc: 0.2163 - val_loss: 0.6574\n",
      "Epoch 45/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.2995 - loss: 0.4333 - val_acc: 0.2157 - val_loss: 0.6589\n",
      "Epoch 46/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.2992 - loss: 0.4330 - val_acc: 0.2173 - val_loss: 0.6580\n",
      "Epoch 47/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.3060 - loss: 0.4190 - val_acc: 0.2142 - val_loss: 0.6598\n",
      "Epoch 48/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.3113 - loss: 0.4083 - val_acc: 0.2150 - val_loss: 0.6600\n",
      "Epoch 49/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - acc: 0.3212 - loss: 0.4051 - val_acc: 0.2153 - val_loss: 0.6605\n",
      "Epoch 50/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.3224 - loss: 0.4007 - val_acc: 0.2142 - val_loss: 0.6619\n",
      "Epoch 51/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.3312 - loss: 0.3935 - val_acc: 0.2163 - val_loss: 0.6618\n",
      "Epoch 52/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.3381 - loss: 0.3893 - val_acc: 0.2176 - val_loss: 0.6634\n",
      "Epoch 53/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.3424 - loss: 0.3783 - val_acc: 0.2182 - val_loss: 0.6642\n",
      "Epoch 54/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.3454 - loss: 0.3816 - val_acc: 0.2198 - val_loss: 0.6642\n",
      "Epoch 55/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.3560 - loss: 0.3678 - val_acc: 0.2158 - val_loss: 0.6658\n",
      "Epoch 56/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.3583 - loss: 0.3737 - val_acc: 0.2176 - val_loss: 0.6675\n",
      "Epoch 57/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.3677 - loss: 0.3560 - val_acc: 0.2183 - val_loss: 0.6682\n",
      "Epoch 58/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - acc: 0.3683 - loss: 0.3583 - val_acc: 0.2198 - val_loss: 0.6686\n",
      "Epoch 59/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.3800 - loss: 0.3389 - val_acc: 0.2201 - val_loss: 0.6700\n",
      "Epoch 60/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - acc: 0.3861 - loss: 0.3351 - val_acc: 0.2207 - val_loss: 0.6704\n",
      "Epoch 61/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.3919 - loss: 0.3323 - val_acc: 0.2207 - val_loss: 0.6716\n",
      "Epoch 62/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.3997 - loss: 0.3297 - val_acc: 0.2204 - val_loss: 0.6727\n",
      "Epoch 63/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.4174 - loss: 0.3223 - val_acc: 0.2205 - val_loss: 0.6746\n",
      "Epoch 64/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.4263 - loss: 0.3149 - val_acc: 0.2212 - val_loss: 0.6761\n",
      "Epoch 65/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.4450 - loss: 0.3020 - val_acc: 0.2220 - val_loss: 0.6777\n",
      "Epoch 66/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.4416 - loss: 0.2990 - val_acc: 0.2193 - val_loss: 0.6792\n",
      "Epoch 67/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.4582 - loss: 0.2917 - val_acc: 0.2184 - val_loss: 0.6802\n",
      "Epoch 68/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.4692 - loss: 0.2901 - val_acc: 0.2200 - val_loss: 0.6814\n",
      "Epoch 69/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.4829 - loss: 0.2825 - val_acc: 0.2198 - val_loss: 0.6826\n",
      "Epoch 70/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.4873 - loss: 0.2786 - val_acc: 0.2209 - val_loss: 0.6849\n",
      "Epoch 71/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.4996 - loss: 0.2815 - val_acc: 0.2198 - val_loss: 0.6858\n",
      "Epoch 72/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.5195 - loss: 0.2593 - val_acc: 0.2193 - val_loss: 0.6873\n",
      "Epoch 73/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.5248 - loss: 0.2632 - val_acc: 0.2172 - val_loss: 0.6894\n",
      "Epoch 74/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.5329 - loss: 0.2606 - val_acc: 0.2198 - val_loss: 0.6897\n",
      "Epoch 75/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.5459 - loss: 0.2535 - val_acc: 0.2192 - val_loss: 0.6916\n",
      "Epoch 76/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.5573 - loss: 0.2464 - val_acc: 0.2217 - val_loss: 0.6928\n",
      "Epoch 77/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.5756 - loss: 0.2336 - val_acc: 0.2192 - val_loss: 0.6954\n",
      "Epoch 78/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.5832 - loss: 0.2300 - val_acc: 0.2205 - val_loss: 0.6959\n",
      "Epoch 79/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.5950 - loss: 0.2285 - val_acc: 0.2184 - val_loss: 0.6971\n",
      "Epoch 80/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.6054 - loss: 0.2261 - val_acc: 0.2201 - val_loss: 0.6987\n",
      "Epoch 81/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.6145 - loss: 0.2186 - val_acc: 0.2206 - val_loss: 0.6999\n",
      "Epoch 82/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.6373 - loss: 0.2038 - val_acc: 0.2208 - val_loss: 0.7020\n",
      "Epoch 83/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.6413 - loss: 0.2047 - val_acc: 0.2217 - val_loss: 0.7035\n",
      "Epoch 84/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.6560 - loss: 0.1976 - val_acc: 0.2220 - val_loss: 0.7048\n",
      "Epoch 85/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.6680 - loss: 0.1923 - val_acc: 0.2192 - val_loss: 0.7084\n",
      "Epoch 86/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.6755 - loss: 0.1885 - val_acc: 0.2200 - val_loss: 0.7090\n",
      "Epoch 87/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.6866 - loss: 0.1811 - val_acc: 0.2210 - val_loss: 0.7108\n",
      "Epoch 88/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.6798 - loss: 0.1838 - val_acc: 0.2192 - val_loss: 0.7113\n",
      "Epoch 89/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.6975 - loss: 0.1787 - val_acc: 0.2209 - val_loss: 0.7136\n",
      "Epoch 90/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.7098 - loss: 0.1691 - val_acc: 0.2207 - val_loss: 0.7147\n",
      "Epoch 91/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.7182 - loss: 0.1673 - val_acc: 0.2205 - val_loss: 0.7160\n",
      "Epoch 92/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.7215 - loss: 0.1635 - val_acc: 0.2176 - val_loss: 0.7193\n",
      "Epoch 93/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.7376 - loss: 0.1599 - val_acc: 0.2200 - val_loss: 0.7195\n",
      "Epoch 94/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.7478 - loss: 0.1520 - val_acc: 0.2198 - val_loss: 0.7216\n",
      "Epoch 95/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.7584 - loss: 0.1469 - val_acc: 0.2177 - val_loss: 0.7234\n",
      "Epoch 96/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.7634 - loss: 0.1440 - val_acc: 0.2189 - val_loss: 0.7252\n",
      "Epoch 97/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.7713 - loss: 0.1406 - val_acc: 0.2182 - val_loss: 0.7268\n",
      "Epoch 98/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.7762 - loss: 0.1379 - val_acc: 0.2190 - val_loss: 0.7289\n",
      "Epoch 99/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.7797 - loss: 0.1364 - val_acc: 0.2190 - val_loss: 0.7305\n",
      "Epoch 100/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.7872 - loss: 0.1338 - val_acc: 0.2186 - val_loss: 0.7325\n",
      "Epoch 101/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.7985 - loss: 0.1273 - val_acc: 0.2166 - val_loss: 0.7352\n",
      "Epoch 102/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - acc: 0.8072 - loss: 0.1226 - val_acc: 0.2192 - val_loss: 0.7350\n",
      "Epoch 103/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.8082 - loss: 0.1232 - val_acc: 0.2189 - val_loss: 0.7372\n",
      "Epoch 104/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8144 - loss: 0.1197 - val_acc: 0.2199 - val_loss: 0.7392\n",
      "Epoch 105/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8223 - loss: 0.1165 - val_acc: 0.2198 - val_loss: 0.7403\n",
      "Epoch 106/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.8250 - loss: 0.1155 - val_acc: 0.2178 - val_loss: 0.7427\n",
      "Epoch 107/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - acc: 0.8291 - loss: 0.1112 - val_acc: 0.2196 - val_loss: 0.7446\n",
      "Epoch 108/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8423 - loss: 0.1050 - val_acc: 0.2203 - val_loss: 0.7453\n",
      "Epoch 109/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8425 - loss: 0.1050 - val_acc: 0.2195 - val_loss: 0.7478\n",
      "Epoch 110/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - acc: 0.8484 - loss: 0.0990 - val_acc: 0.2202 - val_loss: 0.7476\n",
      "Epoch 111/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8547 - loss: 0.0978 - val_acc: 0.2199 - val_loss: 0.7509\n",
      "Epoch 112/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - acc: 0.8619 - loss: 0.0952 - val_acc: 0.2205 - val_loss: 0.7521\n",
      "Epoch 113/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8638 - loss: 0.0939 - val_acc: 0.2208 - val_loss: 0.7545\n",
      "Epoch 114/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.8694 - loss: 0.0911 - val_acc: 0.2205 - val_loss: 0.7556\n",
      "Epoch 115/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.8746 - loss: 0.0885 - val_acc: 0.2202 - val_loss: 0.7574\n",
      "Epoch 116/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.8783 - loss: 0.0847 - val_acc: 0.2200 - val_loss: 0.7597\n",
      "Epoch 117/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8773 - loss: 0.0868 - val_acc: 0.2177 - val_loss: 0.7624\n",
      "Epoch 118/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.8830 - loss: 0.0836 - val_acc: 0.2245 - val_loss: 0.7614\n",
      "Epoch 119/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8837 - loss: 0.0821 - val_acc: 0.2212 - val_loss: 0.7631\n",
      "Epoch 120/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.8911 - loss: 0.0795 - val_acc: 0.2191 - val_loss: 0.7662\n",
      "Epoch 121/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8896 - loss: 0.0785 - val_acc: 0.2215 - val_loss: 0.7660\n",
      "Epoch 122/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.8983 - loss: 0.0761 - val_acc: 0.2195 - val_loss: 0.7675\n",
      "Epoch 123/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9023 - loss: 0.0712 - val_acc: 0.2197 - val_loss: 0.7693\n",
      "Epoch 124/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9101 - loss: 0.0698 - val_acc: 0.2195 - val_loss: 0.7718\n",
      "Epoch 125/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9125 - loss: 0.0678 - val_acc: 0.2207 - val_loss: 0.7735\n",
      "Epoch 126/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9166 - loss: 0.0643 - val_acc: 0.2223 - val_loss: 0.7764\n",
      "Epoch 127/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9198 - loss: 0.0639 - val_acc: 0.2209 - val_loss: 0.7764\n",
      "Epoch 128/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.9216 - loss: 0.0633 - val_acc: 0.2205 - val_loss: 0.7785\n",
      "Epoch 129/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - acc: 0.9232 - loss: 0.0620 - val_acc: 0.2185 - val_loss: 0.7813\n",
      "Epoch 130/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9287 - loss: 0.0583 - val_acc: 0.2200 - val_loss: 0.7806\n",
      "Epoch 131/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - acc: 0.9305 - loss: 0.0589 - val_acc: 0.2210 - val_loss: 0.7840\n",
      "Epoch 132/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9333 - loss: 0.0561 - val_acc: 0.2189 - val_loss: 0.7853\n",
      "Epoch 133/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.9350 - loss: 0.0541 - val_acc: 0.2214 - val_loss: 0.7868\n",
      "Epoch 134/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.9402 - loss: 0.0527 - val_acc: 0.2199 - val_loss: 0.7885\n",
      "Epoch 135/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.9423 - loss: 0.0511 - val_acc: 0.2203 - val_loss: 0.7909\n",
      "Epoch 136/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.9439 - loss: 0.0493 - val_acc: 0.2205 - val_loss: 0.7918\n",
      "Epoch 137/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9454 - loss: 0.0489 - val_acc: 0.2197 - val_loss: 0.7938\n",
      "Epoch 138/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.9482 - loss: 0.0474 - val_acc: 0.2197 - val_loss: 0.7949\n",
      "Epoch 139/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - acc: 0.9491 - loss: 0.0473 - val_acc: 0.2191 - val_loss: 0.7966\n",
      "Epoch 140/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.9511 - loss: 0.0466 - val_acc: 0.2201 - val_loss: 0.7991\n",
      "Epoch 141/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.9529 - loss: 0.0458 - val_acc: 0.2180 - val_loss: 0.7995\n",
      "Epoch 142/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - acc: 0.9540 - loss: 0.0447 - val_acc: 0.2163 - val_loss: 0.8022\n",
      "Epoch 143/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - acc: 0.9576 - loss: 0.0416 - val_acc: 0.2182 - val_loss: 0.8033\n",
      "Epoch 144/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9594 - loss: 0.0419 - val_acc: 0.2187 - val_loss: 0.8038\n",
      "Epoch 145/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9603 - loss: 0.0416 - val_acc: 0.2191 - val_loss: 0.8056\n",
      "Epoch 146/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.9611 - loss: 0.0391 - val_acc: 0.2175 - val_loss: 0.8075\n",
      "Epoch 147/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - acc: 0.9604 - loss: 0.0400 - val_acc: 0.2189 - val_loss: 0.8085\n",
      "Epoch 148/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.9641 - loss: 0.0377 - val_acc: 0.2196 - val_loss: 0.8093\n",
      "Epoch 149/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9639 - loss: 0.0379 - val_acc: 0.2190 - val_loss: 0.8131\n",
      "Epoch 150/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9682 - loss: 0.0355 - val_acc: 0.2192 - val_loss: 0.8111\n",
      "Epoch 151/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9698 - loss: 0.0348 - val_acc: 0.2181 - val_loss: 0.8138\n",
      "Epoch 152/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9733 - loss: 0.0332 - val_acc: 0.2184 - val_loss: 0.8157\n",
      "Epoch 153/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9729 - loss: 0.0328 - val_acc: 0.2203 - val_loss: 0.8172\n",
      "Epoch 154/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9744 - loss: 0.0323 - val_acc: 0.2184 - val_loss: 0.8188\n",
      "Epoch 155/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9730 - loss: 0.0322 - val_acc: 0.2189 - val_loss: 0.8201\n",
      "Epoch 156/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9749 - loss: 0.0316 - val_acc: 0.2169 - val_loss: 0.8211\n",
      "Epoch 157/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9732 - loss: 0.0315 - val_acc: 0.2178 - val_loss: 0.8230\n",
      "Epoch 158/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9754 - loss: 0.0305 - val_acc: 0.2198 - val_loss: 0.8241\n",
      "Epoch 159/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9784 - loss: 0.0286 - val_acc: 0.2179 - val_loss: 0.8254\n",
      "Epoch 160/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9800 - loss: 0.0272 - val_acc: 0.2180 - val_loss: 0.8274\n",
      "Epoch 161/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9817 - loss: 0.0262 - val_acc: 0.2214 - val_loss: 0.8272\n",
      "Epoch 162/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9817 - loss: 0.0267 - val_acc: 0.2187 - val_loss: 0.8307\n",
      "Epoch 163/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9831 - loss: 0.0248 - val_acc: 0.2198 - val_loss: 0.8316\n",
      "Epoch 164/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9847 - loss: 0.0244 - val_acc: 0.2168 - val_loss: 0.8338\n",
      "Epoch 165/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9863 - loss: 0.0234 - val_acc: 0.2187 - val_loss: 0.8338\n",
      "Epoch 166/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9871 - loss: 0.0232 - val_acc: 0.2168 - val_loss: 0.8367\n",
      "Epoch 167/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9855 - loss: 0.0230 - val_acc: 0.2187 - val_loss: 0.8375\n",
      "Epoch 168/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9871 - loss: 0.0217 - val_acc: 0.2173 - val_loss: 0.8389\n",
      "Epoch 169/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9873 - loss: 0.0217 - val_acc: 0.2196 - val_loss: 0.8399\n",
      "Epoch 170/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9851 - loss: 0.0232 - val_acc: 0.2191 - val_loss: 0.8399\n",
      "Epoch 171/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9855 - loss: 0.0224 - val_acc: 0.2195 - val_loss: 0.8406\n",
      "Epoch 172/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9863 - loss: 0.0217 - val_acc: 0.2189 - val_loss: 0.8420\n",
      "Epoch 173/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9896 - loss: 0.0201 - val_acc: 0.2192 - val_loss: 0.8443\n",
      "Epoch 174/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9901 - loss: 0.0194 - val_acc: 0.2195 - val_loss: 0.8444\n",
      "Epoch 175/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9910 - loss: 0.0182 - val_acc: 0.2210 - val_loss: 0.8467\n",
      "Epoch 176/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9914 - loss: 0.0179 - val_acc: 0.2184 - val_loss: 0.8478\n",
      "Epoch 177/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9923 - loss: 0.0173 - val_acc: 0.2163 - val_loss: 0.8522\n",
      "Epoch 178/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9877 - loss: 0.0203 - val_acc: 0.2185 - val_loss: 0.8484\n",
      "Epoch 179/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9894 - loss: 0.0188 - val_acc: 0.2164 - val_loss: 0.8505\n",
      "Epoch 180/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9917 - loss: 0.0175 - val_acc: 0.2198 - val_loss: 0.8523\n",
      "Epoch 181/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9930 - loss: 0.0165 - val_acc: 0.2193 - val_loss: 0.8534\n",
      "Epoch 182/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9934 - loss: 0.0161 - val_acc: 0.2198 - val_loss: 0.8548\n",
      "Epoch 183/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9936 - loss: 0.0158 - val_acc: 0.2183 - val_loss: 0.8558\n",
      "Epoch 184/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9946 - loss: 0.0147 - val_acc: 0.2205 - val_loss: 0.8568\n",
      "Epoch 185/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9946 - loss: 0.0144 - val_acc: 0.2205 - val_loss: 0.8582\n",
      "Epoch 186/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9950 - loss: 0.0140 - val_acc: 0.2201 - val_loss: 0.8601\n",
      "Epoch 187/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9956 - loss: 0.0137 - val_acc: 0.2194 - val_loss: 0.8614\n",
      "Epoch 188/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9965 - loss: 0.0129 - val_acc: 0.2205 - val_loss: 0.8628\n",
      "Epoch 189/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9960 - loss: 0.0132 - val_acc: 0.2193 - val_loss: 0.8643\n",
      "Epoch 190/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.9959 - loss: 0.0127 - val_acc: 0.2184 - val_loss: 0.8646\n",
      "Epoch 191/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9956 - loss: 0.0130 - val_acc: 0.2192 - val_loss: 0.8655\n",
      "Epoch 192/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9968 - loss: 0.0122 - val_acc: 0.2190 - val_loss: 0.8677\n",
      "Epoch 193/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9966 - loss: 0.0123 - val_acc: 0.2198 - val_loss: 0.8689\n",
      "Epoch 194/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9967 - loss: 0.0121 - val_acc: 0.2201 - val_loss: 0.8692\n",
      "Epoch 195/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9967 - loss: 0.0117 - val_acc: 0.2196 - val_loss: 0.8714\n",
      "Epoch 196/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9973 - loss: 0.0110 - val_acc: 0.2190 - val_loss: 0.8719\n",
      "Epoch 197/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9974 - loss: 0.0109 - val_acc: 0.2224 - val_loss: 0.8730\n",
      "Epoch 198/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9979 - loss: 0.0104 - val_acc: 0.2201 - val_loss: 0.8739\n",
      "Epoch 199/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9978 - loss: 0.0105 - val_acc: 0.2199 - val_loss: 0.8761\n",
      "Epoch 200/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9982 - loss: 0.0101 - val_acc: 0.2193 - val_loss: 0.8772\n",
      "Epoch 201/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9982 - loss: 0.0099 - val_acc: 0.2206 - val_loss: 0.8780\n",
      "Epoch 202/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - acc: 0.9983 - loss: 0.0099 - val_acc: 0.2185 - val_loss: 0.8801\n",
      "Epoch 203/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9985 - loss: 0.0095 - val_acc: 0.2182 - val_loss: 0.8808\n",
      "Epoch 204/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9988 - loss: 0.0093 - val_acc: 0.2210 - val_loss: 0.8814\n",
      "Epoch 205/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9990 - loss: 0.0088 - val_acc: 0.2187 - val_loss: 0.8832\n",
      "Epoch 206/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9984 - loss: 0.0089 - val_acc: 0.2206 - val_loss: 0.8833\n",
      "Epoch 207/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9982 - loss: 0.0095 - val_acc: 0.2194 - val_loss: 0.8841\n",
      "Epoch 208/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9967 - loss: 0.0100 - val_acc: 0.2197 - val_loss: 0.8805\n",
      "Epoch 209/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9815 - loss: 0.0178 - val_acc: 0.2208 - val_loss: 0.8762\n",
      "Epoch 210/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9839 - loss: 0.0166 - val_acc: 0.2218 - val_loss: 0.8750\n",
      "Epoch 211/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9895 - loss: 0.0147 - val_acc: 0.2250 - val_loss: 0.8737\n",
      "Epoch 212/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9958 - loss: 0.0117 - val_acc: 0.2238 - val_loss: 0.8771\n",
      "Epoch 213/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9979 - loss: 0.0101 - val_acc: 0.2239 - val_loss: 0.8783\n",
      "Epoch 214/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9988 - loss: 0.0085 - val_acc: 0.2256 - val_loss: 0.8799\n",
      "Epoch 215/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9992 - loss: 0.0081 - val_acc: 0.2247 - val_loss: 0.8809\n",
      "Epoch 216/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9991 - loss: 0.0076 - val_acc: 0.2246 - val_loss: 0.8827\n",
      "Epoch 217/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9995 - loss: 0.0073 - val_acc: 0.2259 - val_loss: 0.8845\n",
      "Epoch 218/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9994 - loss: 0.0072 - val_acc: 0.2248 - val_loss: 0.8860\n",
      "Epoch 219/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9995 - loss: 0.0069 - val_acc: 0.2266 - val_loss: 0.8873\n",
      "Epoch 220/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9996 - loss: 0.0067 - val_acc: 0.2250 - val_loss: 0.8887\n",
      "Epoch 221/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9995 - loss: 0.0068 - val_acc: 0.2258 - val_loss: 0.8892\n",
      "Epoch 222/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9994 - loss: 0.0066 - val_acc: 0.2246 - val_loss: 0.8906\n",
      "Epoch 223/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9997 - loss: 0.0061 - val_acc: 0.2253 - val_loss: 0.8919\n",
      "Epoch 224/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9995 - loss: 0.0064 - val_acc: 0.2241 - val_loss: 0.8924\n",
      "Epoch 225/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9995 - loss: 0.0064 - val_acc: 0.2253 - val_loss: 0.8937\n",
      "Epoch 226/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9997 - loss: 0.0062 - val_acc: 0.2256 - val_loss: 0.8953\n",
      "Epoch 227/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9998 - loss: 0.0060 - val_acc: 0.2259 - val_loss: 0.8956\n",
      "Epoch 228/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9998 - loss: 0.0057 - val_acc: 0.2246 - val_loss: 0.8968\n",
      "Epoch 229/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9997 - loss: 0.0058 - val_acc: 0.2248 - val_loss: 0.8973\n",
      "Epoch 230/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9996 - loss: 0.0056 - val_acc: 0.2231 - val_loss: 0.8994\n",
      "Epoch 231/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9998 - loss: 0.0058 - val_acc: 0.2234 - val_loss: 0.8993\n",
      "Epoch 232/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9998 - loss: 0.0057 - val_acc: 0.2252 - val_loss: 0.9005\n",
      "Epoch 233/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9997 - loss: 0.0054 - val_acc: 0.2231 - val_loss: 0.9013\n",
      "Epoch 234/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9998 - loss: 0.0054 - val_acc: 0.2245 - val_loss: 0.9030\n",
      "Epoch 235/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9999 - loss: 0.0051 - val_acc: 0.2237 - val_loss: 0.9036\n",
      "Epoch 236/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9999 - loss: 0.0051 - val_acc: 0.2237 - val_loss: 0.9046\n",
      "Epoch 237/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9999 - loss: 0.0048 - val_acc: 0.2239 - val_loss: 0.9058\n",
      "Epoch 238/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0050 - val_acc: 0.2239 - val_loss: 0.9065\n",
      "Epoch 239/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9998 - loss: 0.0049 - val_acc: 0.2234 - val_loss: 0.9071\n",
      "Epoch 240/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9999 - loss: 0.0047 - val_acc: 0.2241 - val_loss: 0.9090\n",
      "Epoch 241/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0048 - val_acc: 0.2244 - val_loss: 0.9090\n",
      "Epoch 242/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 0.9999 - loss: 0.0045 - val_acc: 0.2241 - val_loss: 0.9105\n",
      "Epoch 243/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - acc: 0.9999 - loss: 0.0046 - val_acc: 0.2234 - val_loss: 0.9112\n",
      "Epoch 244/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9999 - loss: 0.0043 - val_acc: 0.2244 - val_loss: 0.9116\n",
      "Epoch 245/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9999 - loss: 0.0043 - val_acc: 0.2229 - val_loss: 0.9130\n",
      "Epoch 246/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 1.0000 - loss: 0.0042 - val_acc: 0.2247 - val_loss: 0.9136\n",
      "Epoch 247/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 1.0000 - loss: 0.0043 - val_acc: 0.2218 - val_loss: 0.9145\n",
      "Epoch 248/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - acc: 1.0000 - loss: 0.0044 - val_acc: 0.2227 - val_loss: 0.9146\n",
      "Epoch 249/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0043 - val_acc: 0.2222 - val_loss: 0.9156\n",
      "Epoch 250/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 1.0000 - loss: 0.0041 - val_acc: 0.2218 - val_loss: 0.9162\n",
      "Epoch 251/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0042 - val_acc: 0.2234 - val_loss: 0.9174\n",
      "Epoch 252/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0040 - val_acc: 0.2227 - val_loss: 0.9182\n",
      "Epoch 253/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0040 - val_acc: 0.2236 - val_loss: 0.9189\n",
      "Epoch 254/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9999 - loss: 0.0040 - val_acc: 0.2231 - val_loss: 0.9189\n",
      "Epoch 255/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9994 - loss: 0.0046 - val_acc: 0.2194 - val_loss: 0.9208\n",
      "Epoch 256/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9967 - loss: 0.0066 - val_acc: 0.2202 - val_loss: 0.9170\n",
      "Epoch 257/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - acc: 0.9887 - loss: 0.0104 - val_acc: 0.2170 - val_loss: 0.9158\n",
      "Epoch 258/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9788 - loss: 0.0153 - val_acc: 0.2223 - val_loss: 0.9072\n",
      "Epoch 259/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9855 - loss: 0.0127 - val_acc: 0.2223 - val_loss: 0.9074\n",
      "Epoch 260/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9954 - loss: 0.0084 - val_acc: 0.2250 - val_loss: 0.9080\n",
      "Epoch 261/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9994 - loss: 0.0059 - val_acc: 0.2267 - val_loss: 0.9082\n",
      "Epoch 262/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 0.9996 - loss: 0.0048 - val_acc: 0.2265 - val_loss: 0.9101\n",
      "Epoch 263/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - acc: 0.9999 - loss: 0.0042 - val_acc: 0.2291 - val_loss: 0.9110\n",
      "Epoch 264/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 0.9999 - loss: 0.0041 - val_acc: 0.2278 - val_loss: 0.9124\n",
      "Epoch 265/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - acc: 1.0000 - loss: 0.0039 - val_acc: 0.2279 - val_loss: 0.9134\n",
      "Epoch 266/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - acc: 1.0000 - loss: 0.0037Early stopping condition met. Waiting: 1/2\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 1.0000 - loss: 0.0037 - val_acc: 0.2281 - val_loss: 0.9144\n",
      "Epoch 267/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - acc: 1.0000 - loss: 0.0035Early stopping condition met. Waiting: 2/2\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - acc: 1.0000 - loss: 0.0035 - val_acc: 0.2277 - val_loss: 0.9154\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 중 얼리스토핑 콜백 적용\n",
    "early_stopping_callback = CustomEarlyStopping(patience=2)  # patience는 얼리스토핑 전에 기다리는 에포크 수\n",
    "\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs], decoder_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    "  callbacks=[early_stopping_callback]  # 얼리 스토핑 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 가중치 비교\n",
    "original_weights = model.get_weights()\n",
    "\n",
    "# 모델을 저장\n",
    "model.save(PATH_MODEL)\n",
    "\n",
    "# 모델을 불러옴\n",
    "model_loaded = load_model(PATH_MODEL, custom_objects={'custom_loss': custom_loss, 'acc': acc})\n",
    "\n",
    "# 불러온 모델의 가중치\n",
    "loaded_weights = model_loaded.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n",
      "가중치 일치\n"
     ]
    }
   ],
   "source": [
    "# 가중치 비교\n",
    "for original, loaded in zip(original_weights, loaded_weights):\n",
    "    if np.array_equal(original, loaded):\n",
    "        print(\"가중치 일치\")\n",
    "    else:\n",
    "        print(\"가중치 불일치\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# this time, we want to keep the states too, to be output\n",
    "# by our sampling model\n",
    "decoder_outputs, h, c = decoder_lstm(\n",
    "  decoder_inputs_single_x,\n",
    "  initial_state=decoder_states_inputs\n",
    ")\n",
    "# decoder_outputs, state_h = decoder_lstm(\n",
    "#   decoder_inputs_single_x,\n",
    "#   initial_state=decoder_states_inputs\n",
    "# ) #gru\n",
    "decoder_states = [h, c]\n",
    "# decoder_states = [h] # gru\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The sampling model\n",
    "# inputs: y(t-1), h(t-1), c(t-1)\n",
    "# outputs: y(t), h(t), c(t)\n",
    "decoder_model = Model(\n",
    "  [decoder_inputs_single] + decoder_states_inputs, \n",
    "  [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    output_tokens, h, c = decoder_model.predict(\n",
    "      [target_seq] + states_value\n",
    "    )\n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "    # Get next wordgfhjfghj\n",
    "    idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    # states_value = [h] # gru\n",
    "\n",
    "  return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_model.save(PATH_ENCODER_MODEL)\n",
    "decoder_model.save(PATH_DECODER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "-\n",
      "Input: what are the three dominant political parties in America ?\n",
      "Translation: a political party ( from , genitive partis , `` part '' , `` portion '' ) is a political organization that typically seeks to influence , or entirely control , government policy , usually by nominating candidates with aligned political views and trying to seat them in political office .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Do some test translations\n",
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "-\n",
      "Input: How are the directions of the velocity and force vectors related in a circular motion\n",
      "Translation: in physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path .\n"
     ]
    }
   ],
   "source": [
    "  # Do some test translations\n",
    "i = 1\n",
    "print(i)\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
